<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>周小白</title>
  
  
  <link href="http://baixiaozhou.github.io/atom.xml" rel="self"/>
  
  <link href="http://baixiaozhou.github.io/"/>
  <updated>2025-03-18T09:18:36.017Z</updated>
  <id>http://baixiaozhou.github.io/</id>
  
  <author>
    <name>baixiaozhou</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Ceph 介绍</title>
    <link href="http://baixiaozhou.github.io/p/Ceph-%E4%BB%8B%E7%BB%8D/"/>
    <id>http://baixiaozhou.github.io/p/Ceph-%E4%BB%8B%E7%BB%8D/</id>
    <published>2025-03-18T07:00:27.000Z</published>
    <updated>2025-03-18T09:18:36.017Z</updated>
    
    <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a>Ceph 介绍</h1><p>This article was written by baixiaozhou on 1742281227000.</p><!-- Your content starts here --><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><strong>Ceph</strong> 是一个开源的分布式存储系统，提供 <strong>统一的存储</strong> 接口和高可用性。它是为现代数据中心设计的，能够支持多种存储需求，包括 <strong>块存储</strong>、<strong>文件存储</strong> 和 <strong>对象存储</strong>。</p><h2 id="核心特性"><a href="#核心特性" class="headerlink" title="核心特性"></a>核心特性</h2><ol><li><p><strong>统一存储平台</strong>: Ceph 能够提供 <strong>块存储</strong>（类似于传统的磁盘）、<strong>对象存储</strong>（适用于云存储）、以及 <strong>文件系统存储</strong>（通过 CephFS 提供）等多种存储接口。它支持在同一平台上同时管理多种存储形式。</p></li><li><p><strong>去中心化架构</strong>: Ceph 不依赖任何单一的管理节点，而是通过分布式方式自动平衡数据，支持横向扩展。所有节点都可以动态加入到集群中，且系统会自动进行 <strong>数据均衡</strong> 和 <strong>故障恢复</strong>。</p></li><li><p><strong>高可用性和容错</strong>：Ceph 的设计支持高可用性和 <strong>自动故障恢复</strong>。数据被复制到多个副本，并通过 <strong>CRUSH（Controlled Replication Under Scalable Hashing）算法</strong> 实现动态的负载均衡与数据分布。</p></li><li><p><strong>分布式和可扩展性</strong>：Ceph 的设计允许 <strong>横向扩展</strong>，可以轻松地通过增加节点来扩展存储容量和性能。它的扩展性几乎没有上限，适合用于大规模数据中心和云平台。</p></li><li><p><strong>高性能</strong>：Ceph 通过使用 <strong>自我修复机制</strong> 和 <strong>数据分布算法</strong>，能够在硬件失败或节点增加的情况下提供 <strong>高性能存储</strong></p></li><li><p><strong>强大的管理和监控功能</strong>：Ceph 提供了 <strong>监控和管理工具</strong>，如 <strong>Ceph Dashboard</strong> 和 <strong>Ceph CLI</strong>，用于集群状态检查、性能监控、日志查看和管理操作</p></li></ol><h2 id="主要组件"><a href="#主要组件" class="headerlink" title="主要组件"></a>主要组件</h2><ol><li>MON(Monitor): 负责 <strong>存储集群的元数据管理</strong>, 维护集群状态的映射，包括<a href="https://docs.ceph.com/en/reef/rados/operations/monitoring/#display-mon-map">监控器映射</a>、管理器映射、OSD 映射、MDS 映射和 CRUSH 映射。这些映射是 Ceph 守护进程相互协调所需的关键集群状态。监视器还负责管理守护进程和客户端之间的身份验证。通常至少需要三个监视器来实现冗余和高可用性。</li><li>MGR(Manager): 负责跟踪运行时指标和 Ceph 集群的当前状态，包括存储利用率、当前性能指标和系统负载。Ceph Manager 守护进程还托管基于 python 的模块，用于管理和公开 Ceph 集群信息，包括基于 Web 的 <a href="https://docs.ceph.com/en/reef/mgr/dashboard/#mgr-dashboard">Ceph 控制面板</a>和 <a href="https://docs.ceph.com/en/mgr/restful">REST API</a> 的 API 中。高可用性通常需要至少两个 Manager。</li><li>OSD(Object Storage Daemon): OSD 是存储数据的核心组件。每个 OSD 守护进程负责管理一个存储设备（磁盘）和其上存储的数据副本。OSD 是 Ceph 系统中进行数据存储和恢复的主要工作单元，处理数据复制、恢复、再平衡，并通过检查其他 Ceph OSD 守护进程的心跳信号，向 Ceph 监控器和管理器提供一些监控信息。通常需要至少三个 Ceph OSD 来实现冗余和高可用性。</li><li>MDS(Metadata Server): 对于 <strong>CephFS（Ceph 文件系统）</strong>，MDS 负责管理文件系统的元数据，如文件和目录的结构、权限等。它确保 CephFS 文件系统能正常运行。</li><li>RGW(Ceph Object Gateway): 在应用程序和 Ceph 存储集群之间提供 RESTful 网关。 与 S3 兼容的 API 是最常用的，但 Swift 也可用。</li><li>RADOS(Reliable Autonomic Distributed Object Store): Ceph 的存储后端，是一个 <strong>分布式对象存储系统</strong>。所有的存储数据都被划分为对象，分布在不同的 OSD 节点上，RADOS 确保数据的可靠性、可用性和性能。</li></ol><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ol><li><p>   <strong>云存储</strong>：Ceph 被广泛应用于构建云存储平台，支持 <strong>对象存储</strong>（例如 AWS S3 API）、<strong>块存储</strong>（例如虚拟机磁盘）和 <strong>文件系统存储</strong>（例如 CephFS）。</p></li><li><p><strong>大数据存储</strong>：Ceph 的高可扩展性和容错性使其成为处理大规模数据存储需求的理想选择，尤其适用于 <strong>大数据分析</strong> 和 <strong>机器学习</strong> 领域。</p></li><li><p><strong>虚拟化环境</strong>：Ceph 可以用作 <strong>虚拟机存储</strong>（如 OpenStack、KVM 或 VMware），提供高性能和高可用的块存储。</p></li><li><p><strong>容器化和微服务</strong>：Ceph 与容器平台（如 Kubernetes）集成，提供持久化存储服务，支持容器应用的数据存储需求。</p></li></ol><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><p>Ceph 存储集群需要以下内容：至少一个 Ceph Monitor 和至少一个 Ceph Manager，以及至少与 Ceph 集群中存储的给定对象的副本一样多的OSD，（例如，如果给定对象的三个副本存储在 Ceph 集群中， 则该 Ceph 集群中必须至少存在三个 OSD）。</p><p>至于对操作系统，机器配置等要求，大家可以自行在官网上进行查阅: <a href="https://docs.ceph.com/en/reef/start/hardware-recommendations/">https://docs.ceph.com/en/reef/start/hardware-recommendations/</a></p><p>Ceph 提供了多种部署方式，我这里采用手动部署来完成整个部署流程。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>准备三台集群，</p><table><thead><tr><th><strong>主机名</strong></th><th><strong>角色</strong></th></tr></thead><tbody><tr><td>node1</td><td>MON, MGR, OSD</td></tr><tr><td>node2</td><td>MON, OSD</td></tr><tr><td>node3</td><td>MON,  OSD</td></tr></tbody></table><p>系统准备:</p><ol><li>时间同步: 确保三个节点时间一致，可以使用 ntp&#x2F;chronyd</li><li>ssh 免密: 管理节点 node1 需要配置免密到所有节点</li><li>关闭防火墙(也可以单独放开规则)和 selinux</li></ol><h2 id="安装ceph"><a href="#安装ceph" class="headerlink" title="安装ceph"></a>安装ceph</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y ceph ceph-common ceph-mon ceph-osd ceph-mgr ceph-mds</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">A brief description of the content</summary>
    
    
    
    <category term="Technology" scheme="http://baixiaozhou.github.io/categories/Technology/"/>
    
    
    <category term="Programming" scheme="http://baixiaozhou.github.io/tags/Programming/"/>
    
    <category term="Hexo" scheme="http://baixiaozhou.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>VictoriaMetrics 介绍</title>
    <link href="http://baixiaozhou.github.io/p/VictoriaMetrics%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"/>
    <id>http://baixiaozhou.github.io/p/VictoriaMetrics%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/</id>
    <published>2025-02-19T09:07:48.000Z</published>
    <updated>2025-02-26T09:50:30.992Z</updated>
    
    <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a>VictoriaMetrics 介绍</h1><p>This article was written by baixiaozhou on 1739956068000.</p><!-- Your content starts here --><p>官方文档: <a href="https://docs.victoriametrics.com/">https://docs.victoriametrics.com/</a></p><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>我们先看一下VictoriaMetrics 官网的介绍: VictoriaMetrics 是一个开源的、高可用的、分布式、时间序列数据库，用于存储和查询时间序列数据。<br>从简述来看，我们其实可以发现，VictoriaMetrics 其实和 Prometheus 有很多相似之处，那么我们为什么还要使用 VictoriaMetrics 呢？<br>在了解这些之前，我们先来了解一下 Prometheus 的一些特点:</p><ol><li>单实例，不可扩展: Prometheus 的作者及社区核心开发者都秉承一个理念：Prometheus 只聚焦核心的功能，扩展性的功能留给社区解决，所以 Prometheus 自诞生至今都是单实例不可扩展的。</li><li>无法处理大规模数据: Prometheus 作为时序数据库，其核心功能就是存储和查询时序数据，但是 Prometheus 本身并没有提供分布式存储和查询的能力。默认情况下，prometheus 存储数据时长默认保留 15 天，超过 15 天的数据会被自动清理掉（可修改）。</li></ol><p>在长期存储方案出现之前，用户如果需要跨集群聚合计算数据时，社区提供了Federation 方式。<br>2017 年，Prometheus 加⼊ Remote Read&#x2F;Write API，自此之后社区涌现出大量长期存储的方案，如 Thanos、Grafana Cortex&#x2F;Mimir、VictoriaMetrics、Wavefront、Splunk、Sysdig、SignalFx、InfluxDB、Graphite 等。 而我们这篇文章要介绍的 VictoriaMetrics 就是其中之一。</p><h2 id="1-1-VictoriaMetrics-的特点"><a href="#1-1-VictoriaMetrics-的特点" class="headerlink" title="1.1 VictoriaMetrics 的特点"></a>1.1 VictoriaMetrics 的特点</h2><p>由于官网中关于 VictoriaMetrics 的特点描述比较多，这里我们主要展示一下核心特点或者日常使用中比较关键的一些点:</p><ul><li>它可以用作 Prometheus 的长期存储。这里的长期存储指的就是<strong>Prometheus 通过 remote_write url 将数据写入到 vm 中，以 vm作为数据存储的载体</strong></li><li>也可以用做 Prometheus 的直接替代品，因为vm 支持 prometheus 语法。</li><li>数据压缩率高，与 TimescaleDB 相比，可以在有限存储中存储多达 70 倍的数据点，与 Prometheus、Thanos 或 Cortex 相比，所需的存储空间最多可减少 7 倍。（官网提供的数据）</li><li>实现了一种类似 PromQL 的查询语言 - <a href="https://docs.victoriametrics.com/metricsql/">MetricsQL，</a> 在 PromQL 的基础上提供了改进的功能</li><li>可以用作 Grafana 中 Graphite 的直接替代品，因为它支持 <a href="https://docs.victoriametrics.com/#graphite-api-usage">Graphite API</a></li></ul><h2 id="1-2-VictoriaMetrics-的架构和组成"><a href="#1-2-VictoriaMetrics-的架构和组成" class="headerlink" title="1.2 VictoriaMetrics 的架构和组成"></a>1.2 VictoriaMetrics 的架构和组成</h2><p>从部署上来说，VictoriaMetrics 有两种部署方式，一种是单机部署，一种是集群部署。 在实际的线上环境中，还是以集群部署为主，因为集群部署可以提供更高的可用性，同时也可以提供更好的性能。因此我们这里可以看下集群部署的架构图。</p><p>VictoriaMetrics 的架构图如下所示:<br><img src="https://docs.victoriametrics.com/Cluster-VictoriaMetrics_cluster-scheme.webp" alt="VictoriaMetrics 架构图"></p><p>集群的核心角色包括以下几个组件:</p><ul><li>vminsert: 接收提取的数据，并根据指标名称及其所有标签的一致哈希将其分布在 <code>VMStstorage</code> 节点之间</li><li>vmstorage: 存储原始数据并返回给定标签筛选条件的给定时间范围内的查询数据</li><li>vmselect： 通过从所有已配置的 <code>VMStlayer</code> 节点获取所需数据来执行传入查询</li></ul><p>除了上面的这几个组件，VictoriaMetrics 还提供了其他的一些组件</p><ul><li>vmagent: 一个<strong>可选的独立组件</strong>，主要用于数据采集和转发</li><li>vmalert: 用于执行给定<a href="https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/">警报</a>的列表 或<a href="https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/">录制</a>针对配置的 <code>-datasource.url</code> 的规则</li><li>vmauth: 是一个 HTTP 代理，可以<a href="https://docs.victoriametrics.com/vmauth/#authorization">授权</a>、<a href="https://docs.victoriametrics.com/vmauth/#routing">路由</a> 以及跨 <a href="https://github.com/VictoriaMetrics/VictoriaMetrics">VictoriaMetrics</a> 组件或任何其他 HTTP 后端的<a href="https://docs.victoriametrics.com/vmauth/#load-balancing">负载均衡</a>请求。</li><li>vmbackup&#x2F;vmrestore: 数据备份&#x2F;恢复</li><li>vmctl: 数据迁移工具，用于从其他时序数据库（TSDB）导入数据到 VictoriaMetrics。</li><li>vmgateway: 是 VictoriaMetrics 时间序列数据库 （TSDB） 的代理。</li><li>vmbackupmanager: 备份管理器自动执行常规备份程序</li><li>vmalert-tool:  是 <strong>VictoriaMetrics 提供的工具</strong>，用于测试、调试和管理 <strong>vmalert 规则</strong>，主要用于 <strong>验证 Prometheus Alerting 规则</strong> 以及 <strong>预处理 VictoriaMetrics 的告警配置</strong>。</li></ul><h1 id="2-部署安装"><a href="#2-部署安装" class="headerlink" title="2. 部署安装"></a>2. 部署安装</h1><h2 id="2-1-下载"><a href="#2-1-下载" class="headerlink" title="2.1 下载"></a>2.1 下载</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从 github 上下载</span></span><br><span class="line">wget https://github.com/VictoriaMetrics/VictoriaMetrics/releases/download/v1.111.0/victoria-metrics-linux-arm64-v1.111.0-cluster.tar.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压</span></span><br><span class="line">tar -xzvf victoria-metrics-linux-arm64-v1.111.0-cluster.tar.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到集群的包中包括三个文件</span></span><br><span class="line">vminsert-prod  vmselect-prod  vmstorage-prod</span><br></pre></td></tr></table></figure><p>一个最小化的集群必须包含以下节点:</p><ul><li>一个带有<code>-storageDataPath</code> 标志的 <code>vmstorage</code> 节点</li><li>一个带有 <code>-storageNode=&lt;vmstorage_host&gt;</code> 参数的 <code>vminsert</code> 节点</li><li>一个带有 <code>-storageNode=&lt;vmstorage_host&gt;</code> 参数的 <code>vmselect</code> 节点</li></ul><p>如果完全以<code>VictoriaMetrics</code>作为存储系统，此外还需要一个 <code>vmagent</code> 节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从 github 上下载</span></span><br><span class="line">wget https://github.com/VictoriaMetrics/VictoriaMetrics/releases/download/v1.111.0/vmutils-linux-arm64-v1.111.0.tar.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压</span></span><br><span class="line">tar xzvf vmutils-linux-arm64-v1.111.0.tar.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">包括其他的一些组件包</span></span><br><span class="line">vmagent-prod vmalert-prod vmalert-tool-prod vmauth-prod vmbackup-prod vmrestore-prod vmctl-prod</span><br></pre></td></tr></table></figure><h2 id="2-2-部署"><a href="#2-2-部署" class="headerlink" title="2.2 部署"></a>2.2 部署</h2><p>我们以单个节点完成<code>victoriametrics</code>的部署，将 <code>vmagent</code>、<code>vmstorage</code>、<code>vmselect</code>、<code>vminsert</code>的二进制文件放到<code>/usr/local/bin</code>目录下。</p><p>我们通过<code>systemd</code>的形式分别启动这四个程序。</p><h3 id="vmstorage-配置"><a href="#vmstorage-配置" class="headerlink" title="vmstorage 配置"></a>vmstorage 配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># /usr/lib/systemd/system/vmstorage.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=vmstorage</span><br><span class="line">Documentation=https://docs.victoriametrics.com/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/local/bin/vmstorage-prod \</span><br><span class="line">  -retentionPeriod=1d \</span><br><span class="line">  -storageDataPath=/root/victoriametrics/data</span><br><span class="line">Restart=on-failure</span><br><span class="line">User=root</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>这里主要给服务添加了两个参数，分别是<code>retentionPeriod</code>和 <code>storageDataPath</code>参数，分别代表数据保留周期和数据存储路径。在服务启动后，我们可以一下服务的端口占用:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ss -anltp | grep vmstorage</span><br><span class="line">LISTEN 0      4096         0.0.0.0:8482       0.0.0.0:*    users:((&quot;vmstorage-prod&quot;,pid=2247,fd=11))</span><br><span class="line">LISTEN 0      4096         0.0.0.0:8400       0.0.0.0:*    users:((&quot;vmstorage-prod&quot;,pid=2247,fd=9))</span><br><span class="line">LISTEN 0      4096         0.0.0.0:8401       0.0.0.0:*    users:((&quot;vmstorage-prod&quot;,pid=2247,fd=10))</span><br></pre></td></tr></table></figure><p>服务默认占用了三个端口，其中 8400 和 8401 端口分别是用于接受 <code>vminsert</code> 和 <code>vmselect</code>请求的端口，可以通过参数控制:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-vminsertAddr string</span><br><span class="line">    TCP address to accept connections from vminsert services (default &quot;:8400&quot;)</span><br><span class="line">-vmselectAddr string</span><br><span class="line">    TCP address to accept connections from vmselect services (default &quot;:8401&quot;)</span><br></pre></td></tr></table></figure><h3 id="vminsert-配置"><a href="#vminsert-配置" class="headerlink" title="vminsert 配置"></a>vminsert 配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># /usr/lib/systemd/system/vminsert.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=vminsert</span><br><span class="line">Documentation=https://docs.victoriametrics.com/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/local/bin/vminsert-prod \</span><br><span class="line">  -storageNode=192.168.141.129:8400</span><br><span class="line">Restart=on-failure</span><br><span class="line">User=root</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>这里给服务只配置了一个参数:<code>storageNode</code>指定了存储节点。</p><p>这里引申出一个问题，假如我有多个sotrage 节点应该如何配置呢？数据又是如何存储的？</p><p>其实在上文中，我们介绍vminsert 组件的时候就已经提示过:<code>accepts the ingested data and spreads it among vmstorage nodes according to consistent hashing over metric name and all its labels</code>。也就是说当我们有多个 storage 节点的时候，数据会分布在多个节点上。那这样一来就会有个很明显的问题，一旦节点宕机异常等，就会导致数据丢失或者无法查询等情况，为此就需要有数据复制机制,<code>vminsert</code>提供了<code>-replicationFactor</code>参数，用于控制数据复制来保证可用性。</p><h3 id="vmselect配置"><a href="#vmselect配置" class="headerlink" title="vmselect配置"></a>vmselect配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># /usr/lib/systemd/system/vmselect.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=vmselect</span><br><span class="line">Documentation=https://docs.victoriametrics.com/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/local/bin/vmselect-prod \</span><br><span class="line">  -storageNode=192.168.141.129:8401</span><br><span class="line">Restart=on-failure</span><br><span class="line">User=root</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>这里也是指定了存储节点的 8401端口</p><h3 id="vmagent配置"><a href="#vmagent配置" class="headerlink" title="vmagent配置"></a>vmagent配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># /usr/lib/systemd/system/vmagent.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=vmagent</span><br><span class="line">Documentation=https://docs.victoriametrics.com/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/local/bin/vmagent-prod \</span><br><span class="line">  -promscrape.config=/root/prometheus/prometheus/config/vm.yml \</span><br><span class="line">  -remoteWrite.url=http://192.168.141.129:8480/insert/0/prometheus/</span><br><span class="line">Restart=on-failure</span><br><span class="line">User=root</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>需要指定配置文件和写入的 url。这里的配置文件类似于<code>prometheus</code>的配置文件，我这里采集的的是<code>node_exporter</code>的指标:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">15s</span>  <span class="comment"># 每 15 秒采集一次</span></span><br><span class="line">  <span class="attr">scrape_timeout:</span> <span class="string">10s</span>   <span class="comment"># 超时时间 10 秒</span></span><br><span class="line"></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;node_exporter&#x27;</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9100&#x27;</span>]  <span class="comment"># 采集本地 node_exporter</span></span><br></pre></td></tr></table></figure><h3 id="2-3-启动"><a href="#2-3-启动" class="headerlink" title="2.3 启动"></a>2.3 启动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">systemctl daemon-reload</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">systemctl start vmagent vmselect vminsert vmstorage</span></span><br></pre></td></tr></table></figure><h2 id="2-4-监控查看"><a href="#2-4-监控查看" class="headerlink" title="2.4 监控查看"></a>2.4 监控查看</h2><p><a href="http://192.168.141.129:8481/select/0/">http://192.168.141.129:8481/select/0/</a> 可以通过这样的方式访问 vmui 进行监控指标的查询</p>]]></content>
    
    
    <summary type="html">A brief description of the content</summary>
    
    
    
    <category term="Technology" scheme="http://baixiaozhou.github.io/categories/Technology/"/>
    
    
    <category term="Programming" scheme="http://baixiaozhou.github.io/tags/Programming/"/>
    
    <category term="Hexo" scheme="http://baixiaozhou.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://baixiaozhou.github.io/p/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    <id>http://baixiaozhou.github.io/p/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/</id>
    <published>2025-02-18T02:23:06.804Z</published>
    <updated>2025-03-14T02:18:41.688Z</updated>
    
    <content type="html"><![CDATA[<h2 id="范松茂"><a href="#范松茂" class="headerlink" title="范松茂"></a>范松茂</h2><ol><li>linux 基础</li><li></li></ol><p>sudo mount -t nfs -o vers&#x3D;3,nolock,proto&#x3D;tcp,noresvport 10.0.128.122:&#x2F;cfs-7428apbf8z &#x2F;mnt</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;范松茂&quot;&gt;&lt;a href=&quot;#范松茂&quot; class=&quot;headerlink&quot; title=&quot;范松茂&quot;&gt;&lt;/a&gt;范松茂&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;linux 基础&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;sudo mount -t nfs -o vers&amp;#</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Linux知识库总结</title>
    <link href="http://baixiaozhou.github.io/p/Linux%E7%9F%A5%E8%AF%86%E5%BA%93%E6%80%BB%E7%BB%93/"/>
    <id>http://baixiaozhou.github.io/p/Linux%E7%9F%A5%E8%AF%86%E5%BA%93%E6%80%BB%E7%BB%93/</id>
    <published>2025-02-07T06:48:48.000Z</published>
    <updated>2025-03-06T07:08:23.850Z</updated>
    
    <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a>Linux知识库总结</h1><p>This article was written by baixiaozhou on 1738910928000.</p><h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><p>集群线上稳定性维护</p><p>1月 1 号-6 月30 号每月 30号前完成一次月度集群巡检</p><p>1月 1 号-6 月30 号完成值班任务，解决线上告警问题，故障响应时间不超过30min</p><p>1月 1 号-6 月30 号无违反运维红线产生的故障</p><p>1月 1 号-6 月30 号参与 juicefs 集群监控运维</p><p>1月 1 号-6 月30 号参与 KFS 集群监控运维</p><p>1月 1 号-6 月30 号参与 KPFS 集群监控运维</p><p>1.31 号前完成中邮信源集群桶复制进程异常 GC 修复</p><p>2.30 号前完成戴尔上海集群、北京集群电池更换</p><p>产品稳定性及日常测试跟进</p><p>9 月 30 号前，接入内部集群性能测试，完成百 G 网卡集群性能测试</p><p>7 月 30 号前完成 Minimax 集群测试</p><p>部署工具升级优化，自动化开发</p><p>6.30号前完成 KPFS 自动化部署</p><p>bogun 项目白屏化</p><p>6.30 号前初步完成 bogun 白屏化项目开发。</p><p>2025 1-6 月份 OKR</p><ol><li><p>集群线上稳定性维护<br>1月 1 号-6 月30 号每月 30号前完成一次月度集群巡检<br>1月 1 号-6 月30 号完成值班任务，解决线上告警问题，故障响应时间不超过30min<br>1月 1 号-6 月30 号无违反运维红线产生的故障<br>1月 1 号-6 月30 号参与 juicefs 集群监控运维<br>1月 1 号-6 月30 号参与 KFS 集群监控运维</p><p>1月 1 号-6 月30 号参与 KPFS 集群监控运维<br>1.31 号前完成中邮信源集群桶复制进程异常 GC 修复<br>2.30 号前完成戴尔上海集群、北京集群电池更换</p></li><li><p>部署工具升级优化，戴尔集群升级</p></li></ol><p>​6 月 30 号前完成 KPFS 部署工具开发</p><p>​6 月 30 前完成戴尔集群升级</p><ol start="3"><li>bogun 项目白屏化<br>6.30 号前初步完成 bogun 白屏化项目开发。</li></ol><p>面试问题</p><ol><li><p>Linux 基础</p><ol><li>基础命令的使用 （日志检查，基础命令）<ol><li><strong>如何查找一个命令或者文件的路径？</strong>（which，find，locate）</li><li>Linux 权限， 755&#x2F;700&#x2F;644 的区别</li><li>linux 文件类型</li><li><strong>如何切换到其他用户？（su 和 sudo 的区别）</strong></li><li>linux 网卡 bond 的模式</li><li><strong>Linux 软链接（symbolic link）和硬链接（hard link）的区别？</strong></li><li>日志查看， grep，awk，less，more，tail</li><li>简单脚本， 查看 nginx 日志中最近 10 行 200 请求的平均耗时情况，或者状态码出现的次数</li></ol></li><li>网络<ol><li>TCP 三次握手和四次挥手</li><li>如何查看端口占用 （netstat、ss 或者 lsof）</li><li>如何测试端口连通性（telnet 或者 nc）</li></ol></li><li>其他命令<ol><li>查看进程状态 （ps）</li><li>如何杀死进程 （kill -9， kill ，kill -15的区别）</li></ol></li></ol></li><li><p>监控</p><ol><li>常用的监控系统用过哪些（用过prometheus 就问一下 promql 语法， 列一下常用的）</li><li>常用的监控命令 （内存、cpu、负载、磁盘io 等）</li></ol></li><li><p>自动化工具 ansible 等</p><ol><li>剧本</li><li>标签</li><li>参数等</li></ol></li><li><p>数据库</p><ol><li>mysql 主从同步原理，配置</li><li>sql 语句的简单查询。group by 等</li></ol></li><li><p>K8s pod的启动过程中，k8s的各个组件是怎样互相调用的</p></li><li><p>docker 基础操作，挂载，docker-compose , 深入的话问一下 docker 技术底座，cgroup，文件系统，命名空间这些（作为一个加分项）</p></li><li><p>日志采集 elk 相关的，问一下 采集链路，分片规划啥的</p></li><li><p>问题排查</p><ol><li>系统故障如何排错，CPU 高、内存高、负载高的场景</li><li>日志查看，系统排错</li></ol><p>项目经验:</p><p>这个根据实际的项目展开询问，比如有 elk 日志等的就问相关的</p><p>开发能力，到时候就问一下基础的</p></li></ol><p>招行鲁班平台对接</p><p>命令行参数设置</p><p>kingyuctl –token xxx –endpoint xxx</p><p>–accesskey –id xxx show</p><p>–accesskey –id xxx enable xxx</p><p>–accesskey –id xxx disable xxx</p><p>–bucketquota </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通用验证函数（兼容所有切片类型）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ValidateSingleValue</span><span class="params">(name <span class="type">string</span>)</span></span> <span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(c *cli.Context, values <span class="keyword">interface</span>&#123;&#125;)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">        <span class="comment">// 通过反射获取值数量</span></span><br><span class="line">        v := reflect.ValueOf(values)</span><br><span class="line">        <span class="keyword">if</span> v.Kind() != reflect.Slice &#123;</span><br><span class="line">            <span class="keyword">return</span> fmt.Errorf(<span class="string">&quot;param &#x27;%s&#x27; is not a slice type&quot;</span>, name)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> v.Len() &gt; <span class="number">1</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> fmt.Errorf(<span class="string">&quot;param &#x27;%s&#x27; allows only one value&quot;</span>, name)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 类型特化包装器</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AsStringAction</span><span class="params">(fn <span class="keyword">interface</span>&#123;&#125;)</span></span> cli.ActionFunc &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(c *cli.Context, s []<span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> fn.(<span class="function"><span class="keyword">func</span><span class="params">(*cli.Context, <span class="keyword">interface</span>&#123;&#125;)</span></span> <span class="type">error</span>)(c, s)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AsIntAction</span><span class="params">(fn <span class="keyword">interface</span>&#123;&#125;)</span></span> cli.ActionFunc &#123; </span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(c *cli.Context, i []<span class="type">int</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> fn.(<span class="function"><span class="keyword">func</span><span class="params">(*cli.Context, <span class="keyword">interface</span>&#123;&#125;)</span></span> <span class="type">error</span>)(c, i)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用示例</span></span><br><span class="line">&amp;cli.StringSliceFlag&#123;</span><br><span class="line">    Name:   <span class="string">&quot;name&quot;</span>,</span><br><span class="line">    Action: AsStringAction(ValidateSingleValue(<span class="string">&quot;name&quot;</span>)),</span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line">&amp;cli.IntSliceFlag&#123;</span><br><span class="line">    Name:   <span class="string">&quot;count&quot;</span>,</span><br><span class="line">    Action: AsIntAction(ValidateSingleValue(<span class="string">&quot;count&quot;</span>)),</span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GOOS=linux GOARCH=amd64 <span class="keyword">go</span> build -trimpath -ldflags <span class="string">&quot;-s -w&quot;</span> -gcflags <span class="string">&quot;all=-trimpath=$PWD&quot;</span> -o kingyuctl</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">A brief description of the content</summary>
    
    
    
    <category term="Technology" scheme="http://baixiaozhou.github.io/categories/Technology/"/>
    
    
    <category term="Programming" scheme="http://baixiaozhou.github.io/tags/Programming/"/>
    
    <category term="Hexo" scheme="http://baixiaozhou.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus使用介绍</title>
    <link href="http://baixiaozhou.github.io/p/Prometheus%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"/>
    <id>http://baixiaozhou.github.io/p/Prometheus%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/</id>
    <published>2024-12-18T08:11:55.000Z</published>
    <updated>2024-12-26T06:57:56.037Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装请参考官网: https://prometheus.io/docs/prometheus/latest/installation/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载地址: https://prometheus.io/download/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">github地址: https://github.com/prometheus/prometheus</span></span><br></pre></td></tr></table></figure><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Prometheus 是一个开源的监控系统和告警工具包，用于收集和存储监控数据。它提供了强大的查询语言 PromQL，用于分析和可视化监控数据。Prometheus 可以与多种数据源集成，包括 Prometheus 自身、外部服务、数据库等。</p><p>下图是官方提供的架构图:<br><img src="https://prometheus.ac.cn/assets/architecture.png" alt="Prometheus architecture"></p><p>Prometheus 由多个组件组成，包括:</p><ul><li>Prometheus Server: 负责收集和存储监控数据，提供查询和聚合功能。</li><li>Alertmanager: 负责处理告警，包括分组、静默、抑制、静默规则等。</li><li>Pushgateway: 用于临时存储和转发监控数据的中间网关。</li><li>Exporter: 用于收集和导出监控数据的客户端。</li><li>Service discovery: 用于自动发现和配置监控数据的客户端。</li><li>Prometheus web UI: 用于查询和可视化监控数据的 Web 界面。</li></ul><h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><p>Prometheus 非常适合记录任何纯粹的数字时间序列。它既适合以机器为中心的监控，也适合监控高度动态的面向服务的体系结构。在微服务的世界中，它对多维数据收集和查询的支持是一个特别的优势。</p><p>Prometheus 旨在实现可靠性，成为您在出现故障时可以求助的系统，以便您可以快速诊断问题。每个 Prometheus 服务器都是独立的，不依赖于网络存储或其他远程服务。当您的基础设施的其他部分出现故障时，您可以依靠它，并且您不需要设置大量基础设施来使用它。</p><h2 id="不适用场景"><a href="#不适用场景" class="headerlink" title="不适用场景"></a>不适用场景</h2><p>Prometheus 重视可靠性。您始终可以查看有关系统的可用统计信息，即使在故障情况下也是如此。如果您需要 100% 的准确性，例如针对每个请求的计费，那么 Prometheus 不是一个好的选择，因为收集的数据可能不够详细和完整。在这种情况下，最好使用其他系统来收集和分析计费数据，并将 Prometheus 用于其他监控需求。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="解压安装包"><a href="#解压安装包" class="headerlink" title="解压安装包"></a>解压安装包</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@192 ~]# tar xzvf prometheus-3.0.1.linux-arm64.tar.gz</span><br><span class="line">[root@192 ~]# <span class="built_in">ls</span> prometheus-3.0.1.linux-arm64</span><br><span class="line">LICENSE  NOTICE  prometheus  prometheus.yml  promtool</span><br></pre></td></tr></table></figure><p>可以看到其中主要包含三个文件:</p><ul><li>promethues:  监控服务端</li><li>prometool:  监控工具</li><li>prometheus.yml:  配置文件</li></ul><h2 id="启动参数"><a href="#启动参数" class="headerlink" title="启动参数"></a>启动参数</h2><p>prometheus 启动参数，可以通过<code>prometheus -h</code>进行查看,支持参数的列表包括:</p><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><code>--config.file=&quot;prometheus.yml&quot;</code></td><td>配置 Prometheus 配置文件的路径。</td><td>无默认值</td><td><code>--config.file=&quot;prometheus.yml&quot;</code></td></tr><tr><td><code>--config.auto-reload-interval=30s</code></td><td>指定 Prometheus 检测配置文件变化并自动重载的间隔时间。</td><td>无默认值</td><td><code>--config.auto-reload-interval=30s</code></td></tr><tr><td><code>--web.listen-address=0.0.0.0:9090</code></td><td>配置 Prometheus 用于 UI、API 和遥测的监听地址。</td><td>无默认值</td><td><code>--web.listen-address=0.0.0.0:9090</code></td></tr><tr><td><code>--[no-]auto-gomaxprocs</code></td><td>自动设置 GOMAXPROCS 以匹配 Linux 容器的 CPU 配额。</td><td>默认开启</td><td><code>--auto-gomaxprocs</code></td></tr><tr><td><code>--[no-]auto-gomemlimit</code></td><td>自动设置 GOMEMLIMIT 以匹配 Linux 容器或系统内存限制。</td><td>默认开启</td><td><code>--auto-gomemlimit</code></td></tr><tr><td><code>--auto-gomemlimit.ratio=0.9</code></td><td>容器或系统内存的最大可用比例，决定内存限制的比例。</td><td><code>0.9</code></td><td><code>--auto-gomemlimit.ratio=0.8</code></td></tr><tr><td><code>--web.config.file=&quot;&quot;</code></td><td>[实验性] 配置文件的路径，可以启用 TLS 或认证。</td><td>无默认值</td><td><code>--web.config.file=&quot;web_config.yml&quot;</code></td></tr><tr><td><code>--web.read-timeout=5m</code></td><td>配置读取请求的最大超时时间，并关闭空闲连接。</td><td><code>5m</code></td><td><code>--web.read-timeout=10m</code></td></tr><tr><td><code>--web.max-connections=512</code></td><td>配置所有监听器的最大并发连接数。</td><td><code>512</code></td><td><code>--web.max-connections=1024</code></td></tr><tr><td><code>--web.max-notifications-subscribers=16</code></td><td>限制最大并发接收实时通知的订阅者数量。如果达到限制，新的订阅请求将被拒绝，直到现有连接关闭。</td><td><code>16</code></td><td><code>--web.max-notifications-subscribers=32</code></td></tr><tr><td><code>--web.external-url=&lt;URL&gt;</code></td><td>配置 Prometheus 在外部可访问的 URL 地址。例如，如果通过反向代理提供 Prometheus 服务时使用。该 URL 用于生成相对或绝对链接。</td><td>无默认值</td><td><code>--web.external-url=&quot;https://prometheus.example.com&quot;</code></td></tr><tr><td><code>--web.route-prefix=&lt;path&gt;</code></td><td>配置 Prometheus 内部路由的路径前缀。默认使用 <code>--web.external-url</code> 的路径部分。</td><td>无默认值</td><td><code>--web.route-prefix=&quot;/prometheus&quot;</code></td></tr><tr><td><code>--web.user-assets=&lt;path&gt;</code></td><td>配置静态资产目录路径，访问路径为 <code>/user</code>。</td><td>无默认值</td><td><code>--web.user-assets=&quot;/path/to/assets&quot;</code></td></tr><tr><td><code>--[no-]web.enable-lifecycle</code></td><td>启用通过 HTTP 请求来进行 Prometheus 的关闭和重载功能。</td><td>默认开启</td><td><code>--web.enable-lifecycle</code></td></tr><tr><td><code>--[no-]web.enable-admin-api</code></td><td>启用用于管理操作的 API 端点。</td><td>默认开启</td><td><code>--web.enable-admin-api</code></td></tr><tr><td><code>--[no-]web.enable-remote-write-receiver</code></td><td>启用接收远程写入请求的 API 端点。</td><td>默认开启</td><td><code>--web.enable-remote-write-receiver</code></td></tr><tr><td><code>--web.remote-write-receiver.accepted-protobuf-messages=prometheus.WriteRequest...</code></td><td>配置接受的远程写入的 Protobuf 消息类型。</td><td>默认开启</td><td><code>--web.remote-write-receiver.accepted-protobuf-messages=prometheus.WriteRequest</code></td></tr><tr><td><code>--[no-]web.enable-otlp-receiver</code></td><td>启用接收 OTLP 写入请求的 API 端点。</td><td>默认关闭</td><td><code>--web.enable-otlp-receiver</code></td></tr><tr><td><code>--web.console.templates=&quot;consoles&quot;</code></td><td>配置控制台模板目录路径，访问路径为 <code>/consoles</code>。</td><td>默认值为 <code>consoles</code></td><td><code>--web.console.templates=&quot;/path/to/templates&quot;</code></td></tr><tr><td><code>--web.console.libraries=&quot;console_libraries&quot;</code></td><td>配置控制台库目录路径。</td><td>默认值为 <code>console_libraries</code></td><td><code>--web.console.libraries=&quot;/path/to/libraries&quot;</code></td></tr><tr><td><code>--web.page-title=&quot;Prometheus Time Series Collection and Processing Server&quot;</code></td><td>配置 Prometheus 实例的文档标题。</td><td>默认值</td><td><code>--web.page-title=&quot;My Prometheus Server&quot;</code></td></tr><tr><td><code>--web.cors.origin=&quot;.*&quot;</code></td><td>配置 CORS 的源匹配规则，完全匹配的正则表达式。</td><td><code>.*</code></td><td><code>--web.cors.origin=&quot;https://example.com&quot;</code></td></tr><tr><td><code>--storage.tsdb.path=&quot;data/&quot;</code></td><td>配置 Prometheus 存储指标的基本路径。仅在服务器模式下使用。</td><td><code>data/</code></td><td><code>--storage.tsdb.path=&quot;/var/lib/prometheus/data&quot;</code></td></tr><tr><td><code>--storage.tsdb.retention.time=STORAGE.TSDB.RETENTION.TIME</code></td><td>配置指标存储的保留时间。</td><td>默认为 <code>15d</code></td><td><code>--storage.tsdb.retention.time=&quot;30d&quot;</code></td></tr><tr><td><code>--storage.tsdb.retention.size=STORAGE.TSDB.RETENTION.SIZE</code></td><td>配置指标存储的最大大小。</td><td>无默认值</td><td><code>--storage.tsdb.retention.size=&quot;500GB&quot;</code></td></tr><tr><td><code>--[no-]storage.tsdb.no-lockfile</code></td><td>禁止在数据目录中创建锁文件。</td><td>默认关闭</td><td><code>--storage.tsdb.no-lockfile</code></td></tr><tr><td><code>--storage.tsdb.head-chunks-write-queue-size=0</code></td><td>配置写入磁盘的队列大小，用于块的写入操作。实验性功能。</td><td><code>0</code></td><td><code>--storage.tsdb.head-chunks-write-queue-size=1024</code></td></tr><tr><td><code>--storage.agent.path=&quot;data-agent/&quot;</code></td><td>配置代理模式下指标存储的基本路径。</td><td><code>data-agent/</code></td><td><code>--storage.agent.path=&quot;/path/to/agent/data&quot;</code></td></tr><tr><td><code>--[no-]storage.agent.wal-compression</code></td><td>启用压缩代理 WAL（Write-Ahead Log）。</td><td>默认关闭</td><td><code>--storage.agent.wal-compression</code></td></tr><tr><td><code>--storage.agent.retention.min-time=STORAGE.AGENT.RETENTION.MIN-TIME</code></td><td>配置代理模式下指标数据的最小保留时间。</td><td>无默认值</td><td><code>--storage.agent.retention.min-time=&quot;1h&quot;</code></td></tr><tr><td><code>--storage.agent.retention.max-time=STORAGE.AGENT.RETENTION.MAX-TIME</code></td><td>配置代理模式下指标数据的最大保留时间。</td><td>无默认值</td><td><code>--storage.agent.retention.max-time=&quot;24h&quot;</code></td></tr><tr><td><code>--[no-]storage.agent.no-lockfile</code></td><td>禁止在代理模式下创建数据目录中的锁文件。</td><td>默认关闭</td><td><code>--storage.agent.no-lockfile</code></td></tr><tr><td><code>--storage.remote.flush-deadline=&lt;duration&gt;</code></td><td>配置在关闭或配置重载时等待刷新样本的最大时限。</td><td>无默认值</td><td><code>--storage.remote.flush-deadline=&quot;2m&quot;</code></td></tr><tr><td><code>--storage.remote.read-sample-limit=5e7</code></td><td>配置远程读取接口中每个查询能返回的最大样本数。</td><td><code>5e7</code></td><td><code>--storage.remote.read-sample-limit=1000000</code></td></tr><tr><td><code>--storage.remote.read-concurrent-limit=10</code></td><td>配置并发远程读取调用的最大数量。</td><td><code>10</code></td><td><code>--storage.remote.read-concurrent-limit=20</code></td></tr><tr><td><code>--storage.remote.read-max-bytes-in-frame=1048576</code></td><td>配置每个远程读取响应中每帧的最大字节数。</td><td><code>1048576</code></td><td><code>--storage.remote.read-max-bytes-in-frame=2048000</code></td></tr><tr><td><code>--rules.alert.for-outage-tolerance=1h</code></td><td>配置 Prometheus 停机恢复期间容忍的最大时间。</td><td></td><td></td></tr></tbody></table><h2 id="配置文件参数"><a href="#配置文件参数" class="headerlink" title="配置文件参数"></a>配置文件参数</h2><p>我们可以看一下配置文件默认的内容:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># my global config </span></span><br><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">15s</span> <span class="comment"># Set the scrape interval to every 15 seconds. Default is every 1 minute.</span></span><br><span class="line">  <span class="attr">evaluation_interval:</span> <span class="string">15s</span> <span class="comment"># Evaluate rules every 15 seconds. The default is every 1 minute.</span></span><br><span class="line">  <span class="comment"># scrape_timeout is set to the global default (10s).</span></span><br><span class="line"><span class="comment"># Alertmanager configuration</span></span><br><span class="line"><span class="attr">alerting:</span></span><br><span class="line">  <span class="attr">alertmanagers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">static_configs:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">targets:</span></span><br><span class="line">          <span class="comment"># - alertmanager:9093</span></span><br><span class="line"><span class="comment"># Load rules once and periodically evaluate them according to the global &#x27;evaluation_interval&#x27;.</span></span><br><span class="line"><span class="attr">rule_files:</span></span><br><span class="line">  <span class="comment"># - &quot;first_rules.yml&quot;</span></span><br><span class="line">  <span class="comment"># - &quot;second_rules.yml&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A scrape configuration containing exactly one endpoint to scrape:</span></span><br><span class="line"><span class="comment"># Here it&#x27;s Prometheus itself.</span></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="comment"># The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&quot;prometheus&quot;</span></span><br><span class="line">    <span class="comment"># metrics_path defaults to &#x27;/metrics&#x27;</span></span><br><span class="line">    <span class="comment"># scheme defaults to &#x27;http&#x27;.</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;localhost:9090&quot;</span>]</span><br></pre></td></tr></table></figure><p>在配置文件中我们可以看到有多个配置块: global、alerting、rule_files、scrape_configs。 除此之外，还支持其他配置块信息，示例如下:</p><h3 id="global-全局配置"><a href="#global-全局配置" class="headerlink" title="global 全局配置"></a>global 全局配置</h3><p>在 <code>global</code> 配置块中，我们可以定义全局的配置参数，这些参数将应用于所有的抓取任务。以下是一些常用的全局配置参数：</p><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><strong><code>scrape_interval</code></strong></td><td>定义 Prometheus 每次抓取目标的间隔时间。</td><td><code>1m</code></td><td><code>15s</code>（每 15 秒抓取一次）</td></tr><tr><td><strong><code>scrape_timeout</code></strong></td><td>定义每次抓取任务的最大超时时间。如果在这个时间内没有得到响应，则认为抓取失败。</td><td><code>10s</code></td><td><code>30s</code>（每个抓取任务最多等待 30 秒）</td></tr><tr><td><strong><code>scrape_protocols</code></strong></td><td>配置抓取时与目标通信的协议。支持以下协议：<code>PrometheusProto</code>、<code>OpenMetricsText0.0.1</code>、<code>OpenMetricsText1.0.0</code>、<code>PrometheusText0.0.4</code>。</td><td>默认值为 <code>[OpenMetricsText1.0.0, OpenMetricsText0.0.1, PrometheusText0.0.4]</code></td><td><code>PrometheusProto, OpenMetricsText1.0.0</code></td></tr><tr><td><strong><code>evaluation_interval</code></strong></td><td>定义 Prometheus 用来评估告警规则的频率。</td><td><code>1m</code></td><td><code>30s</code>（每 30 秒评估一次规则）</td></tr><tr><td><strong><code>rule_query_offset</code></strong></td><td>偏移告警规则评估的时间戳，指定一个延迟时间，确保基础指标在评估前已被抓取。如果启用远程写入或抓取有延迟，可能需要设置此项。</td><td><code>0s</code></td><td><code>10s</code>（向后延迟 10 秒评估规则）</td></tr><tr><td><strong><code>external_labels</code></strong></td><td>向 Prometheus 中的时间序列和告警添加标签，这些标签会在与外部系统（如 Alertmanager、远程存储、联邦等）通信时附加。</td><td>无默认值</td><td><code>monitor: &#39;main-monitor&#39;</code></td></tr><tr><td><strong><code>query_log_file</code></strong></td><td>配置文件中指定的 PromQL 查询日志文件的路径，用于记录所有 PromQL 查询。重新加载配置文件时会重新打开该文件。</td><td>无默认值</td><td><code>/var/log/prometheus/query.log</code></td></tr><tr><td><strong><code>body_size_limit</code></strong></td><td>抓取请求的响应体大小限制。如果响应体超过此大小，则抓取会失败。0 表示没有限制。</td><td><code>0</code>（无大小限制）</td><td><code>100MB</code>（限制为 100MB）</td></tr><tr><td><strong><code>sample_limit</code></strong></td><td>每次抓取中允许的最大样本数。如果在指标重标签后样本数超过此值，则该抓取任务会被视为失败。 0 表示无限制。</td><td><code>0</code>（无限制）</td><td><code>10000</code>（最多 10000 个样本）</td></tr><tr><td><strong><code>label_limit</code></strong></td><td>每个抓取任务允许的最大标签数量。如果标签数量超过此值，抓取会失败。 0 表示没有限制。</td><td><code>0</code>（无限制）</td><td><code>1000</code>（最多 1000 个标签）</td></tr><tr><td><strong><code>label_name_length_limit</code></strong></td><td>每个标签名称的最大长度。如果标签名称超过此值，抓取会失败。0 表示没有限制。</td><td><code>0</code>（无限制）</td><td><code>50</code>（标签名称最多 50 个字符）</td></tr><tr><td><strong><code>label_value_length_limit</code></strong></td><td>每个标签值的最大长度。如果标签值超过此值，抓取会失败。0 表示没有限制。</td><td><code>0</code>（无限制）</td><td><code>200</code>（标签值最多 200 个字符）</td></tr><tr><td><strong><code>target_limit</code></strong></td><td>每个抓取任务允许的目标数量的最大值。如果目标数量超过此限制，Prometheus 会标记这些目标为失败并不进行抓取。 0 表示没有限制。</td><td><code>0</code>（无限制）</td><td><code>100</code>（最多 100 个目标）</td></tr><tr><td><strong><code>keep_dropped_targets</code></strong></td><td>限制在目标重标签过程中被丢弃的目标数量，控制被丢弃的目标在内存中的保存数量。0 表示没有限制。</td><td><code>0</code>（无限制）</td><td><code>50</code>（最多保留 50 个被丢弃的目标）</td></tr></tbody></table><h3 id="alerting-告警配置项"><a href="#alerting-告警配置项" class="headerlink" title="alerting 告警配置项"></a>alerting 告警配置项</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><strong><code>alert_relabel_configs</code></strong></td><td>用于定义告警标签重写规则。告警标签重写允许你修改告警的标签，以适应 Alertmanager 或其他系统的要求。</td><td>无默认值</td><td><code>- source_labels: [alertname]</code><br><code>target_label: severity</code></td></tr><tr><td><strong><code>alertmanagers</code></strong></td><td>定义 Alertmanager 配置，用于指定 Prometheus 向哪些 Alertmanager 实例发送告警。</td><td>无默认值</td><td><code>- static_configs:</code><br><code>    - targets: [&#39;alertmanager:9093&#39;]</code></td></tr></tbody></table><h3 id="rule-files-告警规则文件配置项"><a href="#rule-files-告警规则文件配置项" class="headerlink" title="rule_files 告警规则文件配置项"></a>rule_files 告警规则文件配置项</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><strong><code>rule_files</code></strong></td><td>定义一个包含告警规则的文件路径列表。所有匹配的文件将被读取并加载规则和告警。</td><td>无默认值</td><td><code>- &#39;alert_rules.yml&#39;</code><br><code>- &#39;other_rules/*.yml&#39;</code></td></tr></tbody></table><h3 id="scrape-config-files-指标配置文件"><a href="#scrape-config-files-指标配置文件" class="headerlink" title="scrape_config_files 指标配置文件"></a>scrape_config_files 指标配置文件</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><strong><code>scrape_config_files</code></strong></td><td>指定一个或多个文件路径或路径模式，用于加载抓取配置文件。所有匹配的文件将被读取并应用到抓取配置。</td><td>无默认值</td><td><code>- &#39;scrape_configs/*.yml&#39;</code><br><code>- &#39;custom_scrape_config.yml&#39;</code></td></tr></tbody></table><h3 id="scrape-configs-指标配置"><a href="#scrape-configs-指标配置" class="headerlink" title="scrape_configs 指标配置"></a>scrape_configs 指标配置</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><strong><code>scrape_configs</code></strong></td><td>定义一个或多个抓取配置项，用于设置 Prometheus 如何抓取目标。支持多个抓取配置。</td><td>无默认值</td><td><code>- job_name: &#39;node_exporter&#39;</code><br><code>  static_configs: [ &#123; targets: [&#39;localhost:9100&#39;] &#125; ]</code></td></tr></tbody></table><h3 id="remote-write-远程写入"><a href="#remote-write-远程写入" class="headerlink" title="remote_write 远程写入"></a>remote_write 远程写入</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><strong><code>remote_write</code></strong></td><td>配置远程写入功能，将数据写入远程存储系统。可以配置多个远程写入目标。</td><td>无默认值</td><td><code>- url: &#39;http://remote-storage/receive&#39;</code><br><code>  write_relabel_configs: [...]</code></td></tr></tbody></table><h3 id="remote-read-远程读取"><a href="#remote-read-远程读取" class="headerlink" title="remote_read 远程读取"></a>remote_read 远程读取</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><strong><code>remote_read</code></strong></td><td>配置远程读取功能，从远程存储系统读取数据。可以配置多个远程读取目标。</td><td>无默认值</td><td><code>- url: &#39;http://remote-storage/read&#39;</code><br><code>  read_relabel_configs: [...]</code></td></tr></tbody></table><h3 id="storage-存储"><a href="#storage-存储" class="headerlink" title="storage 存储"></a>storage 存储</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><strong><code>tsdb</code></strong></td><td>配置时间序列数据库（TSDB）的设置，用于存储 Prometheus 采集的数据。</td><td>无默认值</td><td><code>max_samples_per_tsdb_block: 1000000</code><br><code>  retention: &#39;30d&#39;</code></td></tr><tr><td><strong><code>exemplars</code></strong></td><td>配置用于存储示例数据的相关设置。示例数据用于增强高卡诺图的分析，提供对数据点的详细追踪。</td><td>无默认值</td><td><code>enable: true</code><br><code>  retention: &#39;7d&#39;</code></td></tr></tbody></table><h3 id="tracing-跟踪"><a href="#tracing-跟踪" class="headerlink" title="tracing 跟踪"></a>tracing 跟踪</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th><th><strong>默认值</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td><strong><code>tracing</code></strong></td><td>配置与追踪系统集成的设置。用于将追踪数据导出到外部追踪系统（例如 Jaeger 或 Zipkin）。</td><td>无默认值</td><td><code>- provider: &#39;jaeger&#39;</code><br><code>  config:</code><br><code>    endpoint: &#39;http://jaeger:5775&#39;</code></td></tr></tbody></table><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@192 ~]# ./prometheus --config.file prometheus.yml</span><br></pre></td></tr></table></figure><p>也可以通过配置 <code>systemd service</code> 文件进行启动</p><p>Start.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">set -e</span><br><span class="line"></span><br><span class="line">ROOT=$(unset CDPATH &amp;&amp; cd &quot;$(dirname &quot;$&#123;BASH_SOURCE[0]&#125;&quot;)&quot; &amp;&amp; pwd)</span><br><span class="line">cd $ROOT</span><br><span class="line"></span><br><span class="line">exec $ROOT/prometheus \</span><br><span class="line">    --config.file &quot;prometheus.yml&quot; \</span><br><span class="line">    --web.listen-address &quot;0.0.0.0:9080&quot; \</span><br><span class="line">    --web.enable-lifecycle \</span><br><span class="line">    --web.enable-admin-api \</span><br><span class="line">    --query.max-concurrency &quot;1000&quot; \</span><br><span class="line">    --query.timeout &quot;2m&quot; \</span><br><span class="line">    --storage.tsdb.retention.time &quot;12h&quot; \</span><br><span class="line">    --storage.tsdb.retention.size &quot;1GB&quot; \</span><br><span class="line">    --storage.tsdb.path &quot;/root/prometheus/prometheus/data&quot;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/usr/lib/systemd/system/prometheus.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Prometheus Monitoring System</span><br><span class="line">Documentation=https://prometheus.io/docs/introduction/overview/</span><br><span class="line">Wants=network-online.target</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/root/prometheus/prometheus/start.sh</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><h1 id="接入exporter"><a href="#接入exporter" class="headerlink" title="接入exporter"></a>接入exporter</h1><p>exporter 是一个收集指标的程序，Prometheus 服务器通过抓取这些指标数据来监控目标系统。Prometheus 提供了丰富的 exporter，用于监控各种系统和服务。例如，用于监控 Linux 系统的 <code>node_exporter</code>、用于监控 MySQL 数据库的 <code>mysqld_exporter</code>、用于监控 Redis 数据库的 <code>redis_exporter</code> 等。此外，用户还可以编写自己的 exporter 来监控其他系统和服务。</p><p>常见 exporter 如下:</p><ul><li><a href="https://github.com/prometheus/node_exporter">node_exporter</a>：用于监控 Linux 系统。</li><li><a href="https://github.com/prometheus/mysqld_exporter">mysqld_exporter</a>：用于监控 MySQL 数据库。</li><li><a href="https://github.com/oliver006/redis_exporter">redis_exporter</a>：用于监控 Redis 数据库。</li><li><a href="https://github.com/prometheus/blackbox_exporter">blackbox_exporter</a>：用于监控网络服务。</li><li><a href="https://github.com/nginxinc/nginx-prometheus-exporter">nginx_exporter</a>：用于监控 Nginx 服务器。</li><li><a href="https://github.com/ncabatoff/process-exporter">process_exporter</a>: 监控进程服务</li><li><a href="https://github.com/martin-helmich/prometheus-nginxlog-exporter">nginxlog_exporter</a>: 监控 nginx 日志</li><li>……</li></ul><p>我在本地启动了<code>node_exporter</code>、<code>process_exporter</code>、<code>nginxlog_exporter</code>，并将其配置到<code>prometheus.yml</code>中。<code>node_exporter</code>用于监控本地主机，<code>process_exporter</code>用于监控本地进程，<code>nginxlog_exporter</code>用于监控本地 nginx 日志。<code>prometheus.yml</code>配置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="comment"># The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&quot;prometheus&quot;</span></span><br><span class="line">    <span class="comment"># metrics_path defaults to &#x27;/metrics&#x27;</span></span><br><span class="line">    <span class="comment"># scheme defaults to &#x27;http&#x27;.</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;localhost:9090&quot;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&quot;node_exporter&quot;</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;localhost:9100&quot;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&quot;process_exporter&quot;</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;localhost:9256&quot;</span>]</span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&quot;nginxlog_exporter&quot;</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;localhost:9302&quot;</span>]</span><br></pre></td></tr></table></figure><p>指标接入后，我们就可以查看采集到的指标，当然也可以在通过对应端口查看<code>/metrics</code>信息。</p><h2 id="监控-docker"><a href="#监控-docker" class="headerlink" title="监控 docker"></a>监控 docker</h2><p>如果我们想监控 docker 容器中的指标，我们可以使用 <code>docker stats</code> 命令来查看容器的资源使用情况。例如，我们可以使用以下命令来查看所有正在运行的容器的资源使用情况：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@192 ~]# docker stats</span><br><span class="line">CONTAINER ID   NAME      CPU %     MEM USAGE / LIMIT    MEM %     NET I/O           BLOCK I/O         PIDS</span><br><span class="line">5e48f91da9cd   kibana    0.60%     281MiB / 1.42GiB     19.33%    1.95GB / 3.47GB   5.04GB / 1.06GB   19</span><br><span class="line">186c160bd03e   es        0.44%     401.8MiB / 1.42GiB   27.64%    3.5GB / 2.02GB    6.63GB / 43.6GB   93</span><br></pre></td></tr></table></figure><p>Docker 容器的监控方案有很多，除了 Docker 自带的docker stats命令，还有很多开源的解决方案，例如 sysdig、cAdvisor。</p><p>cAdvisor 是谷歌开源的一款通用的容器监控解决方案。cAdvisor 不仅可以采集机器上所有运行的容器信息，还提供了基础的查询界面和 HTTP 接口，更方便与外部系统结合。所以，cAdvisor很快成了容器指标监控最常用组件，并且 Kubernetes 也集成了 cAdvisor 作为容器监控指标的默认工具。我们这里通过 cAdvisor 来监控 docker 容器。</p><p>安装 cAdvisor</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ docker run \</span><br><span class="line">  --volume=/:/rootfs:ro \</span><br><span class="line">  --volume=/var/run:/var/run:ro \</span><br><span class="line">  --volume=/sys:/sys:ro \</span><br><span class="line">  --volume=/var/lib/docker/:/var/lib/docker:ro \</span><br><span class="line">  --volume=/dev/disk/:/dev/disk:ro \</span><br><span class="line">  --publish=8080:8080 \</span><br><span class="line">  --detach=<span class="literal">true</span> \</span><br><span class="line">  --name=cadvisor \</span><br><span class="line">  --privileged \</span><br><span class="line">  --device=/dev/kmsg \</span><br><span class="line">  swr.cn-north-4.myhuaweicloud.com/ddn-k8s/gcr.io/cadvisor/cadvisor-arm64:v0.49.1-linuxarm64</span><br><span class="line">  </span><br></pre></td></tr></table></figure><p>由于我个人环境是 arm 版本的，并且原始的源太慢，所以使用华为云的镜像。<br>安装完成后，可以通过 <code>http://localhost:8080</code> 访问 cAdvisor 的监控界面</p><h1 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h1><h2 id="查询语法"><a href="#查询语法" class="headerlink" title="查询语法"></a>查询语法</h2><p>Prometheus 的查询语法基于 <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/">PromQL</a>，PromQL 是一种用于在 Prometheus 中查询时间序列数据的查询语言。</p><p>promql 指标和语法请参考:<code>https://www.prometheus.wang/promql/</code></p><h2 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h2><p>部分内置函数:</p><table><thead><tr><th><strong>函数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td><code>avg()</code></td><td>计算一组时间序列的平均值。</td></tr><tr><td><code>avg_over_time()</code></td><td>计算指定时间范围内时间序列的平均值。例如，<code>avg_over_time(node_cpu_seconds_total[1h])</code> 计算过去一小时内的平均值。</td></tr><tr><td><code>max()</code></td><td>计算一组时间序列的最大值。</td></tr><tr><td><code>max_over_time()</code></td><td>计算指定时间范围内时间序列的最大值。</td></tr><tr><td><code>min()</code></td><td>计算一组时间序列的最小值。</td></tr><tr><td><code>min_over_time()</code></td><td>计算指定时间范围内时间序列的最小值。</td></tr><tr><td><code>sum()</code></td><td>计算一组时间序列的总和。</td></tr><tr><td><code>sum_over_time()</code></td><td>计算指定时间范围内时间序列的总和。</td></tr><tr><td><code>count()</code></td><td>计算一组时间序列的数量。</td></tr><tr><td><code>count_over_time()</code></td><td>计算指定时间范围内时间序列的数量。</td></tr><tr><td><code>rate()</code></td><td>计算速率（每秒变化的值），通常用于计数器类型的指标。例如，<code>rate(http_requests_total[5m])</code> 计算过去 5 分钟内的每秒请求数。</td></tr><tr><td><code>irate()</code></td><td>计算速率（每秒变化的值），但使用的是两个最近数据点的瞬时变化。通常用于更精确的速率计算。</td></tr><tr><td><code>histogram_quantile()</code></td><td>从直方图数据中计算分位数。</td></tr><tr><td><code>increase()</code></td><td>计算一个计数器在指定时间范围内的增加值。</td></tr><tr><td><code>delta()</code></td><td>计算时间序列在指定时间范围内的差值。</td></tr><tr><td><code>changes()</code></td><td>计算时间序列在指定时间范围内变化的次数。</td></tr><tr><td><code>label_replace()</code></td><td>替换标签值，支持正则表达式和替换功能。例如，<code>label_replace(metric, &quot;new_label&quot;, &quot;$1&quot;, &quot;label_name&quot;, &quot;(.*)&quot;)</code> 会将标签值根据正则进行替换。</td></tr><tr><td><code>clamp_max()</code></td><td>限制最大值，例如，<code>clamp_max(metric, 100)</code> 将 <code>metric</code> 的值限制在最大 100。</td></tr><tr><td><code>clamp_min()</code></td><td>限制最小值，例如，<code>clamp_min(metric, 0)</code> 将 <code>metric</code> 的值限制在最小 0。</td></tr><tr><td><code>avg_over_time()</code></td><td>计算给定时间窗口内的时间序列的平均值。例如，<code>avg_over_time(metric[1h])</code>。</td></tr><tr><td><code>stddev()</code></td><td>计算一组时间序列的标准差。</td></tr><tr><td><code>stddev_over_time()</code></td><td>计算给定时间范围内时间序列的标准差。</td></tr><tr><td><code>quantile_over_time()</code></td><td>计算给定时间范围内的时间序列的分位数。</td></tr><tr><td><code>topk()</code></td><td>返回排名前 <code>k</code> 的时间序列。</td></tr><tr><td><code>bottomk()</code></td><td>返回排名后 <code>k</code> 的时间序列。</td></tr><tr><td><code>sort()</code></td><td>对时间序列按值进行排序。</td></tr><tr><td><code>sort_desc()</code></td><td>对时间序列按值进行降序排序。</td></tr><tr><td><code>time()</code></td><td>返回当前时间戳，以秒为单位。</td></tr><tr><td><code>label_join()</code></td><td>将多个标签值合并成一个新的标签。</td></tr><tr><td><code>label_values()</code></td><td>返回指定标签的所有标签值。例如，<code>label_values(http_requests_total, job)</code> 会返回所有 <code>http_requests_total</code> 指标的 <code>job</code> 标签值。</td></tr><tr><td><code>idelta()</code></td><td>计算时间序列的瞬时变化，类似于 <code>rate()</code>，但适用于计数器和其他类型的时间序列。</td></tr><tr><td><code>avg_over_time()</code></td><td>计算时间序列在指定时间范围内的平均值。</td></tr><tr><td><code>reset()</code></td><td>重置某个计数器值，常用于重置函数的计算。</td></tr><tr><td><code>histogram_quantile()</code></td><td>根据直方图数据计算指定分位数。例如，<code>histogram_quantile(0.95, http_duration_seconds_bucket)</code> 计算 HTTP 请求响应时间的 95% 分位数。</td></tr><tr><td><code>increase()</code></td><td>计算计数器在时间范围内的增加量，适用于计数器类型的指标。</td></tr><tr><td><code>over_time()</code></td><td>计算时间序列在指定时间范围内的总值变化量。</td></tr><tr><td><code>count_values()</code></td><td>计算不同标签值的出现次数。例如，<code>count_values(&quot;status&quot;, http_requests_total)</code> 会返回不同 <code>status</code> 标签值的出现次数。</td></tr></tbody></table><h2 id="查询示例"><a href="#查询示例" class="headerlink" title="查询示例"></a>查询示例</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询机器负载</span></span><br><span class="line">node_load1/node_load5/node_load15</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询 CPU 使用率</span></span><br><span class="line">sum by (instance)(irate(node_cpu_seconds_total&#123;mode!=&quot;idle&quot;&#125;[1m])) / sum by (instance)(irate(node_cpu_seconds_total[1m]))</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看某个进程的CPU使用率</span> </span><br><span class="line">sum by (instance)(irate(namedprocess_namegroup_cpu_seconds_total&#123;groupname=&quot;sysstress&quot;&#125;[1m])) //该指标由 process_exporter 提供</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看某个进程的内存使用率</span></span><br><span class="line">sum by (groupname)(namedprocess_namegroup_memory_bytes&#123;groupname=&quot;sysstress&quot;&#125;)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以使用正则</span></span><br><span class="line">http_requests_total&#123;job=~&quot;.*server&quot;&#125;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">按照应用和进程类型来获取 CPU 利用率最高的 3 个样本数据：</span></span><br><span class="line">topk(3, sum(rate(instance_cpu_time_ns[5m])) by (app, proc))</span><br></pre></td></tr></table></figure><h1 id="告警配置"><a href="#告警配置" class="headerlink" title="告警配置"></a>告警配置</h1><p>告警规则允许基于 Prometheus 表达式语言表达式定义告警条件，并将有关触发告警的通知发送到外部服务。每当告警表达式在给定时间点产生一个或多个向量元素时，该告警即被视为针对这些元素的标签集处于活动状态。</p><h2 id="告警规则"><a href="#告警规则" class="headerlink" title="告警规则"></a>告警规则</h2><p>告警规则配置文件通常使用 YAML 编写，以固定的格式进行操作，下面是告警规则支持的参数:</p><table><thead><tr><th>参数名</th><th>类型</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td><code>alert</code></td><td>字符串</td><td>必须指定</td><td>告警名称，必须唯一。</td></tr><tr><td><code>expr</code></td><td>字符串</td><td>无</td><td>触发告警的 PromQL 表达式，表示监控指标的条件。</td></tr><tr><td><code>for</code></td><td>时间</td><td>无</td><td>触发告警前条件保持满足的时间。例如 <code>1m</code> 表示条件满足 1 分钟后才告警。</td></tr><tr><td><code>labels</code></td><td>字典</td><td>无</td><td>告警附加标签，通常用来标识告警的源，例如 <code>severity: critical</code>。</td></tr><tr><td><code>annotations</code></td><td>字典</td><td>无</td><td>告警附加信息，用于提供额外的上下文信息，如告警的描述和解决建议。</td></tr><tr><td><code>severity</code></td><td>字符串</td><td>无</td><td>自定义标签，用于指示告警的严重级别。例如 <code>critical</code>, <code>warning</code> 等。</td></tr><tr><td><code>summary</code></td><td>字符串</td><td>无</td><td>告警的简要描述，通常用于告警通知中。</td></tr><tr><td><code>description</code></td><td>字符串</td><td>无</td><td>告警的详细描述，通常用于告警通知中。</td></tr></tbody></table><p>其中，<code>annnotations</code> 下的附加信息是可以自定义的，例如 <code>summary</code> 和 <code>description</code>都是自定义的。如果需要，还可以添加其他自定义的标签</p><p>以下是一个简单的告警规则配置示例（rules&#x2F;alert.yml）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">groups:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">localhost</span> <span class="string">alert</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">alert:</span> <span class="string">HighLoad</span>           <span class="comment"># 告警名称</span></span><br><span class="line">    <span class="attr">expr:</span> <span class="string">node_load1</span> <span class="string">&gt;</span> <span class="number">1.5</span>    <span class="comment"># 触发告警的 PromQL 表达式</span></span><br><span class="line">    <span class="attr">for:</span> <span class="string">1m</span>                   <span class="comment"># 触发告警前条件保持满足的时间</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">severity:</span> <span class="string">critical</span>      <span class="comment"># 自定义标签</span></span><br><span class="line">      <span class="attr">resource:</span> <span class="string">node</span>          <span class="comment"># 自定义标签</span></span><br><span class="line">    <span class="attr">annotations:</span></span><br><span class="line">      <span class="attr">summary:</span> <span class="string">&quot;High load on <span class="template-variable">&#123;&#123; $labels.instance &#125;&#125;</span>&quot;</span> <span class="comment"># 告警的简要描述（自定义）</span></span><br><span class="line">      <span class="attr">description:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; $labels.instance &#125;&#125;</span> has a load average of <span class="template-variable">&#123;&#123; $value &#125;&#125;</span>&quot;</span> <span class="comment"># 告警的详细描述 (自定义)</span></span><br><span class="line">      <span class="attr">runbook_url:</span> <span class="string">https://baixiaozhou.github.io/p/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/</span> <span class="comment"># 告警处理文档 (自定义)</span></span><br><span class="line">      <span class="attr">recovery:</span> <span class="string">node_load1</span> <span class="string">&lt;</span> <span class="number">1.5</span> <span class="comment"># 恢复条件 (自定义)</span></span><br></pre></td></tr></table></figure><p>在 promethues 引用告警文件</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rule_files:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;rules/alert.yml&#x27;</span> <span class="comment"># 也可以使用通配，例如 rules/*.yml</span></span><br></pre></td></tr></table></figure><h2 id="告警通知"><a href="#告警通知" class="headerlink" title="告警通知"></a>告警通知</h2><p>alertmanager 用于接收prometheus 发出的告警并发送通知。它负责去重、分组和将告警路由到正确的接收器集成（email 等），还负责静默和抑制告警。</p><ol><li>分组:分组将性质相似的告警归类到一个通知中。这在大型故障期间尤其有用，因为此时许多系统会同时发生故障，可能会同时触发数百甚至数千个告警。<ul><li>示例：在您的集群中运行着数十或数百个服务实例，当网络分区发生时，一半的服务实例无法再访问数据库。Prometheus 中的告警规则被配置为在每个服务实例无法与数据库通信时发送告警。因此，会向 Alertmanager 发送数百个告警。</li><li>作为一个用户，您只想收到一个页面，但仍然能够看到哪些服务实例受到了影响。因此，您可以将 Alertmanager 配置为按其集群和告警名称对告警进行分组，以便它发送一个简化的通知。</li><li>告警的分组、分组通知的计时和这些通知的接收者是在配置文件中的路由树中配置的。</li></ul></li><li>抑制:抑制是指在某些其他告警已经触发的情况下抑制某些告警的通知。<ul><li>示例：一个告警正在触发，通知您整个集群不可访问。Alertmanager 可以配置为在该特定告警触发时静默有关该集群的所有其他告警。这将阻止发送与实际问题无关的数百或数千个触发告警的通知。</li><li>抑制是在 Alertmanager 的配置文件中配置的。</li></ul></li><li>静默:静默是一种简单的方法，可以将告警静默一段时间。静默是根据匹配器配置的，就像路由树一样。传入的告警会检查它们是否与活动静默的所有相等或正则表达式匹配器匹配。如果匹配，则不会为该告警发送任何通知。<ul><li>静默是在 Alertmanager 的 Web 界面中配置的。</li></ul></li></ol><p>告警通知配置文件通常使用 YAML 格式编写。以下是一个简单的告警通知配置示例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">smtp_smarthost:</span> <span class="string">&#x27;smtp.example.com:25&#x27;</span></span><br><span class="line">  <span class="attr">smtp_from:</span> <span class="string">&#x27;&lt;EMAIL&gt;&#x27;</span></span><br><span class="line">  <span class="attr">smtp_auth_username:</span> <span class="string">&#x27;&lt;EMAIL&gt;&#x27;</span></span><br><span class="line">  <span class="attr">smtp_auth_password:</span> <span class="string">&#x27;&lt;PASSWORD&gt;&#x27;</span></span><br><span class="line">  <span class="attr">smtp_require_tls:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="attr">route:</span></span><br><span class="line">  <span class="attr">group_by:</span> [<span class="string">&#x27;alertname&#x27;</span>]</span><br><span class="line">  <span class="attr">group_wait:</span> <span class="string">10s</span></span><br><span class="line">  <span class="attr">group_interval:</span> <span class="string">5m</span></span><br><span class="line">  <span class="attr">repeat_interval:</span> <span class="string">12h</span></span><br><span class="line">  <span class="attr">receiver:</span> <span class="string">&#x27;email&#x27;</span></span><br><span class="line"><span class="attr">receivers:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&#x27;email&#x27;</span></span><br><span class="line">  <span class="attr">email_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">to:</span> <span class="string">&#x27;&lt;EMAIL&gt;&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="长期存储方案对比"><a href="#长期存储方案对比" class="headerlink" title="长期存储方案对比"></a>长期存储方案对比</h1><p><a href="https://kubesphere.io/zh/blogs/prometheus-storage/">https://kubesphere.io/zh/blogs/prometheus-storage/</a></p>]]></content>
    
    
    <summary type="html">A brief description of the content</summary>
    
    
    
    <category term="Prometheus" scheme="http://baixiaozhou.github.io/categories/Prometheus/"/>
    
    <category term="监控方案" scheme="http://baixiaozhou.github.io/categories/Prometheus/%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88/"/>
    
    
    <category term="Programming" scheme="http://baixiaozhou.github.io/tags/Programming/"/>
    
    <category term="Hexo" scheme="http://baixiaozhou.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>ebpf系列教程(2) --工具集 bpftrace 使用介绍</title>
    <link href="http://baixiaozhou.github.io/p/ebpf%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B-2-%E5%B7%A5%E5%85%B7%E9%9B%86-bpftrace-%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"/>
    <id>http://baixiaozhou.github.io/p/ebpf%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B-2-%E5%B7%A5%E5%85%B7%E9%9B%86-bpftrace-%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/</id>
    <published>2024-11-19T08:14:59.000Z</published>
    <updated>2024-11-27T09:49:35.722Z</updated>
    
    <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a>ebpf系列教程(2) --工具集 bpftrace 使用介绍</h1><p>This article was written by baixiaozhou on 1732004099000.</p><!-- Your content starts here --><p>在阅读这篇文章之前，想先问大家一个技术问题: 如果监控进程的重启操作？比如我想通过监控下 nginx 的进程是否发生了重启，是否发生了 reload 操作？对于这类问题的思路有很多，比如:</p><ol><li>监控进程的 pid 变化情况</li><li>通过监控系统日志等来判断进程的变化情况。</li><li>…</li></ol><p>当然我们这里不讨论这些方法的优劣。我们不妨换个新的思路设想一下，进程的启停都会在内核中进行操作，假如说我们能够捕获到内核中的进程停止操作以及进程启动操作，类似于在内核中做一个 hook，当内核执行的时候自动触发，那我们是不是就能够直接获取到呢？带着这个疑问，我们来开始展开今天的文章。</p><h1 id="bpftrace-概述"><a href="#bpftrace-概述" class="headerlink" title="bpftrace 概述"></a>bpftrace 概述</h1><p>我们先看下bpftrace 官方的介绍(<a href="https://github.com/bpftrace/bpftrace">https://github.com/bpftrace/bpftrace</a>):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bpftrace is a high-level tracing language for Linux. bpftrace uses LLVM as a backend to compile scripts to eBPF-bytecode and makes use of libbpf and bcc for interacting with the Linux BPF subsystem, as well as existing Linux tracing capabilities: kernel dynamic tracing (kprobes), user-level dynamic tracing (uprobes), tracepoints, etc. The bpftrace language is inspired by awk, C, and predecessor tracers such as DTrace and SystemTap. </span><br></pre></td></tr></table></figure><p>简单来说，bpftrace 是一个基于 eBPF（Extended Berkeley Packet Filter）的高层次性能调试和故障排查工具。它通过提供简洁的脚本语言，简化了 eBPF 程序的编写，使开发者和系统管理员能够方便地监控系统行为、分析性能问题，以及调试应用程序。</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ol><li>强大的动态追踪能力：<ul><li>bpftrace利用eBPF技术，能够在不修改内核代码的情况下，实现对内核和应用程序的深度监控。</li><li>它集成了多种Linux追踪功能，如内核动态追踪（kprobes）、用户级动态追踪（uprobes）和tracepoints等，满足不同的追踪需求。</li></ul></li><li>高效的性能：<ul><li>bpftrace使用了eBPF技术来收集和处理跟踪数据，对系统性能的影响较小。</li><li>它通过LLVM作为后端编译器，将脚本编译为高效的BPF字节码，确保代码运行时的性能。</li></ul></li><li>简洁而强大的脚本语言：<ul><li>bpftrace的脚本语言设计简洁而强大，支持复杂的追踪逻辑和数据聚合。</li><li>它的语言设计灵感来源于awk、C语言以及如DTrace和SystemTap等先前的追踪工具，易于理解和编写。</li></ul></li><li>丰富的内置功能：<ul><li>bpftrace内置了许多实用的功能，如定时采样、直方图统计、聚合计数、调用栈跟踪等，可以轻松处理各种常见的跟踪需求。</li><li>它还支持条件过滤、聚合统计、函数调用、打印输出等操作，使得追踪和分析更加灵活和强大。</li></ul></li><li>广泛的应用场景：<ul><li>bpftrace适用于性能监控、故障诊断、安全审计、开发调试等多种场景。</li><li>它可以实时监控系统调用、磁盘I&#x2F;O、网络活动等，帮助开发者快速定位性能瓶颈和故障点。</li></ul></li><li>可扩展性：<ul><li>bpftrace支持借助eBPF技术进行动态追踪和事件捕获，这意味着它可以根据需要自定义和开发更高级的跟踪功能。</li></ul></li></ol><h1 id="bpftrace-安装"><a href="#bpftrace-安装" class="headerlink" title="bpftrace 安装"></a>bpftrace 安装</h1><p>现在很多的 linux 发行版已经内置了 bpftrace 模块，在安装前可以确定下是否已经内置:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@192 ~]# bpftrace -V</span><br><span class="line">bpftrace v0.12.1</span><br></pre></td></tr></table></figure><p>如果没有安装，那么需要手动安装，这里以 centos 为例进行安装,在安装前需要确定操作系统内核: 官方建议升级到 Linux4.9以及更高的内核，下面是内核版本迭代过程中增加的功能:</p><ul><li>4.1 - kprobes</li><li>4.3 - uprobes</li><li>4.6 - stack traces, count and hist builtins (use PERCPU maps for accuracy and efficiency)</li><li>4.7 - tracepoints</li><li>4.9 - timers&#x2F;profiling</li></ul><h2 id="yum-安装"><a href="#yum-安装" class="headerlink" title="yum 安装"></a>yum 安装</h2><p>根据官方提供的方法（<a href="https://github.com/fbs/el7-bpf-specs/blob/master/README.md#repository%EF%BC%89%EF%BC%8C%E9%80%9A%E8%BF%87">https://github.com/fbs/el7-bpf-specs/blob/master/README.md#repository），通过</a> yum 进行安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl https://repos.baslab.org/rhel/7/bpftools/bpftools.repo --output /etc/yum.repos.d/bpftools.repo</span><br><span class="line">yum install bpftrace bpftrace-tools bpftrace-doc bcc-static bcc-tools</span><br></pre></td></tr></table></figure><p>但是这个页面搜了下是 404 的，给的链接不靠谱。</p><p>在测试的过程中，我是安装了 centos8 进行操作的，实际操作过程中使用了阿里云的 yum 源</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@192 ~]# cd /etc/yum.repos.d</span><br><span class="line">[root@192 ~]# wget https://mirrors.aliyun.com/repo/Centos-8.repo</span><br><span class="line">[root@192 ~]# yum clean all</span><br><span class="line">[root@192 ~]# yum makecache</span><br><span class="line">[root@192 ~]# yum install -y bpftrace</span><br></pre></td></tr></table></figure><h2 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h2><p>编译安装，首先 clone 下bpftrace 的代码，进行操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:bpftrace/bpftrace.git</span><br><span class="line"><span class="built_in">cd</span> bpftrace</span><br></pre></td></tr></table></figure><p>进入之后，可以看到提供了编译脚本,因为 bpftrace 支持基于docker 进行编译，所以直接使用 docker 编译更为方便些，在编译前需要提前安装 docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y docker-ce docker-cli</span><br></pre></td></tr></table></figure><p>在实际测试过程中，我是以<code>0.11.1</code>分支为基础进行编译的:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@192 bpftrace]# git status</span><br><span class="line">头指针分离于 v0.11.1</span><br><span class="line">[root@192 bpftrace]./build.sh</span><br></pre></td></tr></table></figure><p>等待编译完成后，生成的可执行程序位于<code>./build-release/src/bpftrace</code>下，查看编译后的版本情况:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@192 bpftrace]# ./build-release/src/bpftrace -V</span><br><span class="line">bpftrace v0.11.1-dirty</span><br></pre></td></tr></table></figure><p>由于编译环境操作系统的差异，编译过程中可能会遇到各种问题，大家请自行解决;不过还是建议大家通过 yum 的形式进行安装</p><h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="探针-Probes"><a href="#探针-Probes" class="headerlink" title="探针 Probes"></a>探针 Probes</h3><p>探针是 bpftrace 的核心，用于定义事件触发，类似于事件的监控点，下面是bpftrace 提供的一些探针类型：<br><img src="/image.png" alt="alt text"></p><table><thead><tr><th>探针类型</th><th>描述</th></tr></thead><tbody><tr><td><strong>kprobe</strong></td><td>跟踪内核函数的入口点，监视内核函数调用。例如：<code>kprobe:sys_read</code>。</td></tr><tr><td><strong>kretprobe</strong></td><td>跟踪内核函数的返回点，监视内核函数调用的返回值。例如：<code>kretprobe:sys_read</code>。</td></tr><tr><td><strong>uprobe</strong></td><td>跟踪用户空间程序的入口点，监视用户进程中的函数调用。例如：<code>uprobe:/bin/bash:readline</code>。</td></tr><tr><td><strong>uretprobe</strong></td><td>跟踪用户空间程序的返回点，监视用户进程函数的返回值。例如：<code>uretprobe:/bin/bash:readline</code>。</td></tr><tr><td><strong>tracepoint</strong></td><td>监控内核中定义的静态跟踪点，提供更稳定的接口。例如：<code>tracepoint:syscalls:sys_enter_read</code>。</td></tr><tr><td><strong>usdt</strong></td><td>跟踪用户空间定义的静态探针（User-level Statically Defined Tracing）。例如：<code>usdt:/bin/bash:probe_name</code>。</td></tr><tr><td><strong>software</strong></td><td>跟踪软件事件，如上下文切换（<code>software:context_switches</code>）。</td></tr><tr><td><strong>hardware</strong></td><td>跟踪硬件事件，如 CPU 周期或指令计数（<code>hardware:cpu_cycles</code>）。</td></tr><tr><td><strong>profile</strong></td><td>定期采样的探针，用于分析程序的性能或热点（<code>profile:hz:100</code> 每秒触发 100 次）。</td></tr><tr><td><strong>interval</strong></td><td>按固定时间间隔触发的探针，通常用于周期性报告数据（<code>interval:s:1</code> 每秒触发一次）。</td></tr><tr><td><strong>BEGIN&#x2F;END</strong></td><td>bpftrace 脚本的特殊探针：<code>BEGIN</code> 在脚本启动时触发，<code>END</code> 在脚本结束时触发。</td></tr></tbody></table><h3 id="方法列表"><a href="#方法列表" class="headerlink" title="方法列表"></a>方法列表</h3><table><thead><tr><th><strong>函数名</strong></th><th><strong>描述</strong></th><th><strong>同步&#x2F;异步&#x2F;编译时</strong></th></tr></thead><tbody><tr><td><code>bswap(uint8\16\32\64 n)</code></td><td>反转字节顺序</td><td>同步</td></tr><tr><td><code>buf(void *d [, int length])</code></td><td>返回指针 <code>d</code> 指向的数据的十六进制格式字符串</td><td>同步</td></tr><tr><td><code>cat(char *filename)</code></td><td>打印文件内容</td><td>异步</td></tr><tr><td><code>cgroupid(char *path)</code></td><td>解析 CGroup ID</td><td>编译时</td></tr><tr><td><code>cgroup_path(int cgroupid, string filter)</code></td><td>将 CGroup ID 转换为 CGroup 路径</td><td>同步</td></tr><tr><td><code>exit([int code])</code></td><td>退出 bpftrace，支持可选退出码</td><td>异步</td></tr><tr><td><code>join(char *arr[] [, char *delim])</code></td><td>打印数组</td><td>异步</td></tr><tr><td><code>kaddr(char *name)</code></td><td>解析内核符号名</td><td>编译时</td></tr><tr><td><code>kptr(void *p)</code></td><td>将指针标记为内核空间指针</td><td>同步</td></tr><tr><td><code>kstack([StackMode mode, ][int level])</code></td><td>获取内核调用栈</td><td>同步</td></tr><tr><td><code>ksym(void *p)</code></td><td>解析内核地址</td><td>异步</td></tr><tr><td><code>macaddr(char[6] addr)</code></td><td>转换 MAC 地址数据</td><td>同步</td></tr><tr><td><code>nsecs([TimestampMode mode])</code></td><td>获取时间戳或时间差</td><td>同步</td></tr><tr><td><code>ntop([int af, ]int|char[4|16] addr)</code></td><td>将 IP 地址数据转换为文本</td><td>同步</td></tr><tr><td><code>offsetof(struct, element)</code></td><td>获取结构中元素的偏移量</td><td>编译时</td></tr><tr><td><code>override(u64 rc)</code></td><td>覆盖返回值</td><td>同步</td></tr><tr><td><code>path(struct path *path [, int32 size])</code></td><td>返回完整路径</td><td>同步</td></tr><tr><td><code>percpu_kaddr(const string name [, int cpu])</code></td><td>解析 per-CPU 内核符号名</td><td>同步</td></tr><tr><td><code>print(...)</code></td><td>打印非 map 类型的值，使用默认格式</td><td>异步</td></tr><tr><td><code>printf(char *fmt, ...)</code></td><td>格式化打印</td><td>异步</td></tr><tr><td><code>pton(const string *addr)</code></td><td>将文本 IP 地址转换为字节数组</td><td>编译时</td></tr><tr><td><code>reg(char *name)</code></td><td>返回指定寄存器中的值</td><td>同步</td></tr><tr><td><code>signal(char[] signal | u32 signal)</code></td><td>向当前进程发送信号</td><td>同步</td></tr><tr><td><code>sizeof(...)</code></td><td>返回类型或表达式的大小</td><td>同步</td></tr><tr><td><code>skboutput(const string p, struct sk_buff *s, ...)</code></td><td>将 <code>skb</code> 的数据部分写入 PCAP 文件</td><td>异步</td></tr><tr><td><code>str(char *s [, int length])</code></td><td>返回指针 <code>s</code> 指向的字符串</td><td>同步</td></tr><tr><td><code>strcontains(const char *haystack, const char *needle)</code></td><td>判断字符串 <code>haystack</code> 是否包含字符串 <code>needle</code></td><td>同步</td></tr><tr><td><code>strerror(uint64 error)</code></td><td>根据 errno 返回错误信息</td><td>同步</td></tr><tr><td><code>strftime(char *format, int nsecs)</code></td><td>返回格式化的时间戳</td><td>异步</td></tr><tr><td><code>strncmp(char *s1, char *s2, int length)</code></td><td>比较两个字符串的前 <code>n</code> 个字符</td><td>同步</td></tr><tr><td><code>system(char *fmt)</code></td><td>执行 Shell 命令</td><td>异步</td></tr><tr><td><code>time(char *fmt)</code></td><td>打印格式化时间</td><td>异步</td></tr><tr><td><code>uaddr(char *name)</code></td><td>解析用户态符号名</td><td>编译时</td></tr><tr><td><code>uptr(void *p)</code></td><td>将指针标记为用户空间指针</td><td>同步</td></tr><tr><td><code>ustack([StackMode mode, ][int level])</code></td><td>获取用户态调用栈</td><td>同步</td></tr><tr><td><code>usym(void *p)</code></td><td>解析用户空间地址</td><td>异步</td></tr></tbody></table><h3 id="内置变量"><a href="#内置变量" class="headerlink" title="内置变量"></a>内置变量</h3><p>内置变量是语言中内置的特殊变量。与暂存和映射变量不同，它们不需要 $ 或 @ 作为前缀（位置参数除外）。 “Kernel”列指示所需的最低内核版本，“BPF Helper”列指示用于此内置函数的原始 BPF 帮助器函数。</p><table><thead><tr><th><strong>变量名</strong></th><th><strong>类型</strong></th><th><strong>Kernel</strong></th><th><strong>BPF Helper</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td><code>$1, $2, …​$n</code></td><td><code>int64</code></td><td>n&#x2F;a</td><td>n&#x2F;a</td><td>传递给 bpftrace 程序的第 n 个位置参数。如果传递的参数少于 n，则值为 0。对于字符串参数，使用 <code>str()</code> 调用获取值。</td></tr><tr><td><code>$#</code></td><td><code>int64</code></td><td>n&#x2F;a</td><td>n&#x2F;a</td><td>传递的总位置参数数量。</td></tr><tr><td><code>arg0, arg1, …​argn</code></td><td><code>int64</code></td><td>n&#x2F;a</td><td>n&#x2F;a</td><td>被跟踪函数的第 n 个参数。这些参数从 CPU 寄存器中提取。寄存器中传递的参数数量取决于 CPU 架构（适用于 kprobes、uprobes、usdt）。</td></tr><tr><td><code>args</code></td><td><code>struct args</code></td><td>n&#x2F;a</td><td>n&#x2F;a</td><td>跟踪函数的所有参数结构体。在 tracepoint、fentry、fexit 和带有 DWARF 的 uprobe 探针中可用。使用 <code>args.x</code> 访问参数 x，或使用 <code>args</code> 获取包含所有参数的结构体。</td></tr><tr><td><code>cgroup</code></td><td><code>uint64</code></td><td>4.18</td><td><code>get_current_cgroup_id</code></td><td>当前进程所属的 cgroup ID，仅适用于 cgroupv2。</td></tr><tr><td><code>comm</code></td><td><code>string[16]</code></td><td>4.2</td><td><code>get_current_comm</code></td><td>当前线程的名称。</td></tr><tr><td><code>cpid</code></td><td><code>uint32</code></td><td>n&#x2F;a</td><td>n&#x2F;a</td><td>如果使用 <code>-c</code> 选项调用 bpftrace，则为子进程 ID。</td></tr><tr><td><code>cpu</code></td><td><code>uint32</code></td><td>4.1</td><td><code>raw_smp_processor_id</code></td><td>正在执行 BPF 程序的处理器 ID。</td></tr><tr><td><code>curtask</code></td><td><code>uint64</code></td><td>4.8</td><td><code>get_current_task</code></td><td>指向当前任务的 <code>struct task_struct</code> 指针。</td></tr><tr><td><code>elapsed</code></td><td><code>uint64</code></td><td>(见 nsec)</td><td><code>ktime_get_ns / ktime_get_boot_ns</code></td><td>自 bpftrace 初始化以来经过的纳秒数，基于 nsecs。</td></tr><tr><td><code>func</code></td><td><code>string</code></td><td>n&#x2F;a</td><td>n&#x2F;a</td><td>当前被跟踪函数的名称（适用于 kprobes 和 uprobes）。</td></tr><tr><td><code>gid</code></td><td><code>uint64</code></td><td>4.2</td><td><code>get_current_uid_gid</code></td><td>当前线程的组 ID（以初始命名空间视角）。</td></tr><tr><td><code>jiffies</code></td><td><code>uint64</code></td><td>5.9</td><td><code>get_jiffies_64</code></td><td>内核的 jiffies。在 32 位系统中，使用该内置变量可能较慢。</td></tr><tr><td><code>numaid</code></td><td><code>uint32</code></td><td>5.8</td><td><code>numa_node_id</code></td><td>执行 BPF 程序的 NUMA 节点 ID。</td></tr><tr><td><code>pid</code></td><td><code>uint32</code></td><td>4.2</td><td><code>get_current_pid_tgid</code></td><td>当前线程的进程 ID（即线程组 ID），以初始命名空间视角。</td></tr><tr><td><code>probe</code></td><td><code>string</code></td><td>n&#x2F;a</td><td>n&#x2F;a</td><td>当前探针的名称。</td></tr><tr><td><code>rand</code></td><td><code>uint32</code></td><td>4.1</td><td><code>get_prandom_u32</code></td><td>随机数。</td></tr><tr><td><code>return</code></td><td>n&#x2F;a</td><td>n&#x2F;a</td><td>n&#x2F;a</td><td><code>return</code> 关键字用于退出当前探针，与 <code>exit()</code> 不同，它不会退出 bpftrace。</td></tr><tr><td><code>retval</code></td><td><code>int64</code></td><td>n&#x2F;a</td><td>n&#x2F;a</td><td>被跟踪函数的返回值（适用于 kretprobe、uretprobe、fexit）。</td></tr><tr><td><code>tid</code></td><td><code>uint32</code></td><td>4.2</td><td><code>get_current_pid_tgid</code></td><td>当前线程的线程 ID，以初始命名空间视角。</td></tr><tr><td><code>uid</code></td><td><code>uint64</code></td><td>4.2</td><td><code>get_current_uid_gid</code></td><td>当前线程的用户 ID，以初始命名空间视角。</td></tr></tbody></table><h2 id="命令帮助"><a href="#命令帮助" class="headerlink" title="命令帮助"></a>命令帮助</h2><p>在使用前，我们先查看下 bpftrace 命令的帮助(用 <code>man bpftrace</code> 可以看到更全的信息):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@192 ~]# bpftrace -h</span><br><span class="line">USAGE:</span><br><span class="line">    bpftrace [options] filename</span><br><span class="line">    bpftrace [options] - &lt;stdin input&gt;</span><br><span class="line">    bpftrace [options] -e <span class="string">&#x27;program&#x27;</span></span><br><span class="line"></span><br><span class="line">OPTIONS:</span><br><span class="line">    -B MODE        output buffering mode (<span class="string">&#x27;full&#x27;</span>, <span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">    -f FORMAT      output format (<span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;json&#x27;</span>)</span><br><span class="line">    -o file        redirect bpftrace output to file</span><br><span class="line">    -d             debug info dry run</span><br><span class="line">    -<span class="built_in">dd</span>            verbose debug info dry run</span><br><span class="line">    -e <span class="string">&#x27;program&#x27;</span>   execute this program</span><br><span class="line">    -h, --<span class="built_in">help</span>     show this <span class="built_in">help</span> message</span><br><span class="line">    -I DIR         add the directory to the include search path</span><br><span class="line">    --include FILE add an <span class="comment">#include file before preprocessing</span></span><br><span class="line">    -l [search]    list probes</span><br><span class="line">    -p PID         <span class="built_in">enable</span> USDT probes on PID</span><br><span class="line">    -c <span class="string">&#x27;CMD&#x27;</span>       run CMD and <span class="built_in">enable</span> USDT probes on resulting process</span><br><span class="line">    --usdt-file-activation</span><br><span class="line">                   activate usdt semaphores based on file path</span><br><span class="line">    --unsafe       allow unsafe <span class="built_in">builtin</span> <span class="built_in">functions</span></span><br><span class="line">    -q             keep messages quiet</span><br><span class="line">    -v             verbose messages</span><br><span class="line">    --info         Print information about kernel BPF support</span><br><span class="line">    -k             emit a warning when a bpf helper returns an error (except <span class="built_in">read</span> <span class="built_in">functions</span>)</span><br><span class="line">    -kk            check all bpf helper <span class="built_in">functions</span></span><br><span class="line">    -V, --version  bpftrace version</span><br><span class="line">    --no-warnings  <span class="built_in">disable</span> all warning messages</span><br></pre></td></tr></table></figure><p>部分参数说明:</p><ol><li>-B MODE 设置标准输出的缓冲模式:</li></ol><ul><li>none:无缓冲，每个 IO 尽快写入</li><li>full:一旦缓冲区已满，数据就会被写入</li><li>line:数据在第一个换行符处或缓冲区已满时写入。line是默认的缓冲模式</li></ul><ol start="2"><li>-c COMMAND: 作为子进程运行 COMMAND。当子进程终止时，bpftrace 也将会终止，就像调用了“exit()”一样。如果 bpftrace 在子进程之前终止，则子进程将通过 SIGTERM 终止。</li><li>-e PROGRAM: 执行 PROGRAM</li><li>-l:列出所有探针<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@192 ~]# bpftrace -l | grep  tracepoint:raw_syscalls:*</span><br><span class="line">tracepoint:raw_syscalls:sys_enter</span><br><span class="line">tracepoint:raw_syscalls:sys_exit</span><br></pre></td></tr></table></figure></li></ol><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><p>其基础语法如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">probe[,probe,...] /filter/ &#123; action &#125;</span><br></pre></td></tr></table></figure><ul><li>探针指定要检测的事件类型，bpftrace 定义了多种类型的探针；</li><li>过滤器是可选的，可以根据布尔表达式进行过滤，</li><li>action 是运行的程序</li></ul><p>我们先以<code>hello world</code>做一个入门的示例:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@192 ~]# bpftrace -e &#x27;BEGIN &#123; printf(&quot;Hello Bpftrace!\n&quot;);&#125;&#x27;</span><br><span class="line">Attaching 1 probe...</span><br><span class="line">Hello Bpftrace!</span><br></pre></td></tr></table></figure><p>这里的探针probe 类型是 <code>BEGIN</code>,即在 bpftrace 脚本启动时，BEGIN 探针通过<code>printf</code>函数输出<code>Hello Bpftrace!</code></p><h3 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h3><p>我们再上一个例子,使用 kretprobe 来检测docker进程 sys_read 函数的返回，这里我们要筛选出 docker 进程，就可以使用过滤器进行过滤,在知道进程号的情况下，可以直接使用 <code>pid==</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@192 bpftrace]# bpftrace -e <span class="string">&#x27;kretprobe:vfs_read /pid == 41981/ &#123; @bytes = hist(retval); &#125;&#x27;</span></span><br><span class="line">Attaching 1 probe...</span><br><span class="line">^C</span><br><span class="line">@bytes:</span><br><span class="line">[1]                  329 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|</span><br></pre></td></tr></table></figure><ul><li>这里的<code>kretprobe</code>是内核探针，会在内核函数<code>vfs_read</code>返回时触发，捕获返回值。</li><li><code>pid == 41981</code>条件过滤器，只处理该进程的返回</li><li><code>@bytes = hist(retval);</code>:@bytes 是一个 bpftrace 的全局变量（名称可以自行定义），类型为直方图（hist）;hist(retval) 将记录函数 vfs_read 返回值（retval）的分布情况;retval 是 vfs_read 函数返回的值，即读取到的字节数。</li></ul><p>这里完整的执行逻辑是:</p><ol><li>当内核函数 vfs_read 被调用并完成返回时: kretprobe:vfs_read 会触发探针并且捕获到函数的返回值</li><li>如果触发探针的进程 pid 是 41981，将返回值添加到 @bytes 的直方图中，直方图会记录返回值的分布情况（即不同大小的读取字节数）。</li><li>如果进程 id 不是 41981，则直接跳过</li></ol><p>当然，我们也可以直接通过进程名称的形式去过滤:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bpftrace -e <span class="string">&#x27;kretprobe:vfs_read /comm == &quot;dockerd&quot; / &#123; @bytestest = hist(retval); printf(&quot;pid:%d, comm:%s\n&quot;, pid, comm); &#125;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h3><p>bpftrace 支持以下运算符:</p><ol><li>算数运算符:<code>+, -, *, /, %</code></li><li>逻辑运算符:<code>&amp;&amp;,||,!</code></li><li>按位运算符:<code>&amp;,|,^,&lt;&lt;,&gt;&gt;</code></li><li>关系运算符:<code>&lt;,&lt;=,&gt;,&gt;=,==,!=</code></li><li>赋值运算符:<code>=,&lt;&lt;=,&gt;&gt;=,+=,-=,*=,/=,%=,&amp;=,|=,^=</code></li></ol><p>再次基于上述的案例进行一下操作:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@192 bpftrace]#  bpftrace -e <span class="string">&#x27;kretprobe:vfs_read /comm == &quot;/usr/bin/dockerd&quot; &amp;&amp; comm != &quot;sshd&quot; / &#123; @bytestest = hist(retval); printf(&quot;pid:%d, comm:%s\n&quot;, pid, comm); &#125;&#x27;</span></span><br><span class="line">Attaching 1 probe...</span><br><span class="line">pid:41981, <span class="built_in">comm</span>:dockerd</span><br><span class="line">pid:41981, <span class="built_in">comm</span>:dockerd</span><br><span class="line">pid:1114, <span class="built_in">comm</span>:<span class="keyword">in</span>:imjournal</span><br><span class="line">pid:39225, <span class="built_in">comm</span>:containerd</span><br><span class="line">pid:1114, <span class="built_in">comm</span>:<span class="keyword">in</span>:imjournal</span><br></pre></td></tr></table></figure><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><p>在 bpftrace 中，结构体主要用于访问特定内核事件（如 tracepoints 或 uprobes）中提供的复杂数据类型。<strong>结构体</strong>是 BPF 内核事件的一个核心概念，它允许用户访问和解析事件中嵌套的字段。bpftrace 自动解析许多内核提供的结构体字段，尤其是在支持 BTF（BPF Type Format）时。在使用过程中，可以使用 -&gt; 运算符访问指向结构的指针的字段。</p><p>访问字段的语法:<code>args-&gt;field_name</code>,其中:</p><ul><li>args：bpftrace 自动提供的结构体指针（如 tracepoints 和 usdt 中的 args）。</li><li>field_name：结构体中的字段名称。</li></ul><p>比如说想监控一下文件系统的 open 事件并且打印文件名，进程号等,涉及到的探针是<code>tracepoint:syscalls:sys_enter_openat</code>,我们首先看下这个探针的详细类型:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@192 bpftrace]# bpftrace -lv tracepoint:syscalls:sys_enter_openat</span><br><span class="line">tracepoint:syscalls:sys_enter_openat</span><br><span class="line">    int __syscall_nr</span><br><span class="line">    int dfd</span><br><span class="line">    const char * filename</span><br><span class="line">    int flags</span><br><span class="line">    umode_t mode</span><br></pre></td></tr></table></figure><p>可以看到相关的结构体信息，其中包含了 filename,假如说监控打开了 build.sh的进程信息:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@192 bpftrace]# bpftrace -e <span class="string">&#x27;tracepoint:syscalls:sys_enter_openat /str(args-&gt;filename) == &quot;build.sh&quot;/ &#123; printf(&quot;File: %s, pid:%d\n&quot;, str(args-&gt;filename), pid); &#125;&#x27;</span></span><br><span class="line">Attaching 1 probe...</span><br><span class="line">File: build.sh, pid:46102</span><br><span class="line">File: build.sh, pid:46102</span><br></pre></td></tr></table></figure><p>此外，bpftrace 还支持自定义结构体。我们后续详细展开</p><h3 id="条件语句"><a href="#条件语句" class="headerlink" title="条件语句"></a>条件语句</h3><p>bpftrace 的条件语句目前只支持 if&#x2F;else 暂时不支持 else if 类型操作。通过一个例子来模拟一下,假如说我们需要查看 kill 信号的触发进程:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@192 bpftrace]# bpftrace -e <span class="string">&#x27;tracepoint:syscalls:sys_enter_kill &#123; if (pid &gt; 1) &#123;printf(&quot;pid:%d\n&quot;, pid)&#125; else &#123; printf(&quot;pid is 1\n&quot;)&#125;&#125; &#x27;</span></span><br><span class="line">Attaching 1 probe...</span><br><span class="line"></span><br><span class="line">pid:1509</span><br><span class="line">pid is 1</span><br><span class="line">pid is 1</span><br></pre></td></tr></table></figure><p>这里定义使用了tracepoint:syscalls:sys_enter_kill，用于在执行 kill系统调用的入口处触发,当触发的进程 &gt;1,输出<code>pid:进程号</code>，其他情况下输出<code>pid is 1</code>。</p><p>当然我们也可以扩展为一个脚本，在 kill 进入时输出，在退出时也输出, bpftrace的脚本以.bt为后缀，然后通过<code>bpftrace xxx.bt</code>运行:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env bpftrace</span></span><br><span class="line"></span><br><span class="line">BEGIN</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;Tracing sys_kill... Hit Ctrl-C to end.\n&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tracepoint:syscalls:sys_enter_kill</span><br><span class="line">&#123;</span><br><span class="line">    if (pid &gt; 1) &#123;</span><br><span class="line">        printf(&quot;enter kill,pid is:%d, comm is:%s\n&quot;, pid, comm)</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        printf(&quot;enter kill,pid is 1, comm is:%s\n&quot;, comm)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tracepoint:syscalls:sys_exit_kill</span><br><span class="line">&#123;</span><br><span class="line">    if (pid &gt; 1) &#123;</span><br><span class="line">        printf(&quot;exit kill,pid is:%d, comm is:%s\n&quot;, pid, comm)</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        printf(&quot;exit kill,pid is 1, comm is:%s\n&quot;, comm)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="循环语句"><a href="#循环语句" class="headerlink" title="循环语句"></a>循环语句</h3><p>在 bpftrace 语句中，支持 unroll、 while 和 for 循环（while 循环在内核 5.3 版本开始进行支持，参考:<a href="https://github.com/bpftrace/bpftrace/issues/872">https://github.com/bpftrace/bpftrace/issues/872</a>, 而 for 循环在 5.13 以及更高版本支持）</p><p>unroll 是 bpftrace 提供的用于模拟循环的功能，适合静态固定次数的循环。我们先看下 unroll 的用法:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@192 bptest]# bpftrace -e <span class="string">&#x27;                                                          BEGIN &#123;</span></span><br><span class="line"><span class="string">    unroll(10) &#123;</span></span><br><span class="line"><span class="string">        printf(&quot;pid: %d\n&quot;, pid);</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br></pre></td></tr></table></figure><p>这里做循环的 10 次输出 pid 信息。</p><p>我们在看下<code>while</code>的用法，在使用 while 的时候，我们可以轻松联想到对应支持 <code>break、continue、return</code> 等。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bpftrace -e <span class="string">&#x27;i:ms:100 &#123; $i = 0; while ($i &lt;= 100) &#123; if ($i &gt; 50) &#123; break; &#125; printf(&quot;%d &quot;, $i); $i++&#125; exit(); &#125;&#x27;</span></span><br></pre></td></tr></table></figure><p>也可以看到这里的语法<strong>支持自增</strong>等操作。</p><p>for循环可用于迭代隐射中的元素:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="variable">$kv</span> : @map) &#123;</span><br><span class="line">  block;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="数组和元组"><a href="#数组和元组" class="headerlink" title="数组和元组"></a>数组和元组</h3><p>数组是一组数据的集合。我们可以直接看一个例子:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bpftrace -e <span class="string">&#x27;</span></span><br><span class="line"><span class="string">BEGIN &#123;</span></span><br><span class="line"><span class="string">    // 使用 Map 模拟数组</span></span><br><span class="line"><span class="string">    @my_array[0] = 10;</span></span><br><span class="line"><span class="string">    @my_array[1] = 20;</span></span><br><span class="line"><span class="string">    @my_array[2] = 30;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    // 打印数组元素</span></span><br><span class="line"><span class="string">    printf(&quot;Array elements: %d, %d, %d\n&quot;, @my_array[0], @my_array[1], @my_array[2]);</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><p>元组是一种序列类型（如数组），与数组不同，每个元素可以有不同的类型。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@192 bptest]# bpftrace -e &#x27;</span><br><span class="line">i:s:1 &#123;</span><br><span class="line">  $a = (1,2);</span><br><span class="line">  $b = (3,4, $a);</span><br><span class="line">  print($a);</span><br><span class="line">  print($b);</span><br><span class="line">  print($b.0);</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure><p>至于其他的语法规则，这里不再展开，大家自行查阅官网文档即可。</p><h1 id="回到开头"><a href="#回到开头" class="headerlink" title="回到开头"></a>回到开头</h1><p>那我们现在再来回顾文章开头提到的问题，既然 bpftrace 能够跟踪到内核，那么肯定也可以跟踪到进程的启停操作，我们以<code>nginx -s reload</code>为例分析下，在 nginx 发生 reload 的时候首先会创建新的子进程,子进程创建完毕之后，会让旧进程退出。这里就需要监控到两个地方:</p><ol><li>fork子进程操作</li><li>子进程退出操作</li></ol><p>bpftrace 中有 tracepoint:sched类的探针来探测这些行为，这里提供下脚本:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bpftrace</span></span><br><span class="line"></span><br><span class="line">BEGIN</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Tracing nginx restart or reload... Hit Ctrl-C to end.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tracepoint:<span class="built_in">sched</span>:sched_process_exit</span><br><span class="line">/ <span class="built_in">comm</span> == <span class="string">&quot;nginx&quot;</span> /</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;the nginx process is exit, pid is: %d, comm is:%s, prio is:%d\n&quot;</span>, pid, <span class="built_in">comm</span>, args-&gt;prio)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tracepoint:<span class="built_in">sched</span>:sched_process_fork</span><br><span class="line">/ <span class="built_in">comm</span> == <span class="string">&quot;nginx&quot;</span> /</span><br><span class="line">&#123;</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;the nginx process is fork, pid is:%d, comm is:%s, child pid is:%d\n&quot;</span>, pid, <span class="built_in">comm</span>, args-&gt;child_pid)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们看下效果:<br><img src="/image-1.png" alt="alt text"><br>从图中可以清晰的看到了 reload 操作被成功地捕获。</p><p>这篇文章中，大概展示了下 bpftrace 的相关概念和语法以及基本的操作，而在实际监控场景中，监控的指标多种多样，后续会通过一些典型场景来看看如果使用 bpftrace 进行监控。</p><h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>码字不易，希望文章对各位读者朋友们有所帮助和启发，文章的撰写有的时候是根据自己的经验和遇到的一些场景所思考的，存在不足和错误的地方，希望读者朋友们指正。转载请声明来源</p>]]></content>
    
    
    <summary type="html">A brief description of the content</summary>
    
    
    
    <category term="Technology" scheme="http://baixiaozhou.github.io/categories/Technology/"/>
    
    
    <category term="Programming" scheme="http://baixiaozhou.github.io/tags/Programming/"/>
    
    <category term="Hexo" scheme="http://baixiaozhou.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>ebpf系列教程(1) --初识 ebpf</title>
    <link href="http://baixiaozhou.github.io/p/ebpf%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B-1-%E5%88%9D%E8%AF%86-ebpf/"/>
    <id>http://baixiaozhou.github.io/p/ebpf%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B-1-%E5%88%9D%E8%AF%86-ebpf/</id>
    <published>2024-11-14T07:15:12.000Z</published>
    <updated>2024-11-18T10:52:15.603Z</updated>
    
    <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a>ebpf系列教程(1) --初识 ebpf</h1><p>This article was written by baixiaozhou on 1731568512000.</p><!-- Your content starts here --><p>最初接触到 ebpf 是在调研监控系统的时候，发现了这门比较“新颖”的技术（之前没有接触过）；而且在之前接触到的一些系统中还没有直接的使用过这个技术，所以产生了非常强强烈的好奇心，经过不断的了解之后觉得这个东西应该是未来监控系统和系统性能调优所不可或缺的。</p><p>会尝试将ebpf 做成一个系列，而且也接触不久，所以关于这个系列的更新的频率总体来说应该比较慢，需要不断尝试验证做积累。学习过程中也有可能走到误区之中，所以文章中也会存在不足和错误，欢迎大家指正交流。</p><h1 id="什么是-eBPF"><a href="#什么是-eBPF" class="headerlink" title="什么是 eBPF"></a>什么是 eBPF</h1><p>首先我们来看一下官网的介绍:</p><p>eBPF的核心是一个位于内核中的高效虚拟机。它最初的目的是高效的网络帧过滤，这使得这个虚拟机和eBPF成为处理事件的理想引擎。</p><p>eBPF 是一项革命性的技术，起源于 Linux 内核，它可以在特权上下文中（如操作系统内核）运行沙盒程序。它用于安全有效地扩展内核的功能，而无需通过更改内核源代码或加载内核模块的方式来实现。</p><p>从历史上看，由于内核具有监督和控制整个系统的特权，操作系统一直是实现可观测性、安全性和网络功能的理想场所。同时，由于操作系统内核的核心地位和对稳定性和安全性的高要求，操作系统内核很难快速迭代发展。因此在传统意义上，与在操作系统本身之外实现的功能相比，操作系统级别的创新速度要慢一些。<br><img src="/../images/ebpf.png" alt="alt text"><br>eBPF 从根本上改变了这个方式。通过允许在操作系统中运行沙盒程序的方式，应用程序开发人员可以运行 eBPF 程序，以便在运行时向操作系统添加额外的功能。然后在 JIT 编译器和验证引擎的帮助下，操作系统确保它像本地编译的程序一样具备安全性和执行效率。这引发了一股基于 eBPF 的项目热潮，它们涵盖了广泛的用例，包括下一代网络实现、可观测性和安全功能等领域。</p><p>如今，eBPF 被广泛用于驱动各种用例:在现代数据中心和云原生环境中提供高性能网络和负载均衡，以低开销提取细粒度的安全可观测性数据，帮助应用程序开发人员跟踪应用程序，为性能故障排查、预防性的安全策略执行(包括应用层和容器运行时)提供洞察，等等。</p><h1 id="eBPF能做什么"><a href="#eBPF能做什么" class="headerlink" title="eBPF能做什么"></a>eBPF能做什么</h1><h2 id="网络性能优化与管理"><a href="#网络性能优化与管理" class="headerlink" title="网络性能优化与管理"></a>网络性能优化与管理</h2><ol><li>高效的数据包过滤和路由:eBPF 最初用于数据包过滤，现在可以直接处理、过滤、转发数据包，用于防火墙和负载均衡等应用。与传统的 iptables 或 ipvs 不同，eBPF 在内核中处理数据包，极大地提升了性能和效率。</li><li>服务网格和负载均衡:eBPF 可用于实现无代理的服务网格，如 Cilium，替代传统代理，减少网络延迟、节省资源。</li><li>流量监控与 QoS 控制:eBPF 可以实时收集网络流量数据、延迟信息等，进行带宽控制和 QoS（服务质量）优化。</li></ol><h2 id="系统检测和可观测性"><a href="#系统检测和可观测性" class="headerlink" title="系统检测和可观测性"></a>系统检测和可观测性</h2><ol><li>高效系统追踪和监控:eBPF 通过内核探针（kprobes）和用户探针（uprobes）能够监控系统调用、文件访问、网络活动等，为性能分析提供了丰富的实时数据。</li><li>低开销的应用监控:eBPF 不需要传统监控代理，直接在内核中获取 CPU 使用率、内存消耗、磁盘 I&#x2F;O 等性能指标，减少了资源消耗。</li><li>详细性能分析工具:通过工具如 BPFTrace 和 bcc，可以捕获系统级事件，生成详细的性能分析报告，帮助开发者发现性能瓶颈。</li></ol><h2 id="容器与云原生应用"><a href="#容器与云原生应用" class="headerlink" title="容器与云原生应用"></a>容器与云原生应用</h2><ol><li><pre><code>Kubernetes 网络与安全插件:eBPF 广泛应用于 Kubernetes，如 Cilium 利用 eBPF 实现容器网络管理和安全策略控制。它可以在内核中处理容器间的网络隔离、策略控制和流量限制。</code></pre></li><li>容器性能监控和调优:eBPF 可以在不侵入容器的情况下监控其资源使用，避免对容器环境的额外开销。</li><li>容器的安全监控:通过 eBPF 可以监控容器的系统调用，检测异常行为，帮助进行实时的入侵检测。</li></ol><h2 id="安全与异常检测"><a href="#安全与异常检测" class="headerlink" title="安全与异常检测"></a>安全与异常检测</h2><ol><li>实时入侵检测:eBPF 可以监控系统调用、网络活动、文件操作等，对比正常行为模式，实时发现并响应潜在的安全威胁。</li><li>系统安全增强:通过 eBPF 可以限制特定系统调用，甚至可以动态更新安全策略，防止恶意进程或攻击行为。</li><li>行为分析:eBPF 还可分析进程、用户行为模式，识别潜在的恶意活动或异常操作。</li></ol><h2 id="内核调试与开发"><a href="#内核调试与开发" class="headerlink" title="内核调试与开发"></a>内核调试与开发</h2><ol><li>动态调试工具:eBPF 可以动态插入到内核代码的任意位置，获取特定函数或系统调用的执行情况，为调试提供详细数据，而无需重新编译或重启系统。</li><li>内核性能优化:通过 eBPF 可追踪内核内部性能，发现潜在的性能瓶颈，并进行优化。</li><li>高级开发工具支持:bcc 和 BPFTrace 等工具集极大简化了 eBPF 程序的编写和调试，使得开发者可以用高级语言来定义 eBPF 程序</li></ol><h1 id="eBPF的发展历史"><a href="#eBPF的发展历史" class="headerlink" title="eBPF的发展历史"></a>eBPF的发展历史</h1><h2 id="1-初始版本-BPF诞生"><a href="#1-初始版本-BPF诞生" class="headerlink" title="1.初始版本:BPF诞生"></a>1.初始版本:BPF诞生</h2><p>BPF 的全称是 <strong>“Berkeley Packet Filter”</strong>, 最早是由Steven McCanne 和 Van Jacobson 在 1993 年在冬季 USENIX 会议上提出，论文的原始题目是: <code>The BSD Packet Filter: A New Architecture for User-level Packet Capture</code>, 论文的具体内容: <a href="https://www.tcpdump.org/papers/bpf-usenix93.pdf">https://www.tcpdump.org/papers/bpf-usenix93.pdf</a></p><p>最早的 BPF 是一种用于在内核中实现高效数据包过滤的技术，旨在提升 tcpdump 等工具的网络数据包过滤性能。和其前辈（如 CMU&#x2F;CSPF）的不同之处在于，BPF 使用了一个改良的内存模型，然后通过内核中的一个高效虚拟机将其公开。通过这种方式，BPF过滤器可以以有效的方式进行流量过滤，同时仍然保持过滤器代码和内核之间的边界。在论文中，描述了BPF 的工作视图:</p><p><img src="/../images/BPF%20overview.png" alt="alt text"></p><p>McCanne和Jacobson所做的最重要的事情可能是通过以下五个标准定义了虚拟机的设计（摘抄自<a href="https://www.ferrisellis.com/content/ebpf_past_present_future/">eBPF, part 1: Past, Present, and Future</a>）:</p><ol><li>它必须是协议独立的。不应该修改内核来添加新的协议支持</li><li>通用性，指令集应该足够丰富</li><li>应尽量减少数据包的数据引用</li><li>解码一条指令应该由一个C switch语句组成</li><li>抽象机器寄存器应该驻留在物理寄存器中。</li></ol><p>这种对可扩展性、通用性和性能的强调可能是eBPF在其现代形式下比BPF的原始实现所包含的内容要多得多的原因。</p><h2 id="2-eBPF-扩展-向通用数据处理的过渡"><a href="#2-eBPF-扩展-向通用数据处理的过渡" class="headerlink" title="2.eBPF 扩展:向通用数据处理的过渡"></a>2.eBPF 扩展:向通用数据处理的过渡</h2><p>当Linux内核版本3.18于2014年12月发布时，它包含了扩展BPF（eBPF）的第一个实现。简而言之，eBPF提供的是内核虚拟机，就像BPF一样，但有一些关键的改进:</p><ol><li>eBPF比原来的BPF虚拟机更高效，这要归功于eBPF代码的JIT编译。<ul><li>JIT 编译器:eBPF 支持 Just-In-Time（JIT）编译，可以将 eBPF 字节码转换为原生机器码，直接在 CPU 上运行。JIT 编译显著提高了 eBPF 程序的执行效率，缩小了内核代码执行和 eBPF 字节码之间的性能差距</li></ul></li><li>内核安全检查:eBPF 加入了内核验证器，确保 eBPF 程序的安全性。验证器会在 eBPF 程序执行前检查其代码路径，以防止无限循环和非法访问等问题，从而保护内核安全。</li><li>支持更复杂的数据结构:<ul><li>引入 BPF 映射（Map）:eBPF 支持不同类型的 BPF 映射（如哈希表、数组、队列等），这使得 eBPF 程序可以存储和管理数据，甚至在内核与用户空间之间共享数据。这一功能让 eBPF 不再局限于“过滤器”，而成为一个小型的、数据驱动的处理引擎。</li><li>高效数据传递:BPF 映射在 eBPF 程序和用户空间之间传递数据非常高效，使得 eBPF 程序能够在不频繁陷入用户态的情况下实现数据共享。</li></ul></li><li>支持多种挂载点，增强了通用性:<ul><li>多种挂载点:eBPF 可以附加到多种内核挂载点，不仅局限于网络协议栈，还包括内核跟踪点、系统调用、内核函数和用户空间函数等。这使得 eBPF 成为了一个通用的系统观测工具，而不仅仅是网络过滤器。</li><li>动态插入和卸载:eBPF 程序可以动态加载到内核的特定位置并即时生效，同时可以根据需求卸载，这种动态性避免了系统重启的需求，大大提高了灵活性。</li></ul></li></ol><h2 id="3-eBPF-应用扩展-容器和云原生环境"><a href="#3-eBPF-应用扩展-容器和云原生环境" class="headerlink" title="3.eBPF 应用扩展:容器和云原生环境"></a>3.eBPF 应用扩展:容器和云原生环境</h2><p>随着云计算和容器化技术的普及，对系统监控和网络性能要求更高，eBPF 成为了 Kubernetes、Docker 等容器环境中的理想工具。</p><p>eBPF 在云原生领域的探索:</p><ol><li>2016 年:随着容器编排工具（如 Kubernetes）的普及，微服务架构快速兴起，容器的广泛使用带来了新的网络管理、监控和安全需求。传统的监控和安全工具往往在容器环境中难以扩展且性能不足。</li><li>网络插件 Cilium:Isovalent 公司开发了基于 eBPF 的 Kubernetes 网络插件 Cilium，这是第一个将 eBPF 应用于 Kubernetes 网络管理的项目。Cilium 利用 eBPF 直接在内核中实现网络策略、服务负载均衡等功能，提供了高效的容器间通信控制和可观测性。</li><li>容器安全工具 Falco:Sysdig 公司推出了 Falco，一个基于 eBPF 的实时安全监控工具。Falco 通过监控内核事件检测可疑的系统调用和进程活动，为容器化应用提供了细粒度的入侵检测和安全告警功能。</li></ol><h2 id="4-生态系统扩展和-XDP-引入"><a href="#4-生态系统扩展和-XDP-引入" class="headerlink" title="4.生态系统扩展和 XDP 引入"></a>4.生态系统扩展和 XDP 引入</h2><ol><li>XDP（eXpress Data Path）:这是基于 eBPF 的一个超快速数据包处理框架，允许在网卡驱动的最早阶段处理数据包，极大地提高了数据包处理速度。</li><li>生态系统扩展:此时 eBPF 已经拥有了丰富的开发库和应用框架，Cilium、Falco 和 Tracee 等开源项目基于 eBPF 实现了高效的监控、安全和网络管理工具。</li></ol><h1 id="相关开源项目汇总"><a href="#相关开源项目汇总" class="headerlink" title="相关开源项目汇总"></a>相关开源项目汇总</h1><h2 id="bcc-BPF-Compiler-Collection"><a href="#bcc-BPF-Compiler-Collection" class="headerlink" title="bcc (BPF Compiler Collection)"></a>bcc (BPF Compiler Collection)</h2><ol><li>简介:bcc 是最早也是最常用的 eBPF 工具集合之一，提供了一组用于编写 eBPF 程序的高层次 API，并支持多种语言（Python、C++ 等）。它包含了大量的预构建工具，如 execsnoop 和 opensnoop，用于调试和性能监控。</li><li>用途:系统监控、性能调优、故障排查。</li><li>github: <a href="https://github.com/iovisor/bcc">https://github.com/iovisor/bcc</a></li></ol><h2 id="libbpf"><a href="#libbpf" class="headerlink" title="libbpf"></a>libbpf</h2><ol><li>简介:libbpf 是一个低级的 eBPF 库，直接调用内核的 eBPF API，性能比 bcc 更高。它适合性能要求高的应用，但开发需要更强的 C 编程技能。</li><li>用途:内核开发、性能敏感型应用。</li><li>github: <a href="https://github.com/libbpf/libbpf">https://github.com/libbpf/libbpf</a></li></ol><h2 id="Cilium"><a href="#Cilium" class="headerlink" title="Cilium"></a>Cilium</h2><ol><li>简介:Cilium 是一个基于 eBPF 的网络插件，用于在 Kubernetes 和其他容器化平台上提供高性能的网络和安全功能。它通过 eBPF 实现无代理服务网格、网络策略、流量控制和负载均衡。</li><li>用途:Kubernetes 网络和安全、服务网格。</li><li>github: <a href="https://github.com/cilium/cilium">https://github.com/cilium/cilium</a></li></ol><h2 id="BPFTrace"><a href="#BPFTrace" class="headerlink" title="BPFTrace"></a>BPFTrace</h2><ol><li>简介:BPFTrace 是一个高级的 eBPF 工具，用于编写系统追踪脚本。与 bcc 相比，BPFTrace 更易于上手，语法类似于 awk，非常适合用于快速编写系统性能和行为分析脚本。</li><li>用途:系统性能监控、故障诊断、动态调试。</li><li>github: <a href="https://github.com/bpftrace/bpftrace">https://github.com/bpftrace/bpftrace</a></li></ol><h2 id="Tracee"><a href="#Tracee" class="headerlink" title="Tracee"></a>Tracee</h2><ol><li>简介:Tracee 是由 Aqua Security 开发的 eBPF 安全检测工具，专注于捕获并分析系统调用事件，用于安全监控和入侵检测，尤其适用于容器化环境的安全需求。</li><li>用途:实时监控、入侵检测、恶意行为分析。</li><li>github: <a href="https://github.com/aquasecurity/tracee">https://github.com/aquasecurity/tracee</a></li></ol><h2 id="Katran"><a href="#Katran" class="headerlink" title="Katran"></a>Katran</h2><ol><li>简介:Katran 是 Facebook 开源的基于 eBPF 的负载均衡器，用于实现高性能、低延迟的网络负载分发。它利用 eBPF 实现了高效的负载均衡，同时避免了传统内核负载均衡中的一些性能瓶颈。</li><li>用途:负载均衡、网络流量优化。</li><li>github: <a href="https://github.com/facebookincubator/katran">https://github.com/facebookincubator/katran</a></li></ol><h2 id="Pixie"><a href="#Pixie" class="headerlink" title="Pixie"></a>Pixie</h2><ol><li>简介:Pixie 是一个用于 Kubernetes 环境的可观测性平台，支持实时应用性能监控、故障排查和根因分析。Pixie 使用 eBPF 采集应用数据，实现了无代理监控和低开销的数据采集。</li><li>用途:Kubernetes 监控、应用性能跟踪。</li><li>github: <a href="https://github.com/pixie-io/pixie">https://github.com/pixie-io/pixie</a></li></ol><h2 id="Falco"><a href="#Falco" class="headerlink" title="Falco"></a>Falco</h2><ol><li>简介:Falco 是 Sysdig 开源的一个云原生运行时安全工具。虽然最初基于内核模块，但现在也支持 eBPF，用于实时监控系统调用、文件操作等行为，适合于 Kubernetes 的安全监控。</li><li>用途:安全监控、合规检查。</li><li>github: <a href="https://github.com/falcosecurity/falco">https://github.com/falcosecurity/falco</a></li></ol><h2 id="Hubble"><a href="#Hubble" class="headerlink" title="Hubble"></a>Hubble</h2><ol><li>简介:Hubble 是 Cilium 的一个扩展项目，用于提供网络可观测性和安全分析。它基于 eBPF，可以实时追踪网络流量，生成丰富的可视化数据。</li><li>用途:网络可视化、Kubernetes 可观测性。</li><li>github: <a href="https://github.com/cilium/hubble">https://github.com/cilium/hubble</a></li></ol><h2 id="KubeArmor"><a href="#KubeArmor" class="headerlink" title="KubeArmor"></a>KubeArmor</h2><ol><li>简介:KubeArmor 是基于 eBPF 的 Kubernetes 安全工具，用于限制容器的系统行为和应用程序的操作权限。它可以帮助阻止不安全的行为和攻击路径。</li><li>用途:Kubernetes 安全防护、访问控制。</li><li>github: <a href="https://github.com/kubearmor/KubeArmor">https://github.com/kubearmor/KubeArmor</a></li></ol><h2 id="Parca"><a href="#Parca" class="headerlink" title="Parca"></a>Parca</h2><ol><li>简介:Parca 是一个用于持续剖析的开源工具，利用 eBPF 采集性能数据，帮助开发人员分析应用程序在生产环境中的性能问题。</li><li>用途: 持续性能分析、性能调优。</li><li>github: <a href="https://github.com/parca-dev/parca">https://github.com/parca-dev/parca</a></li></ol><h1 id="发展和展望"><a href="#发展和展望" class="headerlink" title="发展和展望"></a>发展和展望</h1><p>自诞生以来，eBPF 已经从一个简单的网络数据包过滤工具发展成为一项强大的技术，广泛应用于操作系统内核扩展、性能优化和安全监控。eBPF 的影响力仍在不断扩大, 它已在 Linux 内核中牢固地确立了自己的地位，并逐渐被移植到 Windows、其他操作系统和用户空间扩展中。这种跨平台扩展将进一步巩固 eBPF 在操作系统中的地位，使其成为未来系统架构的重要组成部分。</p><p>关于ebpf 未来的发展和展望，我在这里就不班门弄斧了，大家可以参考下这篇文章: <a href="https://eunomia.dev/blogs/ebpf-2024/#emerging-application-fields-driving-cloud-native-architecture-development">https://eunomia.dev/blogs/ebpf-2024/#emerging-application-fields-driving-cloud-native-architecture-development</a></p>]]></content>
    
    
    <summary type="html">A brief description of the content</summary>
    
    
    
    <category term="Technology" scheme="http://baixiaozhou.github.io/categories/Technology/"/>
    
    
    <category term="Linux" scheme="http://baixiaozhou.github.io/tags/Linux/"/>
    
    <category term="ebpf" scheme="http://baixiaozhou.github.io/tags/ebpf/"/>
    
  </entry>
  
  <entry>
    <title>网卡 bond</title>
    <link href="http://baixiaozhou.github.io/p/%E7%BD%91%E5%8D%A1-bond/"/>
    <id>http://baixiaozhou.github.io/p/%E7%BD%91%E5%8D%A1-bond/</id>
    <published>2024-10-24T03:09:16.000Z</published>
    <updated>2024-11-14T02:44:34.284Z</updated>
    
    <content type="html"><![CDATA[<!-- Your content starts here --><h1 id="Bond-的概念"><a href="#Bond-的概念" class="headerlink" title="Bond 的概念"></a>Bond 的概念</h1><p>网卡bond模式是一种网络绑定或链路聚合技术，它可以将多个物理网卡绑定成一个逻辑网卡，从而提高数据报文的可用性和吞吐量。从这段介绍中，我们其实看出一些使用场景，高可用性是为了解决单点故障，提高吞吐量是为了增加网络带宽。从可用性的角度看，网卡的绑定其实就是将多个网卡看作一个整体，当一张网卡挂掉或者异常之后，其他的网卡可以承载流量请求；从吞吐量的角度看，假如说有机器上有两张 100G的网卡，如果分开，就需要配置两个 ip，通信上不方便，这样我们就可以通过 bond 将其作为一个整体进行使用。变相成为了一张 200G 的网卡</p><h1 id="bond的作用"><a href="#bond的作用" class="headerlink" title="bond的作用"></a>bond的作用</h1><ul><li>提高带宽：通过绑定多个物理网卡，可以实现网络带宽的叠加，从而提高整体网络传输速度。</li><li>实现冗余：当其中一个物理网卡出现故障时，其他网卡可以接管其工作，确保网络连接的连续性。</li><li>负载均衡：根据一定的策略将网络流量分配到不同的物理网卡上，实现负载均衡，避免单个网卡过载。</li></ul><h1 id="bond模式"><a href="#bond模式" class="headerlink" title="bond模式"></a>bond模式</h1><p>bond 的模式一共有七种，每个模式都有各自的特点和适用场景，同时部分 bond 需要交换机的支持，以下是各种模式的概述和优缺点阐述:</p><table><thead><tr><th>模式编号</th><th>模式名称</th><th>概述</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>mode-0</td><td>balance-rr (轮询负载均衡)</td><td>在所有可用的接口上依次轮询发送数据包</td><td>最大化带宽利用，提供容错能力</td><td>可能出现包乱序问题，需交换机支持</td></tr><tr><td>mode-1</td><td>active-backup (主备模式)</td><td>只有一个接口处于活动状态，其他接口作为备份</td><td>高可用性，简单配置</td><td>无负载均衡，带宽利用率低</td></tr><tr><td>mode-2</td><td>balance-xor (XOR 负载均衡)</td><td>根据哈希值决定使用哪个接口，保持会话一致性</td><td>保持会话一致性，提供冗余</td><td>需要交换机支持，不适合流量集中场景</td></tr><tr><td>mode-3</td><td>broadcast (广播模式)</td><td>所有数据包都会通过每个接口发送一次</td><td>极高冗余性</td><td>带宽浪费严重，适用于特殊场景</td></tr><tr><td>mode-4</td><td>802.3ad (LACP)</td><td>基于 IEEE 802.3ad 标准动态链路聚合，实现带宽聚合</td><td>动态带宽聚合，高性能，高冗余</td><td>需要交换机支持 LACP，配置复杂</td></tr><tr><td>mode-5</td><td>balance-tlb (传输流量负载均衡)</td><td>根据接口负载动态调整出站流量分配</td><td>出站负载均衡，不需交换机支持</td><td>入站流量无法负载均衡，适合出站流量大的场景</td></tr></tbody></table><h1 id="bond的配置"><a href="#bond的配置" class="headerlink" title="bond的配置"></a>bond的配置</h1><p>配置 bond 的方式多钟多样，包括 nmcli、命令操作以及配置文件的方式，这里我们通过配置文件的方式进行操作。</p><p>在配置之前，我们需要了解到操作系统支持的 bond 参数有哪些？首先我们可以查看下内核中关于 bond 的支持情况</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# modinfo bonding</span><br><span class="line">filename:       /lib/modules/4.18.0-193.28.1.el7.aarch64/kernel/drivers/net/bonding/bonding.ko.xz</span><br><span class="line">author:         Thomas Davis, tadavis@lbl.gov and many others</span><br><span class="line">description:    Ethernet Channel Bonding Driver, v3.7.1</span><br><span class="line">version:        3.7.1</span><br><span class="line">license:        GPL</span><br><span class="line"><span class="built_in">alias</span>:          rtnl-link-bond</span><br><span class="line">rhelversion:    8.2</span><br><span class="line">srcversion:     1E6D86D1C8403DB78D3FBDD</span><br><span class="line">depends:</span><br><span class="line">intree:         Y</span><br><span class="line">name:           bonding</span><br><span class="line">vermagic:       4.18.0-193.28.1.el7.aarch64 SMP mod_unload modversions aarch64</span><br><span class="line">parm:           max_bonds:Max number of bonded devices (int)</span><br><span class="line">parm:           tx_queues:Max number of transmit queues (default = 16) (int)</span><br><span class="line">parm:           num_grat_arp:Number of peer notifications to send on failover event (<span class="built_in">alias</span> of num_unsol_na) (int)</span><br><span class="line">parm:           num_unsol_na:Number of peer notifications to send on failover event (<span class="built_in">alias</span> of num_grat_arp) (int)</span><br><span class="line">parm:           miimon:Link check interval <span class="keyword">in</span> milliseconds (int)</span><br><span class="line">parm:           updelay:Delay before considering <span class="built_in">link</span> up, <span class="keyword">in</span> milliseconds (int)</span><br><span class="line">parm:           downdelay:Delay before considering <span class="built_in">link</span> down, <span class="keyword">in</span> milliseconds (int)</span><br><span class="line">parm:           use_carrier:Use netif_carrier_ok (vs MII ioctls) <span class="keyword">in</span> miimon; 0 <span class="keyword">for</span> off, 1 <span class="keyword">for</span> on (default) (int)</span><br><span class="line">parm:           mode:Mode of operation; 0 <span class="keyword">for</span> balance-rr, 1 <span class="keyword">for</span> active-backup, 2 <span class="keyword">for</span> balance-xor, 3 <span class="keyword">for</span> broadcast, 4 <span class="keyword">for</span> 802.3ad, 5 <span class="keyword">for</span> balance-tlb, 6 <span class="keyword">for</span> balance-alb (charp)</span><br><span class="line">parm:           primary:Primary network device to use (charp)</span><br><span class="line">parm:           primary_reselect:Reselect primary slave once it comes up; 0 <span class="keyword">for</span> always (default), 1 <span class="keyword">for</span> only <span class="keyword">if</span> speed of primary is better, 2 <span class="keyword">for</span> only on active slave failure (charp)</span><br><span class="line">parm:           lacp_rate:LACPDU tx rate to request from 802.3ad partner; 0 <span class="keyword">for</span> slow, 1 <span class="keyword">for</span> fast (charp)</span><br><span class="line">parm:           ad_select:802.3ad aggregation selection logic; 0 <span class="keyword">for</span> stable (default), 1 <span class="keyword">for</span> bandwidth, 2 <span class="keyword">for</span> count (charp)</span><br><span class="line">parm:           min_links:Minimum number of available links before turning on carrier (int)</span><br><span class="line">parm:           xmit_hash_policy:balance-alb, balance-tlb, balance-xor, 802.3ad hashing method; 0 <span class="keyword">for</span> layer 2 (default), 1 <span class="keyword">for</span> layer 3+4, 2 <span class="keyword">for</span> layer 2+3, 3 <span class="keyword">for</span> encap layer 2+3, 4 <span class="keyword">for</span> encap layer 3+4 (charp)</span><br><span class="line">parm:           arp_interval:arp interval <span class="keyword">in</span> milliseconds (int)</span><br><span class="line">parm:           arp_ip_target:arp targets <span class="keyword">in</span> n.n.n.n form (array of charp)</span><br><span class="line">parm:           arp_validate:validate src/dst of ARP probes; 0 <span class="keyword">for</span> none (default), 1 <span class="keyword">for</span> active, 2 <span class="keyword">for</span> backup, 3 <span class="keyword">for</span> all (charp)</span><br><span class="line">parm:           arp_all_targets:fail on any/all arp targets <span class="built_in">timeout</span>; 0 <span class="keyword">for</span> any (default), 1 <span class="keyword">for</span> all (charp)</span><br><span class="line">parm:           fail_over_mac:For active-backup, <span class="keyword">do</span> not <span class="built_in">set</span> all slaves to the same MAC; 0 <span class="keyword">for</span> none (default), 1 <span class="keyword">for</span> active, 2 <span class="keyword">for</span> follow (charp)</span><br><span class="line">parm:           all_slaves_active:Keep all frames received on an interface by setting active flag <span class="keyword">for</span> all slaves; 0 <span class="keyword">for</span> never (default), 1 <span class="keyword">for</span> always. (int)</span><br><span class="line">parm:           resend_igmp:Number of IGMP membership reports to send on <span class="built_in">link</span> failure (int)</span><br><span class="line">parm:           packets_per_slave:Packets to send per slave <span class="keyword">in</span> balance-rr mode; 0 <span class="keyword">for</span> a random slave, 1 packet per slave (default), &gt;1 packets per slave. (int)</span><br><span class="line">parm:           lp_interval:The number of seconds between instances <span class="built_in">where</span> the bonding driver sends learning packets to each slaves peer switch. The default is 1. (uint)</span><br></pre></td></tr></table></figure><h2 id="实战配置"><a href="#实战配置" class="headerlink" title="实战配置"></a>实战配置</h2><h3 id="bond4"><a href="#bond4" class="headerlink" title="bond4"></a>bond4</h3><p>假设我们现在有两张网卡做 bond4，我们通过实战的形式来看一下如何做 bond:</p><ol><li><p>假设我们有两张网卡 enp1s0f0 和 enp1s0f1，首先可以通ethtool 查看下网卡的信息,例如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# ethtool enp1s0f0</span><br><span class="line">Settings <span class="keyword">for</span> enp1s0f0:</span><br><span class="line">Supported ports: [ FIBRE ]</span><br><span class="line">Supported <span class="built_in">link</span> modes:   xxxx</span><br><span class="line">Supported pause frame use: Symmetric</span><br><span class="line">Supports auto-negotiation: Yes</span><br><span class="line">Supported FEC modes: None RS</span><br><span class="line">Advertised <span class="built_in">link</span> modes:  xxxx</span><br><span class="line">Advertised pause frame use: No</span><br><span class="line">Advertised auto-negotiation: Yes</span><br><span class="line">Advertised FEC modes: RS</span><br><span class="line">Speed: 100000Mb/s</span><br><span class="line">Duplex: Full</span><br><span class="line">Port: FIBRE</span><br><span class="line">PHYAD: 0</span><br><span class="line">Transceiver: internal</span><br><span class="line">Auto-negotiation: on</span><br><span class="line">Supports Wake-on: d</span><br><span class="line">Wake-on: d</span><br><span class="line">Current message level: 0x00000004 (4)</span><br><span class="line">       <span class="built_in">link</span></span><br><span class="line">Link detected: <span class="built_in">yes</span></span><br></pre></td></tr></table></figure><p>我们可以看到这张卡的配置是 100000Mb&#x2F;s,也就是一张百 G 的网卡，做bond4 就是将两张百 G 的网卡绑定在一起形成一张200G 的卡</p></li><li><p>不同的操作系统网卡的配置方式存在不同，我们这里以 centos7为例,进入<code>/etc/sysconfig/network-scripts</code> 目录下，我们可以看到网卡的配置文件名称是<code>ifcfg-网卡名</code>的格式。</p></li><li><p>创建 bond 文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=bond0</span><br><span class="line">TYPE=bond</span><br><span class="line">ONBOOT=<span class="built_in">yes</span></span><br><span class="line">BOOTPROTO=none</span><br><span class="line">USERCTL=no</span><br><span class="line">BONDING_OPTS=<span class="string">&quot;mode=4 miimon=100 xmit_hash_policy=layer3+4&quot;</span></span><br><span class="line">IPADDR=192.168.11.10</span><br><span class="line">NETMASK=255.255.255.0</span><br></pre></td></tr></table></figure><p>参数释义:</p></li></ol><ul><li><code>DEVICE=bond0</code>：指定这个配置是用于名为bond0的设备,bond0是逻辑绑定的接口名。</li><li><code>TYPE=bond</code>：表明这个设备是一个 bond 接口。</li><li><code>ONBOOT=yes</code>：在系统启动时自动启动这个网络接口。</li><li><code>BOOTPROTO=none</code>: 不使用任何启动协议（如DHCP）来获取IP地址。这意味着IP地址将静态配置。</li><li><code>USERCTL=no</code>：不允许非root用户控制这个网络接口。</li><li><code>BONDING_OPTS</code>&#x3D;”mode&#x3D;4 miimon&#x3D;100 xmit_hash_policy&#x3D;layer3+4”：这是绑定接口的选项，这一项支持的参数详细类型可以通过上面的<code>modinfo bonding</code>查看，在上述示例中，具体包含：<ul><li><code>mode=4</code>：指定绑定模式为模式4（802.3ad 动态链路聚合）。这种模式使用LACP（链路聚合控制协议）来自动协商链路聚合。</li><li><code>miimon=100</code>：链路监控间隔时间，单位为毫秒。这里设置为100ms，意味着系统每100毫秒检查一次链路状态。</li><li><code>xmit_hash_policy=layer3+4</code>：传输哈希策略，这里设置为基于第三层（IP地址）和第四层（TCP&#x2F;UDP端口号）的哈希。这有助于在多个物理接口之间均匀分布流量。</li></ul></li><li><code>IPADDR=192.168.11.10</code>：为这个绑定接口静态配置的IP地址。</li><li><code>NETMASK=255.255.255.0</code>：子网掩码</li></ul><ol start="4"><li>创建被绑定网卡文件:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 network-scripts]# <span class="built_in">cat</span> ifcfg-enp1s0f0</span><br><span class="line">DEVICE=enp1s0f0</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">ONBOOT=<span class="built_in">yes</span></span><br><span class="line">BOOTPROTO=none</span><br><span class="line">MASTER=bond0</span><br><span class="line">SLAVE=<span class="built_in">yes</span></span><br><span class="line">HOTPLUG=no</span><br><span class="line">[root@node1 network-scripts]# <span class="built_in">cat</span> ifcfg-enp1s0f1</span><br><span class="line">DEVICE=enp1s0f1</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">ONBOOT=<span class="built_in">yes</span></span><br><span class="line">BOOTPROTO=none</span><br><span class="line">MASTER=bond0</span><br><span class="line">SLAVE=<span class="built_in">yes</span></span><br><span class="line">HOTPLUG=no</span><br></pre></td></tr></table></figure>参数释义:</li></ol><ul><li><code>DEVICE=enp1s0f1</code>：指定这个配置是用于名为enp1s0f1的设备。enp1s0f1是物理网络接口的名称，遵循现代Linux的命名约定（基于硬件属性和位置）。</li><li><code>TYPE=Ethernet</code>：表明这个设备是一个以太网接口。</li><li><code>ONBOOT=yes</code>：在系统启动时自动启动这个网络接口。</li><li><code>BOOTPROTO=none</code>：不使用任何启动协议（如DHCP）来获取IP地址。这意味着这个接口将不会从DHCP服务器获取IP配置，而是可能需要静态配置（尽管作为绑定接口的从接口，它通常不会直接分配IP地址）。</li><li><code>MASTER=bond0</code>：指定这个接口的主接口（master interface）是bond0。这意味着enp1s0f1将作为bond0绑定接口的一个从接口。</li><li><code>SLAVE=yes</code>：表明这个接口是一个从接口（slave interface），它是绑定到MASTER指定的主接口上的。</li><li><code>HOTPLUG=no</code>：禁用热插拔功能。这通常用于确保在系统启动时或配置更改时，接口不会被自动激活或禁用，而是根据配置文件中的ONBOOT设置来管理。</li></ul><ol start="4"><li>配置完成后，重启网络:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure></li><li>检查网口<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 network-scripts]# ip a | grep -E &quot;bond0|enp1s0f0|enp1s0f1&quot;</span><br><span class="line">6: enp1s0f0: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc mq master bond0 state UP group default qlen 1000</span><br><span class="line">7: enp1s0f1: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc mq master bond0 state UP group default qlen 1000</span><br><span class="line">9: bond0: &lt;BROADCAST,MULTICAST,MASTER,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    inet 192.168.11.11/24 brd 192.168.11.255 scope global noprefixroute bond0</span><br></pre></td></tr></table></figure>可以看到 enp1s0f0 和 enp1s0f1 网卡的状态都是 slave，都以 bond0 为 master</li></ol><h1 id="bond-测试"><a href="#bond-测试" class="headerlink" title="bond 测试"></a>bond 测试</h1><p>在配置完 bond0 之后，我们可以看一下 bond0 的具体情况</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 network-scripts]# ethtool bond0</span><br><span class="line">Settings <span class="keyword">for</span> bond0:</span><br><span class="line">Supported ports: [ ]</span><br><span class="line">Supported <span class="built_in">link</span> modes:   Not reported</span><br><span class="line">Supported pause frame use: No</span><br><span class="line">Supports auto-negotiation: No</span><br><span class="line">Supported FEC modes: Not reported</span><br><span class="line">Advertised <span class="built_in">link</span> modes:  Not reported</span><br><span class="line">Advertised pause frame use: No</span><br><span class="line">Advertised auto-negotiation: No</span><br><span class="line">Advertised FEC modes: Not reported</span><br><span class="line">Speed: 200000Mb/s</span><br><span class="line">Duplex: Full</span><br><span class="line">Port: Other</span><br><span class="line">PHYAD: 0</span><br><span class="line">Transceiver: internal</span><br><span class="line">Auto-negotiation: off</span><br><span class="line">Link detected: <span class="built_in">yes</span></span><br></pre></td></tr></table></figure><p>这里的网卡速度变成了 200G，也就是聚合成功，如果显示的还是 100G，那么是有问题的，需要对配置进行检查，包括交换机侧是否已经开启支持该功能的配置。</p><p>详细的信息也可以通过以下方式查看:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 network-scripts]# <span class="built_in">cat</span> /proc/net/bonding/bond0</span><br><span class="line">Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)</span><br><span class="line"></span><br><span class="line">Bonding Mode: IEEE 802.3ad Dynamic <span class="built_in">link</span> aggregation</span><br><span class="line">Transmit Hash Policy: layer3+4 (1)</span><br><span class="line">MII Status: up</span><br><span class="line">MII Polling Interval (ms): 100</span><br><span class="line">Up Delay (ms): 0</span><br><span class="line">Down Delay (ms): 0</span><br><span class="line">Peer Notification Delay (ms): 0</span><br><span class="line"></span><br><span class="line">802.3ad info</span><br><span class="line">LACP rate: slow</span><br><span class="line">Min links: 0</span><br><span class="line">Aggregator selection policy (ad_select): stable</span><br><span class="line">System priority: 65535</span><br><span class="line">System MAC address: 9c:63:c0:0b:37:4e</span><br><span class="line">Active Aggregator Info:</span><br><span class="line">Aggregator ID: 5</span><br><span class="line">Number of ports: 2</span><br><span class="line">Actor Key: 29</span><br><span class="line">Partner Key: 2897</span><br><span class="line">Partner Mac Address: 3c:c7:86:87:8a:21</span><br><span class="line"></span><br><span class="line">Slave Interface: enp1s0f0</span><br><span class="line">MII Status: up</span><br><span class="line">Speed: 100000 Mbps</span><br><span class="line">Duplex: full</span><br><span class="line">Link Failure Count: 0</span><br><span class="line">Permanent HW addr: 9c:63:c0:0b:37:4e</span><br><span class="line">Slave queue ID: 0</span><br><span class="line">Aggregator ID: 5</span><br><span class="line">Actor Churn State: none</span><br><span class="line">Partner Churn State: none</span><br><span class="line">Actor Churned Count: 0</span><br><span class="line">Partner Churned Count: 1</span><br><span class="line">details actor lacp pdu:</span><br><span class="line">    system priority: 65535</span><br><span class="line">    system mac address: 9c:63:c0:0b:37:4e</span><br><span class="line">    port key: 29</span><br><span class="line">    port priority: 255</span><br><span class="line">    port number: 1</span><br><span class="line">    port state: 61</span><br><span class="line">details partner lacp pdu:</span><br><span class="line">    system priority: 32768</span><br><span class="line">    system mac address: 3c:c7:86:87:8a:21</span><br><span class="line">    oper key: 2897</span><br><span class="line">    port priority: 32768</span><br><span class="line">    port number: 1</span><br><span class="line">    port state: 61</span><br><span class="line"></span><br><span class="line">Slave Interface: enp1s0f1</span><br><span class="line">MII Status: up</span><br><span class="line">Speed: 100000 Mbps</span><br><span class="line">Duplex: full</span><br><span class="line">Link Failure Count: 0</span><br><span class="line">Permanent HW addr: 9c:63:c0:0b:37:4f</span><br><span class="line">Slave queue ID: 0</span><br><span class="line">Aggregator ID: 5</span><br><span class="line">Actor Churn State: none</span><br><span class="line">Partner Churn State: none</span><br><span class="line">Actor Churned Count: 1</span><br><span class="line">Partner Churned Count: 1</span><br><span class="line">details actor lacp pdu:</span><br><span class="line">    system priority: 65535</span><br><span class="line">    system mac address: 9c:63:c0:0b:37:4e</span><br><span class="line">    port key: 29</span><br><span class="line">    port priority: 255</span><br><span class="line">    port number: 2</span><br><span class="line">    port state: 61</span><br><span class="line">details partner lacp pdu:</span><br><span class="line">    system priority: 32768</span><br><span class="line">    system mac address: 3c:c7:86:87:8a:21</span><br><span class="line">    oper key: 2897</span><br><span class="line">    port priority: 32768</span><br><span class="line">    port number: 2</span><br><span class="line">    port state: 61</span><br></pre></td></tr></table></figure><h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><p>在网卡bond 做完之后，我们需要对性能进行测试，测试一下网卡的带宽是否能达到期望的要求,比较常用的测试工具有 <code>iperf</code> 和 <code>netperf</code>, 我们这里使用<code>iperf</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在服务器和客户端安装 iperf, 这里需要注意的是 iperf 有两个版本， iperf3 需要采用多服务器模式才可以打到性能要求，所以这里安装 iperf2</span></span><br><span class="line">yum install -y iperf <span class="comment"># 安装iperf2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 服务器端（做 bond的服务器）启动 server</span></span><br><span class="line">iperf -s -p 9999</span><br><span class="line"></span><br><span class="line"><span class="comment"># 客户端发起请求</span></span><br><span class="line">iperf -c 192.168.11.11 -p 9999 -P 200 -t 100 <span class="comment"># 200个线程，持续 100s</span></span><br></pre></td></tr></table></figure><p>等完成后，观察测试结果:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/149a73567dc03d8655a97671348dce2d.png" alt="测试结果" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">测试结果</span></div></div><p>可以看到这里的网卡总带宽跑到了 197Gb&#x2F;s,已经接近跑满。同时我们也可以观察下网卡的监控:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/image.png" alt="网卡监控" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">网卡监控</span></div></div><p>可以看到 bond 的流量均匀的打到了两个slave 网卡上。</p><h2 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h2><p>在网卡bond 完成之后，有的时候测试的性能可能并不理想，那么这个时候一般有以下方法进行调优，以 bond4 为例:</p><h3 id="确保-slave-网卡均匀的接收到了流量"><a href="#确保-slave-网卡均匀的接收到了流量" class="headerlink" title="确保 slave 网卡均匀的接收到了流量"></a>确保 slave 网卡均匀的接收到了流量</h3><p>因为bond4 是动态聚合类型的，需要两张网卡都接收到流量，我们可以通过监控查看网卡的流量情况，以 prometheus 为例,可以通过以下指标查看:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rate(node_network_receive_packets_total&#123;node=&quot;xxx&quot;&#125;[1m])</span><br></pre></td></tr></table></figure><h3 id="启用-Jumbo-Frames"><a href="#启用-Jumbo-Frames" class="headerlink" title="启用 Jumbo Frames"></a>启用 Jumbo Frames</h3><p>启用 Jumbo Frames 是指将网卡的最大传输单元（MTU，Maximum Transmission Unit）增大到标准以太网帧（1500 字节）以上，通常设置为 9000 字节左右。Jumbo Frames 可以显著提高传输效率，减少 CPU 开销，在需要传输大量数据的场景中（如高性能计算和数据中心网络），启用 Jumbo Frames 能提升网络性能。</p><p>优势:<br>1.减少数据包数量：由于每个数据包承载的数据更多，数据传输时需要的包数量会减少，进而减少网络和主机的负载。<br>2.降低 CPU 开销：更少的数据包意味着更少的中断请求（IRQ），降低了 CPU 的处理压力，尤其在高吞吐量网络下效果更明显。<br>3.提高吞吐量：在大数据传输的场景中，Jumbo Frames 可以有效增加带宽利用率。</p><p>操作步骤:</p><ol><li>查看当前网卡的 mtu<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# ip a show eth0</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br></pre></td></tr></table></figure>可以看到当前网卡的 mtu 是 1500</li><li>设置 mtu 为 9000<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> dev &lt;网卡名&gt; mtu 9000</span><br><span class="line"><span class="comment"># 如果需要重启之后也保持，那么需要在配置文件中添加</span></span><br><span class="line">MTU=9000</span><br></pre></td></tr></table></figure></li></ol><h3 id="系统调优"><a href="#系统调优" class="headerlink" title="系统调优"></a>系统调优</h3><ul><li>调整 CPU 中断绑定: 如果两张网卡的中断处理都绑定在同一个 CPU 核心上，可能会导致性能瓶颈。可以使用 irqbalance 或手动调整中断的 CPU 绑定，将中断分布到多个 CPU 核心，以减少单核负载。</li><li>优化队列数量和大小：可以通过调整网卡的队列数量和大小，提高网卡的并行处理能力<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ethtool -G enp133s0f1 rx 8192 tx 8192</span><br></pre></td></tr></table></figure></li><li>调整网络栈参数：通过 &#x2F;etc&#x2F;sysctl.conf 文件进行 TCP 参数优化，例如增大 TCP 缓冲区，优化内核参数以支持高吞吐量：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 增加 TCP 缓冲区大小</span><br><span class="line">net.core.rmem_max = 16777216</span><br><span class="line">net.core.wmem_max = 16777216</span><br><span class="line">net.ipv4.tcp_rmem = 4096 87380 16777216</span><br><span class="line">net.ipv4.tcp_wmem = 4096 65536 16777216</span><br></pre></td></tr></table></figure></li></ul><h2 id="故障测试"><a href="#故障测试" class="headerlink" title="故障测试"></a>故障测试</h2><p>既然是双网卡做 bond，尝试关闭其中一个网卡进行测试:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# ifdown enp1s0f0</span><br></pre></td></tr></table></figure><p>然后继续使用 iperf 进行测试，可以看到带宽只能跑到接近 100G</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/image-2.png" alt="测试结果" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">测试结果</span></div></div><p>bond0 和 另外一张up 的网卡有流量并且曲线重合</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/image-1.png" alt="网卡监控" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">网卡监控</span></div></div><p>从结果来看符合预期</p><h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>此文章已经发布在个人博客上: baixiaozhou.github.io<br>码字不易，希望文章对各位读者朋友们有所帮助和启发，文章的撰写有的时候是根据自己的经验和遇到的一些场景所思考的，存在不足和错误的地方，希望读者朋友们指正</p>]]></content>
    
    
    <summary type="html">网卡绑定技术</summary>
    
    
    
    <category term="网卡绑定" scheme="http://baixiaozhou.github.io/categories/%E7%BD%91%E5%8D%A1%E7%BB%91%E5%AE%9A/"/>
    
    
    <category term="Linux" scheme="http://baixiaozhou.github.io/tags/Linux/"/>
    
    <category term="网卡绑定" scheme="http://baixiaozhou.github.io/tags/%E7%BD%91%E5%8D%A1%E7%BB%91%E5%AE%9A/"/>
    
  </entry>
  
  <entry>
    <title>NFS 详解</title>
    <link href="http://baixiaozhou.github.io/p/NFS-%E8%AF%A6%E8%A7%A3/"/>
    <id>http://baixiaozhou.github.io/p/NFS-%E8%AF%A6%E8%A7%A3/</id>
    <published>2024-10-09T02:51:43.000Z</published>
    <updated>2024-11-04T08:32:39.643Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>NFS 全拼 Network File System， 由 Sun Microsystems 于 1984 年开发，旨在允许不同机器间通过网络共享文件。它是一个基于客户端-服务器架构的分布式文件系统协议，允许多个客户端系统像访问本地存储一样访问远程服务器上的文件。</p><p>NFS 使得用户可以通过网络访问远程计算机上的文件，并对文件进行读取、写入、删除等操作，这些操作像本地文件系统一样透明，用户无需关心文件实际存储的位置。</p><h1 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h1><p>NFS 关键概念</p><ol><li>服务器和客户端：<ul><li>服务器：存储文件并将文件系统通过网络共享给客户端。</li><li>客户端：通过网络挂载服务器提供的文件系统，并进行文件操作。</li></ul></li><li>   挂载（Mounting）：<ul><li>客户端使用 NFS 挂载（mount）服务器上共享的文件系统。挂载后，远程文件系统可以像本地文件系统一样进行访问。</li></ul></li><li>   RPC（Remote Procedure Call）：<ul><li>NFS 基于 RPC（远程过程调用）协议进行通信。通过 RPC，客户端发送请求，服务器响应请求并返回相应的数据。</li></ul></li><li>   文件句柄：<ul><li>NFS 使用文件句柄来唯一标识远程文件。客户端在访问文件时，文件句柄将传递给服务器以确定目标文件。</li></ul></li><li>   Stateless（无状态）协议：<ul><li>早期版本的 NFS 是无状态的，这意味着服务器不保存任何有关客户端的信息。每个请求都独立处理，且服务器不跟踪会话状态。</li><li>无状态的设计提高了系统的容错性，但也限制了某些功能。现代的 NFS 引入了一些状态管理来增强功能。</li></ul></li><li>   版本：<ul><li>NFS 经过多次版本迭代，最常用的版本有 NFSv3 和 NFSv4。</li><li>NFSv3：最广泛使用的版本，支持较大的文件系统，并增加了多种优化。</li><li>NFSv4：引入了状态管理、增强的安全性以及简化了防火墙穿越。</li></ul></li><li>   文件锁定：<ul><li>NFS 支持文件锁定机制，使得客户端可以在多人同时操作同一文件时避免冲突。NFSv4 将锁定功能内置，而 NFSv3 需要外部锁定协议（如 NLM）。</li></ul></li><li>   安全性：<ul><li>传统的 NFS 依赖于基于 IP 地址的信任机制。现代的 NFSv4 支持通过 Kerberos 进行强身份认证。</li></ul></li><li>   性能和缓存：<ul><li>为了减少网络通信带来的延迟，NFS 客户端通常使用缓存机制。客户端可以缓存文件的部分内容和属性，并在适当的时候将缓存的数据写回服务器。</li></ul></li></ol><h1 id="部署安装"><a href="#部署安装" class="headerlink" title="部署安装"></a>部署安装</h1><p>我们以 centos 为例来进行NFS 的部署和安装:</p><ol><li><p>安装 nfs 服务(服务器端和客户端都需要安装)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nfs-utils</span><br></pre></td></tr></table></figure><p>安装完毕后，我们可以查看下这个包提供的文件信息:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">/etc/exports.d</span><br><span class="line">/etc/gssproxy/24-nfs-server.conf</span><br><span class="line">/etc/modprobe.d/lockd.conf</span><br><span class="line">/etc/nfs.conf</span><br><span class="line">/etc/nfsmount.conf</span><br><span class="line">/etc/request-key.d/id_resolver.conf</span><br><span class="line">/etc/sysconfig/nfs</span><br><span class="line">/sbin/mount.nfs</span><br><span class="line">/sbin/mount.nfs4</span><br><span class="line">/sbin/osd_login</span><br><span class="line">/sbin/rpc.statd</span><br><span class="line">/sbin/umount.nfs</span><br><span class="line">/sbin/umount.nfs4</span><br><span class="line">/usr/lib/systemd/scripts/nfs-utils_env.sh</span><br><span class="line">/usr/lib/systemd/system-generators/nfs-server-generator</span><br><span class="line">/usr/lib/systemd/system-generators/rpc-pipefs-generator</span><br><span class="line">/usr/lib/systemd/system/auth-rpcgss-module.service</span><br><span class="line">/usr/lib/systemd/system/nfs-blkmap.service</span><br><span class="line">/usr/lib/systemd/system/nfs-client.target</span><br><span class="line">/usr/lib/systemd/system/nfs-config.service</span><br><span class="line">/usr/lib/systemd/system/nfs-idmap.service</span><br><span class="line">/usr/lib/systemd/system/nfs-idmapd.service</span><br><span class="line">/usr/lib/systemd/system/nfs-lock.service</span><br><span class="line">/usr/lib/systemd/system/nfs-mountd.service</span><br><span class="line">/usr/lib/systemd/system/nfs-secure.service</span><br><span class="line">/usr/lib/systemd/system/nfs-server.service</span><br><span class="line">/usr/lib/systemd/system/nfs-utils.service</span><br><span class="line">/usr/lib/systemd/system/nfs.service</span><br><span class="line">/usr/lib/systemd/system/nfslock.service</span><br><span class="line">/usr/lib/systemd/system/proc-fs-nfsd.mount</span><br><span class="line">/usr/lib/systemd/system/rpc-gssd.service</span><br><span class="line">/usr/lib/systemd/system/rpc-statd-notify.service</span><br><span class="line">/usr/lib/systemd/system/rpc-statd.service</span><br><span class="line">/usr/lib/systemd/system/rpc_pipefs.target</span><br><span class="line">/usr/lib/systemd/system/rpcgssd.service</span><br><span class="line">/usr/lib/systemd/system/rpcidmapd.service</span><br><span class="line">/usr/lib/systemd/system/var-lib-nfs-rpc_pipefs.mount</span><br><span class="line">/usr/sbin/blkmapd</span><br><span class="line">/usr/sbin/exportfs</span><br><span class="line">/usr/sbin/mountstats</span><br><span class="line">/usr/sbin/nfsdcltrack</span><br><span class="line">/usr/sbin/nfsidmap</span><br><span class="line">/usr/sbin/nfsiostat</span><br><span class="line">/usr/sbin/nfsstat</span><br><span class="line">/usr/sbin/rpc.gssd</span><br><span class="line">/usr/sbin/rpc.idmapd</span><br><span class="line">/usr/sbin/rpc.mountd</span><br><span class="line">/usr/sbin/rpc.nfsd</span><br><span class="line">/usr/sbin/rpcdebug</span><br><span class="line">/usr/sbin/showmount</span><br><span class="line">/usr/sbin/sm-notify</span><br><span class="line">/usr/sbin/start-statd</span><br><span class="line">/usr/share/doc/nfs-utils-1.3.0</span><br><span class="line">/usr/share/doc/nfs-utils-1.3.0/ChangeLog</span><br><span class="line">/usr/share/doc/nfs-utils-1.3.0/KNOWNBUGS</span><br><span class="line">/usr/share/doc/nfs-utils-1.3.0/NEW</span><br><span class="line">/usr/share/doc/nfs-utils-1.3.0/README</span><br><span class="line">/usr/share/doc/nfs-utils-1.3.0/THANKS</span><br><span class="line">/usr/share/doc/nfs-utils-1.3.0/TODO</span><br><span class="line">/usr/share/man/man5/exports.5.gz</span><br><span class="line">/usr/share/man/man5/nfs.5.gz</span><br><span class="line">/usr/share/man/man5/nfs.conf.5.gz</span><br><span class="line">/usr/share/man/man5/nfsmount.conf.5.gz</span><br><span class="line">/usr/share/man/man7/nfs.systemd.7.gz</span><br><span class="line">/usr/share/man/man7/nfsd.7.gz</span><br><span class="line">/usr/share/man/man8/blkmapd.8.gz</span><br><span class="line">/usr/share/man/man8/exportfs.8.gz</span><br><span class="line">/usr/share/man/man8/gssd.8.gz</span><br><span class="line">/usr/share/man/man8/idmapd.8.gz</span><br><span class="line">/usr/share/man/man8/mount.nfs.8.gz</span><br><span class="line">/usr/share/man/man8/mountd.8.gz</span><br><span class="line">/usr/share/man/man8/mountstats.8.gz</span><br><span class="line">/usr/share/man/man8/nfsd.8.gz</span><br><span class="line">/usr/share/man/man8/nfsdcltrack.8.gz</span><br><span class="line">/usr/share/man/man8/nfsidmap.8.gz</span><br><span class="line">/usr/share/man/man8/nfsiostat.8.gz</span><br><span class="line">/usr/share/man/man8/nfsstat.8.gz</span><br><span class="line">/usr/share/man/man8/rpc.gssd.8.gz</span><br><span class="line">/usr/share/man/man8/rpc.idmapd.8.gz</span><br><span class="line">/usr/share/man/man8/rpc.mountd.8.gz</span><br><span class="line">/usr/share/man/man8/rpc.nfsd.8.gz</span><br><span class="line">/usr/share/man/man8/rpc.sm-notify.8.gz</span><br><span class="line">/usr/share/man/man8/rpc.statd.8.gz</span><br><span class="line">/usr/share/man/man8/rpcdebug.8.gz</span><br><span class="line">/usr/share/man/man8/showmount.8.gz</span><br><span class="line">/usr/share/man/man8/sm-notify.8.gz</span><br><span class="line">/usr/share/man/man8/statd.8.gz</span><br><span class="line">/usr/share/man/man8/umount.nfs.8.gz</span><br><span class="line">/var/lib/nfs</span><br><span class="line">/var/lib/nfs/etab</span><br><span class="line">/var/lib/nfs/rmtab</span><br><span class="line">/var/lib/nfs/rpc_pipefs</span><br><span class="line">/var/lib/nfs/statd</span><br><span class="line">/var/lib/nfs/statd/sm</span><br><span class="line">/var/lib/nfs/statd/sm.bak</span><br><span class="line">/var/lib/nfs/state</span><br><span class="line">/var/lib/nfs/v4recovery</span><br><span class="line">/var/lib/nfs/xtab</span><br></pre></td></tr></table></figure><p>其中包含了一些 nfs 相关的服务，服务的详细介绍如下:</p><table><thead><tr><th>服务名称</th><th>功能描述</th><th>详细说明</th></tr></thead><tbody><tr><td><code>nfs-blkmap.service</code></td><td>支持块映射功能</td><td>用于支持在 NFS 文件系统上的块映射，适合复杂的存储需求，普通 NFS 共享中很少使用。</td></tr><tr><td><code>nfs-idmapd.service</code></td><td>提供用户和组的 ID 映射功能</td><td>NFSv4 所需，负责将用户名和组名映射为 UID 和 GID，用于身份验证。</td></tr><tr><td><code>nfs-lock.service</code></td><td>提供文件锁定功能</td><td>支持 NFSv3 和之前版本的文件锁定，防止多个客户端同时写入导致的数据损坏。</td></tr><tr><td><code>nfs-mountd.service</code></td><td>处理客户端挂载请求</td><td>NFSv3 所需的挂载守护进程，用于管理客户端挂载请求并验证权限。</td></tr><tr><td><code>nfs-secure.service</code></td><td>提供安全的 RPC 服务</td><td>提供基于 Kerberos 认证的安全 RPC 连接，适合需要身份验证的 NFS 环境。</td></tr><tr><td><code>nfs.service</code></td><td>NFS 客户端和服务器主服务</td><td>核心服务，通过 <code>nfs-utils</code> 包提供基本的 NFS 客户端和服务器功能。</td></tr><tr><td><code>nfs-config.service</code></td><td>加载和应用 NFS 配置</td><td>启动 NFS 服务时自动加载配置文件，确保系统配置是最新的。</td></tr><tr><td><code>nfs-idmap.service</code></td><td>NFSv4 的用户 ID 映射</td><td>与 <code>nfs-idmapd</code> 类似，NFSv4 环境中用于将用户和组 ID 映射，以匹配权限。</td></tr><tr><td><code>nfs-rquotad.service</code></td><td>远程磁盘配额管理</td><td>允许设置和查询 NFS 共享中的磁盘配额，适合需要磁盘配额管理的场景。</td></tr><tr><td><code>nfs-server.service</code></td><td>NFS 服务器主服务</td><td>负责处理服务器端的 NFS 共享请求，是 NFS 服务的核心。</td></tr><tr><td><code>nfs-utils.service</code></td><td>管理 NFS 的核心工具包</td><td><code>nfs-utils</code> 提供 NFS 的工具和守护进程，包括 <code>nfsd</code> 和 <code>rpcbind</code>。</td></tr></tbody></table></li><li><p>我们这里只模拟下简单的挂载，所以启动 nfs-server 服务并设置开机自启动（服务器端操作）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start nfs-server</span><br><span class="line">systemctl <span class="built_in">enable</span> nfs-server</span><br></pre></td></tr></table></figure></li><li><p>配置共享目录 （服务器端操作）</p></li></ol><ul><li>创建共享目录,例如目录为&#x2F;mnt&#x2F;nfs_share:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /mnt/nfs_share</span><br></pre></td></tr></table></figure></li><li>设置权限，允许其他用户访问:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> -R 777 /mnt/nfs_share</span><br></pre></td></tr></table></figure></li><li>编辑 &#x2F;etc&#x2F;exports 文件以配置共享路径及其权限。在文件末尾添加以下内容：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/mnt/nfs_share *(rw,<span class="built_in">sync</span>,no_root_squash)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">这里的配置选项含义如下：</span><br><span class="line">•* 表示允许所有 IP 访问。如果需要限制特定 IP，可以替换为特定的 IP 地址或子网。</span><br><span class="line">•rw 表示读写权限。</span><br><span class="line">•<span class="built_in">sync</span> 确保数据同步写入。</span><br><span class="line">•no_root_squash 允许客户端以 root 身份访问。</span><br></pre></td></tr></table></figure></li></ul><ol start="4"><li><p>应用 NFS 配置 （服务器端操作）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exportfs -r</span><br></pre></td></tr></table></figure><p>应用完成后，可以查看:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 mnt]# exportfs -s</span><br><span class="line">/mnt/nfs_share  *(<span class="built_in">sync</span>,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)</span><br></pre></td></tr></table></figure></li><li><p>配置防火墙,确保防火墙允许 NFS 服务的流量通过。可以使用以下命令打开相应的端口(服务器端操作，测试环境可以直接关闭)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --permanent --add-service=nfs</span><br><span class="line">firewall-cmd --permanent --add-service=mountd</span><br><span class="line">firewall-cmd --permanent --add-service=rpc-bind</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure></li><li><p>客户端进行挂载</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /mnt/test</span><br><span class="line">mount -t nfs serverip:/mnt/nfs_share /mnt/test</span><br></pre></td></tr></table></figure><p>挂载完成后，通过 df 查看:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# <span class="built_in">df</span> -h</span><br><span class="line">Filesystem                    Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3                     1.1T  257G  787G  25% /</span><br><span class="line">tmpfs                         126G  2.3M  126G   1% /tmp</span><br><span class="line">node2:/mnt/nfs_share          1.1T  103G  941G  10% /mnt/test</span><br></pre></td></tr></table></figure><p>至此，nfs 部署和挂载就完成了</p></li></ol><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>我们可以在客户端的挂载目录上，进行文件读写,比如创建文件，写入以及读取等</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# <span class="built_in">cd</span> /mnt/test/</span><br><span class="line">[root@node1 <span class="built_in">test</span>]# <span class="built_in">ls</span></span><br><span class="line">[root@node1 <span class="built_in">test</span>]# <span class="built_in">touch</span> test.txt</span><br><span class="line">[root@node1 <span class="built_in">test</span>]# <span class="built_in">echo</span> 123 &gt; test.txt</span><br><span class="line">[root@node1 <span class="built_in">test</span>]# <span class="built_in">cat</span> test.txt</span><br><span class="line">123</span><br></pre></td></tr></table></figure><p>在服务器端的 &#x2F;mnt&#x2F;nfs_share目录下可以看到同样的文件信息</p>]]></content>
    
    
    <summary type="html">NFS 简介</summary>
    
    
    
    <category term="分布式存储" scheme="http://baixiaozhou.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"/>
    
    
    <category term="NFS" scheme="http://baixiaozhou.github.io/tags/NFS/"/>
    
    <category term="存储" scheme="http://baixiaozhou.github.io/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Nginx详解</title>
    <link href="http://baixiaozhou.github.io/p/Nginx%E8%AF%A6%E8%A7%A3/"/>
    <id>http://baixiaozhou.github.io/p/Nginx%E8%AF%A6%E8%A7%A3/</id>
    <published>2024-09-12T02:47:54.000Z</published>
    <updated>2024-12-13T06:14:54.458Z</updated>
    
    <content type="html"><![CDATA[<!-- Your content starts here --><h1 id="Nginx-简介"><a href="#Nginx-简介" class="headerlink" title="Nginx 简介"></a>Nginx 简介</h1><p>Nginx 是一个高性能的 HTTP 和反向代理服务器，同时也可以作为 IMAP&#x2F;POP3 邮件代理服务器。Nginx 以其轻量级、速度快、并发处理能力强等特点而闻名，广泛用于网站架构中作为反向代理、负载均衡器和静态内容服务器。</p><h2 id="Nginx-的主要特点"><a href="#Nginx-的主要特点" class="headerlink" title="Nginx 的主要特点"></a>Nginx 的主要特点</h2><ol><li><p><strong>高并发处理能力</strong>：</p><ul><li>Nginx 采用异步、事件驱动的架构，与传统的 Apache 等基于进程或线程的模型不同。它可以同时处理大量并发连接，具有很高的性能和较低的资源消耗。</li></ul></li><li><p><strong>反向代理</strong>：</p><ul><li>Nginx 作为反向代理服务器时，可以将客户端的请求转发给后端服务器（如 Apache、Tomcat、Node.js 等），然后将后端的响应返回给客户端。常用于负载均衡、缓存加速和安全增强。</li></ul></li><li><p><strong>负载均衡</strong>：</p><ul><li>Nginx 支持多种负载均衡算法，如轮询（Round Robin）、最少连接（Least Connections）、IP 哈希等，能够将请求分发到多个后端服务器以提高应用的可靠性和处理能力。</li></ul></li><li><p><strong>静态内容服务</strong>：</p><ul><li>Nginx 在处理静态文件（如 HTML、CSS、JS、图片等）方面非常高效，常用于静态文件托管。它可以作为内容分发网络（CDN）的一部分来加速网页加载。</li></ul></li><li><p><strong>模块化设计</strong>：</p><ul><li>Nginx 支持模块化设计，允许根据需要启用或禁用功能模块。可以通过模块扩展 Nginx 的功能，如 Lua、SSL、缓存等。</li></ul></li><li><p><strong>内存消耗低</strong>：</p><ul><li>Nginx 的内存占用相对较低，适合高并发环境下的稳定运行。其设计目标是处理大量的请求而不占用过多的资源。</li></ul></li><li><p><strong>高可扩展性</strong>：</p><ul><li>通过编写自定义模块，Nginx 可以与多种语言（如 Lua、Python、Go）集成，极大地增强了其功能和灵活性。OpenResty 就是基于 Nginx 的一个扩展框架，集成了 Lua 来支持动态处理。</li></ul></li><li><p><strong>HTTPS&#x2F;SSL 支持</strong>：</p><ul><li>Nginx 具备完整的 HTTPS 支持，可以通过简单的配置启用 SSL&#x2F;TLS 加密，从而提高网站的安全性。</li></ul></li></ol><h2 id="Nginx-的常见使用场景"><a href="#Nginx-的常见使用场景" class="headerlink" title="Nginx 的常见使用场景"></a>Nginx 的常见使用场景</h2><ol><li><p><strong>静态内容服务</strong>：</p><ul><li>Nginx 非常适合用于提供网站的静态资源，如 HTML 文件、图片、CSS、JavaScript 文件等。</li></ul></li><li><p><strong>反向代理和负载均衡</strong>：</p><ul><li>Nginx 常用于前端反向代理，将客户端的请求转发给后端服务器集群。通过负载均衡算法，Nginx 能有效分配请求并提高后端服务器的利用率和可靠性。</li></ul></li><li><p><strong>API 网关</strong>：</p><ul><li>在微服务架构中，Nginx 常作为 API 网关来路由和管理 API 请求，提供身份验证、速率限制等功能。</li></ul></li><li><p><strong>缓存服务器</strong>：</p><ul><li>Nginx 可以作为缓存代理，缓存静态和动态内容，提高性能并减少后端服务器的负担。</li></ul></li><li><p><strong>邮件代理服务器</strong>：</p><ul><li>除了 HTTP 服务器，Nginx 还可以用作 IMAP&#x2F;POP3&#x2F;SMTP 代理服务器，处理邮件请求并进行负载均衡。</li></ul></li></ol><h2 id="Nginx-vs-Apache"><a href="#Nginx-vs-Apache" class="headerlink" title="Nginx vs. Apache"></a>Nginx vs. Apache</h2><ul><li><p><strong>架构</strong>：</p><ul><li>Nginx 是基于事件驱动的异步架构，适合高并发；Apache 使用的是基于进程&#x2F;线程的架构，每个请求占用一个进程或线程，容易在高并发场景下消耗大量资源。</li></ul></li><li><p><strong>性能</strong>：</p><ul><li>在处理大量静态内容和高并发请求时，Nginx 的表现优于 Apache，且内存消耗更少。</li></ul></li><li><p><strong>配置和模块</strong>：</p><ul><li>Nginx 的模块在编译时确定，而 Apache 支持运行时动态加载模块，因此 Apache 在模块化灵活性方面稍胜一筹。</li></ul></li></ul><h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><div class="tag-plugin image"><div class="image-bg"><img src="https://pic3.zhimg.com/v2-1cd1dab80fc4b50113439120ed54ff22_r.jpg" alt="Nginx 整体框架" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">Nginx 整体框架</span></div></div><h1 id="部署安装"><a href="#部署安装" class="headerlink" title="部署安装"></a>部署安装</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol><li>centos:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nginx</span><br><span class="line">systemctl start nginx</span><br><span class="line">systemctl enable nginx</span><br></pre></td></tr></table></figure></li><li>docker<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull nginx</span><br><span class="line">docker run -d --name nginx -p 8080:80 nginx</span><br></pre></td></tr></table></figure></li></ol><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><p>我们先看一下 nginx 包中提供的相关组件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 配置</span></span><br><span class="line">/etc/logrotate.d/nginx</span><br><span class="line">/etc/nginx/fastcgi.conf</span><br><span class="line">/etc/nginx/fastcgi.conf.default</span><br><span class="line">/etc/nginx/fastcgi_params</span><br><span class="line">/etc/nginx/fastcgi_params.default</span><br><span class="line">/etc/nginx/koi-utf</span><br><span class="line">/etc/nginx/koi-win</span><br><span class="line">/etc/nginx/mime.types</span><br><span class="line">/etc/nginx/mime.types.default</span><br><span class="line">/etc/nginx/nginx.conf</span><br><span class="line">/etc/nginx/nginx.conf.default</span><br><span class="line">/etc/nginx/scgi_params</span><br><span class="line">/etc/nginx/scgi_params.default</span><br><span class="line">/etc/nginx/uwsgi_params</span><br><span class="line">/etc/nginx/uwsgi_params.default</span><br><span class="line">/etc/nginx/win-utf</span><br><span class="line"><span class="comment">## 服务及程序</span></span><br><span class="line">/usr/bin/nginx-upgrade</span><br><span class="line">/usr/lib/systemd/system/nginx.service</span><br><span class="line">/usr/lib64/nginx/modules</span><br><span class="line">/usr/sbin/nginx</span><br><span class="line"><span class="comment">## 文档</span></span><br><span class="line">/usr/share/doc/nginx-1.20.1</span><br><span class="line">/usr/share/doc/nginx-1.20.1/CHANGES</span><br><span class="line">/usr/share/doc/nginx-1.20.1/README</span><br><span class="line">/usr/share/doc/nginx-1.20.1/README.dynamic</span><br><span class="line">/usr/share/doc/nginx-1.20.1/UPGRADE-NOTES-1.6-to-1.10</span><br><span class="line">/usr/share/licenses/nginx-1.20.1</span><br><span class="line">/usr/share/licenses/nginx-1.20.1/LICENSE</span><br><span class="line">/usr/share/man/man3/nginx.3pm.gz</span><br><span class="line">/usr/share/man/man8/nginx-upgrade.8.gz</span><br><span class="line">/usr/share/man/man8/nginx.8.gz</span><br><span class="line">/usr/share/nginx/html/404.html</span><br><span class="line">/usr/share/nginx/html/50x.html</span><br><span class="line">/usr/share/nginx/html/en-US</span><br><span class="line">/usr/share/nginx/html/icons</span><br><span class="line">/usr/share/nginx/html/icons/poweredby.png</span><br><span class="line">/usr/share/nginx/html/img</span><br><span class="line">/usr/share/nginx/html/index.html</span><br><span class="line">/usr/share/nginx/html/nginx-logo.png</span><br><span class="line">/usr/share/nginx/html/poweredby.png</span><br><span class="line">/usr/share/nginx/modules</span><br><span class="line">/usr/share/vim/vimfiles/ftdetect/nginx.vim</span><br><span class="line">/usr/share/vim/vimfiles/ftplugin/nginx.vim</span><br><span class="line">/usr/share/vim/vimfiles/indent/nginx.vim</span><br><span class="line">/usr/share/vim/vimfiles/syntax/nginx.vim</span><br><span class="line">/var/lib/nginx</span><br><span class="line">/var/lib/nginx/tmp</span><br><span class="line"><span class="comment">## 日志</span></span><br><span class="line">/var/log/nginx</span><br><span class="line">/var/log/nginx/access.log</span><br><span class="line">/var/log/nginx/error.log</span><br></pre></td></tr></table></figure><h2 id="命令操作"><a href="#命令操作" class="headerlink" title="命令操作"></a>命令操作</h2><p>我们可以看下 nginx 的命令操作和服务配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# /usr/sbin/nginx -h</span><br><span class="line">nginx version: nginx/1.20.1</span><br><span class="line">Usage: nginx [-?hvVtTq] [-s signal] [-p prefix]</span><br><span class="line">             [-e filename] [-c filename] [-g directives]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -?,-h         : this <span class="built_in">help</span></span><br><span class="line">  -v            : show version and <span class="built_in">exit</span></span><br><span class="line">  -V            : show version and configure options <span class="keyword">then</span> <span class="built_in">exit</span></span><br><span class="line">  -t            : <span class="built_in">test</span> configuration and <span class="built_in">exit</span></span><br><span class="line">  -T            : <span class="built_in">test</span> configuration, dump it and <span class="built_in">exit</span></span><br><span class="line">  -q            : suppress non-error messages during configuration testing</span><br><span class="line">  -s signal     : send signal to a master process: stop, quit, reopen, reload</span><br><span class="line">  -p prefix     : <span class="built_in">set</span> prefix path (default: /usr/share/nginx/)</span><br><span class="line">  -e filename   : <span class="built_in">set</span> error <span class="built_in">log</span> file (default: /var/log/nginx/error.log)</span><br><span class="line">  -c filename   : <span class="built_in">set</span> configuration file (default: /etc/nginx/nginx.conf)</span><br><span class="line">  -g directives : <span class="built_in">set</span> global directives out of configuration file</span><br><span class="line"></span><br><span class="line">[root@node1 ~]# systemctl <span class="built_in">cat</span> nginx.service</span><br><span class="line"><span class="comment"># /usr/lib/systemd/system/nginx.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=The nginx HTTP and reverse proxy server</span><br><span class="line">After=network-online.target remote-fs.target nss-lookup.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">PIDFile=/run/nginx.pid</span><br><span class="line"><span class="comment"># Nginx will fail to start if /run/nginx.pid already exists but has the wrong</span></span><br><span class="line"><span class="comment"># SELinux context. This might happen when running `nginx -t` from the cmdline.</span></span><br><span class="line"><span class="comment"># https://bugzilla.redhat.com/show_bug.cgi?id=1268621</span></span><br><span class="line">ExecStartPre=/usr/bin/rm -f /run/nginx.pid</span><br><span class="line">ExecStartPre=/usr/sbin/nginx -t</span><br><span class="line">ExecStart=/usr/sbin/nginx</span><br><span class="line">ExecReload=/usr/sbin/nginx -s reload</span><br><span class="line">KillSignal=SIGQUIT</span><br><span class="line">TimeoutStopSec=5</span><br><span class="line">KillMode=process</span><br><span class="line">PrivateTmp=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>nginx 命令提供的参数非常简单，包括检查配置文件、发送信号、配置文件路径、error 日志路径等。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nginx -t              <span class="comment"># 检查配置文件是否有语法错误</span></span><br><span class="line">nginx -s reload       <span class="comment"># 热加载，重新加载配置文件</span></span><br><span class="line">nginx -s stop         <span class="comment"># 快速关闭</span></span><br><span class="line">nginx -s quit         <span class="comment"># 等待工作进程处理完成后关闭</span></span><br></pre></td></tr></table></figure><h1 id="配置详解"><a href="#配置详解" class="headerlink" title="配置详解"></a>配置详解</h1><p>我们先看一下 nginx 默认的配置文件内容:</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># For more information on configuration, see:</span></span><br><span class="line"><span class="comment">#   * Official English Documentation: http://nginx.org/en/docs/</span></span><br><span class="line"><span class="comment">#   * Official Russian Documentation: http://nginx.org/ru/docs/</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">user</span> nginx;</span><br><span class="line"><span class="attribute">worker_processes</span> auto;</span><br><span class="line"><span class="attribute">error_log</span> /var/log/nginx/<span class="literal">error</span>.log;</span><br><span class="line"><span class="attribute">pid</span> /run/nginx.pid;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.</span></span><br><span class="line"><span class="attribute">include</span> /usr/share/nginx/modules/<span class="regexp">*.conf</span>;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">    <span class="attribute">worker_connections</span> <span class="number">1024</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="attribute">log_format</span>  main  <span class="string">&#x27;<span class="variable">$remote_addr</span> - <span class="variable">$remote_user</span> [<span class="variable">$time_local</span>] &quot;<span class="variable">$request</span>&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;<span class="variable">$status</span> <span class="variable">$body_bytes_sent</span> &quot;<span class="variable">$http_referer</span>&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;<span class="variable">$http_user_agent</span>&quot; &quot;<span class="variable">$http_x_forwarded_for</span>&quot;&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">access_log</span>  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">sendfile</span>            <span class="literal">on</span>;</span><br><span class="line">    <span class="attribute">tcp_nopush</span>          <span class="literal">on</span>;</span><br><span class="line">    <span class="attribute">tcp_nodelay</span>         <span class="literal">on</span>;</span><br><span class="line">    <span class="attribute">keepalive_timeout</span>   <span class="number">65</span>;</span><br><span class="line">    <span class="attribute">types_hash_max_size</span> <span class="number">4096</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">include</span>             /etc/nginx/mime.types;</span><br><span class="line">    <span class="attribute">default_type</span>        application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load modular configuration files from the /etc/nginx/conf.d directory.</span></span><br><span class="line">    <span class="comment"># See http://nginx.org/en/docs/ngx_core_module.html#include</span></span><br><span class="line">    <span class="comment"># for more information.</span></span><br><span class="line">    <span class="attribute">include</span> /etc/nginx/conf.d/<span class="regexp">*.conf</span>;</span><br><span class="line"></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span>       <span class="number">80</span>;</span><br><span class="line">        <span class="attribute">listen</span>       [::]:<span class="number">80</span>;</span><br><span class="line">        <span class="attribute">server_name</span>  _;</span><br><span class="line">        <span class="attribute">root</span>         /usr/share/nginx/html;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load configuration files for the default server block.</span></span><br><span class="line">        <span class="attribute">include</span> /etc/nginx/default.d/<span class="regexp">*.conf</span>;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">error_page</span> <span class="number">404</span> /<span class="number">404</span>.html;</span><br><span class="line">        <span class="section">location</span> = /<span class="number">404</span>.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">error_page</span> <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span> /50x.html;</span><br><span class="line">        <span class="section">location</span> = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Settings for a TLS enabled server.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    server &#123;</span></span><br><span class="line"><span class="comment">#        listen       443 ssl http2;</span></span><br><span class="line"><span class="comment">#        listen       [::]:443 ssl http2;</span></span><br><span class="line"><span class="comment">#        server_name  _;</span></span><br><span class="line"><span class="comment">#        root         /usr/share/nginx/html;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#        ssl_certificate &quot;/etc/pki/nginx/server.crt&quot;;</span></span><br><span class="line"><span class="comment">#        ssl_certificate_key &quot;/etc/pki/nginx/private/server.key&quot;;</span></span><br><span class="line"><span class="comment">#        ssl_session_cache shared:SSL:1m;</span></span><br><span class="line"><span class="comment">#        ssl_session_timeout  10m;</span></span><br><span class="line"><span class="comment">#        ssl_ciphers HIGH:!aNULL:!MD5;</span></span><br><span class="line"><span class="comment">#        ssl_prefer_server_ciphers on;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#        # Load configuration files for the default server block.</span></span><br><span class="line"><span class="comment">#        include /etc/nginx/default.d/*.conf;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#        error_page 404 /404.html;</span></span><br><span class="line"><span class="comment">#            location = /40x.html &#123;</span></span><br><span class="line"><span class="comment">#        &#125;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#        error_page 500 502 503 504 /50x.html;</span></span><br><span class="line"><span class="comment">#            location = /50x.html &#123;</span></span><br><span class="line"><span class="comment">#        &#125;</span></span><br><span class="line"><span class="comment">#    &#125;</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以看到配置文件基本上被分为了三部分，我们可以划分为全局块，event 块和 http 块</p><h2 id="全局块"><a href="#全局块" class="headerlink" title="全局块"></a>全局块</h2><p>配置文件中是一些全局的基本配置, 除此之外还包括了一些其他的配置，主要参数如下:</p><table><thead><tr><th>参数名</th><th>含义</th><th>示例</th></tr></thead><tbody><tr><td><code>user</code></td><td>指定运行 Nginx 的用户和用户组</td><td><code>user www-data;</code></td></tr><tr><td><code>worker_processes</code></td><td>设置 Nginx 启动的工作进程数，通常根据 CPU 核心数设置</td><td><code>worker_processes auto;</code></td></tr><tr><td><code>error_log</code></td><td>定义错误日志文件路径和日志级别</td><td><code>error_log /var/log/nginx/error.log warn;</code></td></tr><tr><td><code>pid</code></td><td>定义存储 Nginx 主进程 PID 的文件路径</td><td><code>pid /var/run/nginx.pid;</code></td></tr><tr><td><code>worker_rlimit_nofile</code></td><td>设置工作进程可打开的最大文件描述符数</td><td><code>worker_rlimit_nofile 1024;</code></td></tr><tr><td><code>worker_priority</code></td><td>设置工作进程的优先级，负值表示更高优先级</td><td><code>worker_priority -5;</code></td></tr><tr><td><code>include</code></td><td>包含其他配置文件，用于模块化管理配置</td><td><code>include /etc/nginx/conf.d/*.conf;</code></td></tr><tr><td><code>daemon</code></td><td>控制 Nginx 是否以守护进程方式运行，<code>on</code> 为默认值</td><td><code>daemon on;</code></td></tr><tr><td><code>worker_cpu_affinity</code></td><td>绑定 Nginx 工作进程到特定 CPU 核心，提升并行处理性能</td><td><code>worker_cpu_affinity auto;</code></td></tr><tr><td><code>worker_shutdown_timeout</code></td><td>设置工作进程终止时的最大等待时间</td><td><code>worker_shutdown_timeout 10s;</code></td></tr><tr><td><code>lock_file</code></td><td>定义锁文件路径，用于管理 <code>accept_mutex</code> 下的进程锁</td><td><code>lock_file /var/run/nginx.lock;</code></td></tr><tr><td><code>env</code></td><td>设置环境变量</td><td><code>env OPENSSL_CONF=/etc/ssl/openssl.cnf;</code></td></tr></tbody></table><h3 id="Nginx进程的工作模式"><a href="#Nginx进程的工作模式" class="headerlink" title="Nginx进程的工作模式"></a>Nginx进程的工作模式</h3><p>我们先通过<code>ps</code>看一下 nginx 进程的详细情况:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 nginx]# ps -auxf | grep nginx | grep -v grep</span><br><span class="line">root     20588  0.0  0.0  39308  1064 ?        Ss   15:11   0:00 nginx: master process /usr/sbin/nginx</span><br><span class="line">nginx    20589  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20590  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20591  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20592  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20593  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20594  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20595  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20596  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20597  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20598  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20599  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20600  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">nginx    20601  0.0  0.0  39696  1904 ?        S&lt;   15:11   0:00  \_ nginx: worker process</span><br><span class="line">.....</span><br></pre></td></tr></table></figure><p>这里我们可以看到 nginx 有一个 master 进程和多个 worker 进程，这里worker 进程的数量取决于配置文件中 <code>worker_processes</code>的配置。主进程的主要目的是读取和评估配置，以及维护工作进程。工作进程实际处理请求。nginx采用基于事件的模型和依赖于操作系统的机制来有效地在工作进程之间分发请求。</p><p>一旦主进程收到重新加载配置的信号，它会检查新配置文件的语法有效性，并尝试应用其中提供的配置。如果成功，主进程将启动新的工作进程，并向旧的工作进程发送消息，请求它们关闭。否则，主进程回滚更改并继续使用旧配置。旧的工作进程，收到命令关闭，停止接受新的连接，并继续服务当前的请求，直到所有这些请求都得到服务。之后，旧的worker进程退出。</p><h2 id="event-块"><a href="#event-块" class="headerlink" title="event 块"></a>event 块</h2><p>Nginx events 模块的配置参数用于控制 Nginx 如何处理并发连接以及选择合适的事件模型。主要涉及 Nginx 的网络事件处理机制，帮助优化高并发性能。</p><p>以下是 Nginx events 模块的参数及其含义：</p><table><thead><tr><th>参数名</th><th>含义</th><th>示例</th></tr></thead><tbody><tr><td><code>worker_connections</code></td><td>每个工作进程能够处理的最大连接数，直接影响并发连接数量</td><td><code>worker_connections 1024;</code></td></tr><tr><td><code>use</code></td><td>指定使用的事件驱动模型。通常根据操作系统选择适合的模型</td><td><code>use epoll;</code>（Linux）</td></tr><tr><td><code>multi_accept</code></td><td>是否启用一次接受尽可能多的连接，<code>on</code> 表示接受所有可用连接</td><td><code>multi_accept on;</code></td></tr><tr><td><code>accept_mutex</code></td><td>是否启用接受连接的互斥锁，避免多个工作进程同时抢占新连接</td><td><code>accept_mutex on;</code></td></tr><tr><td><code>accept_mutex_delay</code></td><td>在 <code>accept_mutex</code> 启用时，设置工作进程获取新连接前的等待时间</td><td><code>accept_mutex_delay 500ms;</code></td></tr><tr><td><code>debug_connection</code></td><td>启用特定 IP 地址的连接调试日志，便于诊断连接问题</td><td><code>debug_connection 192.168.1.1;</code></td></tr></tbody></table><p>参数请参考: <a href="https://github.com/nginx/nginx/blob/00637cce366f17b78fe1ed5c1ef0e534143045f6/src/event/ngx_event.c">https://github.com/nginx/nginx/blob/00637cce366f17b78fe1ed5c1ef0e534143045f6/src/event/ngx_event.c</a></p><h2 id="http-块"><a href="#http-块" class="headerlink" title="http 块"></a>http 块</h2><p>用于配置 HTTP 协议下的相关行为。该块通常位于 nginx.conf 配置文件中，负责处理 HTTP 请求的行为、代理、缓存、日志等。http块中可以包含多个server块，server块也可以包含多个location块。</p><h3 id="1-全局配置参数"><a href="#1-全局配置参数" class="headerlink" title="1.全局配置参数"></a>1.全局配置参数</h3><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><code>include</code></td><td>引入外部配置文件，便于模块化管理配置。</td></tr><tr><td><code>default_type</code></td><td>为那些在 mime.types 文件中没有特定映射的文件设置默认 MIME 类型               ｜</td></tr><tr><td><code>sendfile</code></td><td>启用 <code>sendfile</code> 以提高文件传输效率，适用于静态资源的传输。</td></tr><tr><td><code>tcp_nopush</code></td><td>提高 TCP 数据包发送效率，常与 <code>sendfile</code> 一起使用，用于减少网络延迟。</td></tr><tr><td><code>tcp_nodelay</code></td><td>在保持长连接时，尽快将数据发送到客户端，减少数据延迟。</td></tr><tr><td><code>keepalive_timeout</code></td><td>设置保持连接的超时时间，控制空闲连接的保持时间。</td></tr><tr><td><code>server_tokens</code></td><td>控制是否显示 NGINX 版本信息。关闭可以增加安全性，避免暴露版本细节。</td></tr><tr><td><code>client_max_body_size</code></td><td>限制客户端请求的最大内容大小，通常用于限制上传文件的大小。</td></tr><tr><td><code>client_body_timeout</code></td><td>设置读取客户端请求体的超时时间。如果在指定时间内无法读取完成，请求将被关闭。</td></tr><tr><td><code>reset_timedout_connection</code></td><td>启用后，连接超时会主动发送 RST 包关闭连接，而不是等待超时。</td></tr></tbody></table><p>关于 mime types部分：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">include             /etc/nginx/mime.types;      <span class="comment"># 这里引用了一个文件，文件里面指定了一些内容映射</span></span><br><span class="line">default_type        application/octet-stream;   <span class="comment"># 默认类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 我们可以看下 mime.types的一些映射</span></span><br><span class="line">types &#123;</span><br><span class="line">    text/html                                        html htm shtml;</span><br><span class="line">    text/css                                         css;</span><br><span class="line">    text/xml                                         xml;</span><br><span class="line">    image/gif                                        gif;</span><br><span class="line">    image/jpeg                                       jpeg jpg;</span><br><span class="line">    application/javascript                           js;</span><br><span class="line">    application/atom+xml                             atom;</span><br><span class="line">    application/rss+xml                              rss;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大家可以参考这篇文章:<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_types">MIME 类型（IANA 媒体类型）</a></p><h3 id="2-日志管理"><a href="#2-日志管理" class="headerlink" title="2.日志管理"></a>2.日志管理</h3><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><code>access_log</code></td><td>设置访问日志的路径和格式，用于记录所有客户端请求的详细信息。</td></tr><tr><td><code>log_format</code></td><td>定义日志格式，可以自定义哪些信息会写入访问日志。</td></tr><tr><td><code>error_log</code></td><td>指定错误日志的路径及日志级别，记录服务器运行过程中发生的错误。</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在全局 可以定义不同的日志格式类型，比如</span></span><br><span class="line">log_format  maina  <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;</span>;</span><br><span class="line">log_format  mainb  <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;xxx&quot;&#x27;</span> ;</span><br><span class="line"><span class="comment"># 在使用的时候就可以指定类型，比如有两个服务， servicea,serviceb,分别使用两个不同格式的日志</span></span><br><span class="line">access_log  /var/log/nginx/servicea.log  maina;</span><br><span class="line">access_log  /var/log/nginx/serviceb.log  mainb;</span><br></pre></td></tr></table></figure><h3 id="3-代理配置"><a href="#3-代理配置" class="headerlink" title="3.代理配置"></a>3.代理配置</h3><table><thead><tr><th>参数</th><th>说明</th><th>作用域</th></tr></thead><tbody><tr><td><code>proxy_buffers</code></td><td>设置代理响应的缓冲区数量和大小。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_buffer_size</code></td><td>设置代理服务器用于读取响应头的缓冲区大小。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_connect_timeout</code></td><td>设置与上游服务器建立连接的超时时间。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_hide_header</code></td><td>隐藏来自上游服务器的指定 HTTP 响应头。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_http_version</code></td><td>指定代理使用的 HTTP 版本（如 1.0 或 1.1）。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_ignore_client_abort</code></td><td>当客户端中止请求时，是否让 NGINX 继续代理到上游服务器。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_max_temp_file_size</code></td><td>设置用于临时文件存储的最大大小。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_next_upstream</code></td><td>定义上游服务器发生错误时是否将请求转发到下一个上游服务器。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_next_upstream_tries</code></td><td>设置最大尝试数，当上游服务器出错时可转发到下一个服务器。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_pass</code></td><td>定义代理请求的上游服务器地址。</td><td><code>location</code></td></tr><tr><td><code>proxy_read_timeout</code></td><td>设置读取上游服务器响应的超时时间。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_redirect</code></td><td>重写上游服务器返回的 <code>Location</code> 或 <code>Refresh</code> 头中的地址。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_request_buffering</code></td><td>设置是否将客户端请求的主体缓存在代理服务器中。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_send_timeout</code></td><td>设置发送请求到上游服务器时的超时时间。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_set_header</code></td><td>设置在代理请求中发送的 HTTP 请求头。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_temp_path</code></td><td>设置存储代理临时文件的目录。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><h3 id="4-连接和请求控制"><a href="#4-连接和请求控制" class="headerlink" title="4. 连接和请求控制"></a>4. 连接和请求控制</h3><table><thead><tr><th>参数</th><th>作用</th><th>作用域</th></tr></thead><tbody><tr><td><code>limit_conn_zone</code></td><td>定义共享区域以限制连接数</td><td><code>http</code></td></tr><tr><td><code>limit_rate</code></td><td>限制响应传输速率</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>limit_req_zone</code></td><td>定义共享区域以限制请求速率</td><td><code>http</code></td></tr><tr><td><code>limit_upload_rate</code></td><td>限制上传传输速率</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>limit_conn</code></td><td>限制客户端的连接数</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>limit_req</code></td><td>限制请求速率</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>limit_rate</code></td><td>限制客户端的下载或上传速率</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>keepalive_requests</code></td><td>设置一个连接在关闭之前允许的最大请求数</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>keepalive_timeout</code></td><td>设置 Keep-Alive 连接的超时时间</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><h3 id="5-压缩和请求"><a href="#5-压缩和请求" class="headerlink" title="5.压缩和请求"></a>5.压缩和请求</h3><table><thead><tr><th>参数</th><th>说明</th><th>作用域</th></tr></thead><tbody><tr><td><code>gzip</code></td><td>启用 Gzip 压缩。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>gzip_min_length</code></td><td>设置启用压缩的响应体最小长度，低于此长度的响应不会被压缩。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>gzip_buffers</code></td><td>设置用于存储压缩数据的缓冲区数量和大小。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>gzip_http_version</code></td><td>设置支持的最小 HTTP 版本，低于该版本的请求不会使用 Gzip 压缩。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>gzip_comp_level</code></td><td>设置 Gzip 压缩级别，范围从 1 到 9，数字越大压缩率越高，资源消耗也越大。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>gzip_vary</code></td><td>启用 <code>Vary: Accept-Encoding</code> 头，指示代理和浏览器缓存应根据 Accept-Encoding 头处理不同的响应。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>gzip_types</code></td><td>指定需要压缩的 MIME 类型。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_cache</code></td><td>启用代理缓存，缓存上游服务器的响应。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr><tr><td><code>proxy_cache_path</code></td><td>定义缓存路径和缓存相关的控制参数，如缓存大小和策略。</td><td><code>http</code></td></tr><tr><td><code>proxy_cache_valid</code></td><td>设置缓存的有效期，不同状态码可设置不同的缓存时间。</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><h3 id="Server块"><a href="#Server块" class="headerlink" title="Server块"></a>Server块</h3><p>作用: </p><ul><li>server 块定义了一个虚拟主机配置。每个 server 块处理指定的域名或 IP 地址的请求，并根据配置响应客户端请求。可以在一个 http 块中定义多个 server 块。server 块中可以包含多个 location 块来处理不同的请求路径。</li></ul><p>用途:<br> -配置特定域名或 IP 的虚拟主机，包括监听端口、域名、根目录等。<br> -设置特定于虚拟主机的配置，例如访问控制、SSL&#x2F;TLS 设置、错误页面等。<br> -定义处理请求的 location 块，用于细化请求的路由和处理</p><p> 支持参数:</p><table><thead><tr><th>参数</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td><code>listen</code></td><td>定义 <code>nginx</code> 监听的 IP 地址和端口号</td><td><code>listen 80;</code></td></tr><tr><td><code>server_name</code></td><td>指定虚拟主机的域名或 IP 地址</td><td><code>server_name example.com;</code></td></tr><tr><td><code>root</code></td><td>设置服务器的根目录</td><td><code>root /var/www/html;</code></td></tr><tr><td><code>index</code></td><td>指定默认的首页文件</td><td><code>index index.html;</code></td></tr><tr><td><code>location</code></td><td>定义匹配 URI 的块</td><td><code>location / &#123; try_files $uri $uri/ =404; &#125;</code></td></tr><tr><td><code>error_page</code></td><td>自定义错误页面</td><td><code>error_page 404 /404.html;</code></td></tr><tr><td><code>return</code></td><td>返回指定的状态码或重定向</td><td><code>return 301 https://$host$request_uri;</code></td></tr><tr><td><code>rewrite</code></td><td>重写 URL</td><td><code>rewrite ^/old-path/(.*)$ /new-path/$1;</code></td></tr><tr><td><code>proxy_pass</code></td><td>代理请求到另一个服务器</td><td><code>proxy_pass http://backend_server;</code></td></tr><tr><td><code>ssl</code></td><td>启用 HTTPS 支持</td><td><code>listen 443 ssl;</code></td></tr><tr><td><code>ssl_certificate</code></td><td>SSL 证书文件路径</td><td><code>ssl_certificate /etc/nginx/ssl/example.crt;</code></td></tr><tr><td><code>ssl_certificate_key</code></td><td>SSL 证书私钥文件路径</td><td><code>ssl_certificate_key /etc/nginx/ssl/example.key;</code></td></tr><tr><td><code>allow</code></td><td>允许指定 IP 地址访问</td><td><code>allow 192.168.1.0/24;</code></td></tr><tr><td><code>deny</code></td><td>拒绝指定 IP 地址访问</td><td><code>deny 192.168.1.100;</code></td></tr><tr><td><code>client_max_body_size</code></td><td>限制客户端请求体的最大大小</td><td><code>client_max_body_size 10M;</code></td></tr><tr><td><code>client_body_timeout</code></td><td>请求体接收超时时间</td><td><code>client_body_timeout 60s;</code></td></tr><tr><td><code>keepalive_timeout</code></td><td>设置 <code>keep-alive</code> 连接超时时间</td><td><code>keepalive_timeout 65;</code></td></tr><tr><td><code>send_timeout</code></td><td>发送响应超时时间</td><td><code>send_timeout 30s;</code></td></tr><tr><td><code>expires</code></td><td>设置缓存过期时间</td><td><code>expires 30d;</code></td></tr><tr><td><code>proxy_cache</code></td><td>启用代理缓存</td><td><code>proxy_cache my_cache;</code></td></tr><tr><td><code>add_header</code></td><td>添加自定义 HTTP 响应头</td><td><code>add_header X-Frame-Options SAMEORIGIN;</code></td></tr></tbody></table><p> 示例:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">server <span class="punctuation">&#123;</span></span><br><span class="line">    listen       <span class="number">80</span>;</span><br><span class="line">    server_name  testa.com;</span><br><span class="line"></span><br><span class="line">    charset utf<span class="number">-8</span>;</span><br><span class="line">    #include mime.types;</span><br><span class="line"></span><br><span class="line">    access_log  /var/logs/nginx/servivea.log maina;</span><br><span class="line">    large_client_header_buffers <span class="number">4</span> <span class="number">8</span>k;</span><br><span class="line"></span><br><span class="line">    location / <span class="punctuation">&#123;</span></span><br><span class="line">        proxy_ignore_client_abort on;</span><br><span class="line">        proxy_connect_timeout <span class="number">5</span>s;</span><br><span class="line">        proxy_read_timeout <span class="number">60</span>s;</span><br><span class="line">        proxy_send_timeout <span class="number">10</span>s;</span><br><span class="line">        client_body_timeout <span class="number">60</span>;</span><br><span class="line">        client_max_body_size <span class="number">20</span>m;</span><br><span class="line">        proxy_request_buffering off;</span><br><span class="line">        proxy_buffers <span class="number">64</span> <span class="number">256</span>k;</span><br><span class="line">        proxy_next_upstream error timeout http_502 http_504;</span><br><span class="line">        proxy_set_header X-Forward-For $remote_addr;</span><br><span class="line">        proxy_pass http<span class="punctuation">:</span><span class="comment">//servicea;</span></span><br><span class="line">        proxy_set_header Host $http_host;</span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h1 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h1><p>假如说我现在有一个服务器，上面部署了 kibana 和 nginx，我现在想把 kibana 暴露出来，可以通过下面的方式实现:</p><p>进入 nginx 的配置目录，创建一个 kibana.conf 文件<code>/etc/nginx/conf.d/kibana.conf</code>，内容如下:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">server <span class="punctuation">&#123;</span></span><br><span class="line">    listen <span class="number">80</span>;</span><br><span class="line">    server_name kibana.example.com;</span><br><span class="line"></span><br><span class="line">    location / <span class="punctuation">&#123;</span></span><br><span class="line">        proxy_pass http<span class="punctuation">:</span><span class="comment">//localhost:5601;</span></span><br><span class="line">        proxy_http_version <span class="number">1.1</span>;</span><br><span class="line">        proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">        proxy_set_header Connection &#x27;upgrade&#x27;;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_cache_bypass $http_upgrade;</span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>通过<code>nginx -t</code>进行检查，没有问题后，通过<code>nginx -s reload</code>进行重载。</p><p>在本地配置 ip 和域名的映射，就可以通过域名访问 kibana 了。</p>]]></content>
    
    
    <summary type="html">Nginx 使用介绍</summary>
    
    
    
    <category term="反向代理" scheme="http://baixiaozhou.github.io/categories/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"/>
    
    
    <category term="Nginx" scheme="http://baixiaozhou.github.io/tags/Nginx/"/>
    
    <category term="反向代理" scheme="http://baixiaozhou.github.io/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"/>
    
    <category term="负载均衡" scheme="http://baixiaozhou.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
  </entry>
  
  <entry>
    <title>Chronyd服务详解</title>
    <link href="http://baixiaozhou.github.io/p/Chronyd%E6%9C%8D%E5%8A%A1%E8%AF%A6%E8%A7%A3/"/>
    <id>http://baixiaozhou.github.io/p/Chronyd%E6%9C%8D%E5%8A%A1%E8%AF%A6%E8%A7%A3/</id>
    <published>2024-09-09T06:31:17.000Z</published>
    <updated>2024-11-04T07:55:59.105Z</updated>
    
    <content type="html"><![CDATA[<!-- Your content starts here --><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>我们先看一下官网的介绍：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chrony is a versatile implementation of the Network Time Protocol (NTP). It can synchronise the system clock with NTP servers, reference clocks (e.g. GPS receiver), and manual input using wristwatch and keyboard. It can also operate as an NTPv4 (RFC 5905) server and peer to provide a time service to other computers in the network.</span><br></pre></td></tr></table></figure><p>简而言之，chronyd 就是用来校准时间的，基于 ntp 协议（ntp 加强版），既可以做服务器，也可以做客户端（既能为其他机器提供时钟同步服务，也能从其他机器上同步时间）</p><p>主要功能:</p><ul><li>时间同步：chronyd 主要负责将系统时间与网络时间服务器进行同步。它通过网络时间协议（NTP）或精确时间协议（PTP）从外部时间源获取时间信息，并调整本地系统时间。</li><li>系统时间校准：Chrony 能够处理系统时钟漂移问题，尤其是在系统启动时或在虚拟化环境中，Chrony 能够在更短的时间内校准系统时间。</li><li>网络时钟漂移：chronyd 能够处理网络延迟和时钟漂移，使得系统时间更加准确。</li></ul><h1 id="部署安装"><a href="#部署安装" class="headerlink" title="部署安装"></a>部署安装</h1><p>现在很多 linux 发行版默认都会安装 chronyd 服务，如果没有安装，我们需要手动进行安装:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y chrony</span><br></pre></td></tr></table></figure><p>安装完成后，我们可以看下 chrony 包中都提供了哪些东西:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# rpm -ql chrony</span><br><span class="line">/etc/NetworkManager/dispatcher.d/20-chrony</span><br><span class="line">/etc/chrony.conf</span><br><span class="line">/etc/chrony.keys</span><br><span class="line">/etc/dhcp/dhclient.d/chrony.sh</span><br><span class="line">/etc/logrotate.d/chrony</span><br><span class="line">/etc/sysconfig/chronyd</span><br><span class="line">/usr/bin/chronyc</span><br><span class="line">/usr/lib/systemd/ntp-units.d/50-chronyd.list</span><br><span class="line">/usr/lib/systemd/system/chrony-dnssrv@.service</span><br><span class="line">/usr/lib/systemd/system/chrony-dnssrv@.timer</span><br><span class="line">/usr/lib/systemd/system/chrony-wait.service</span><br><span class="line">/usr/lib/systemd/system/chronyd.service</span><br><span class="line">/usr/libexec/chrony-helper</span><br><span class="line">/usr/sbin/chronyd</span><br><span class="line">/usr/share/doc/chrony-3.4</span><br><span class="line">/usr/share/doc/chrony-3.4/COPYING</span><br><span class="line">/usr/share/doc/chrony-3.4/FAQ</span><br><span class="line">/usr/share/doc/chrony-3.4/NEWS</span><br><span class="line">/usr/share/doc/chrony-3.4/README</span><br><span class="line">/usr/share/man/man1/chronyc.1.gz</span><br><span class="line">/usr/share/man/man5/chrony.conf.5.gz</span><br><span class="line">/usr/share/man/man8/chronyd.8.gz</span><br><span class="line">/var/lib/chrony</span><br><span class="line">/var/lib/chrony/drift</span><br><span class="line">/var/lib/chrony/rtc</span><br><span class="line">/var/log/chrony</span><br></pre></td></tr></table></figure><p>经常涉及的主要包括:</p><ol><li>&#x2F;etc&#x2F;chrony.conf: 配置文件</li><li>&#x2F;usr&#x2F;bin&#x2F;chronyc: 命令行工具</li><li>&#x2F;usr&#x2F;sbin&#x2F;chronyd: 启动程序</li></ol><h2 id="配置文件详解"><a href="#配置文件详解" class="headerlink" title="配置文件详解"></a>配置文件详解</h2><p>下面是 chronyd 配置文件中提供的参数及每项含义:</p><table><thead><tr><th>配置项</th><th>解释</th></tr></thead><tbody><tr><td><code>server &lt;ntp-server&gt; iburst</code></td><td>指定 NTP 服务器地址，<code>iburst</code> 选项表示在启动时快速发送一系列请求，以加快初始同步过程。</td></tr><tr><td><code>driftfile /var/lib/chrony/drift</code></td><td>指定时钟漂移文件的位置，该文件记录系统时钟的增益或损失率，以帮助 Chrony 在重启后更快地调整时钟。</td></tr><tr><td><code>makestep 1.0 3</code></td><td>允许系统时钟在前 3 次更新中，若时钟偏差超过 1 秒，可以进行大步调整（即直接调至正确时间），而不是逐渐调整。</td></tr><tr><td><code>rtcsync</code></td><td>启用内核与实时时钟（RTC）的同步功能，以确保系统时钟与硬件时钟保持一致。</td></tr><tr><td><code>hwtimestamp *</code></td><td>启用所有支持的接口上的硬件时间戳（该行被注释掉，未启用）。</td></tr><tr><td><code>minsources 2</code></td><td>增加可选时间源的最小数量，当达到该数量时，才会调整系统时钟（该行被注释掉，未启用）。</td></tr><tr><td><code>allow 192.168.0.0/16</code></td><td>允许从指定的局域网（如 192.168.0.0&#x2F;16）访问 NTP 客户端，这通常用于允许局域网内的其他设备与本机进行时间同步（该行被注释掉，未启用）。</td></tr><tr><td><code>local stratum 10</code></td><td>即使本地时间未与时间源同步，也允许本地系统作为时间服务器。<code>stratum</code> 指定了时间层级，<code>stratum 10</code> 表示较低的层次，用于避免对外部 NTP 服务器的依赖（该行被注释掉，未启用）。</td></tr><tr><td><code>keyfile /etc/chrony.keys</code></td><td>指定 NTP 认证的密钥文件路径，用于确保 NTP 客户端和服务器之间的通信是安全的（该行被注释掉，未启用）。</td></tr><tr><td><code>logdir /var/log/chrony</code></td><td>指定日志文件的目录，Chrony 会将日志存储在该目录下。</td></tr><tr><td><code>log measurements statistics tracking</code></td><td>选择哪些信息需要被记录到日志中，包含测量结果、统计信息和跟踪信息（该行被注释掉，未启用）。</td></tr></tbody></table><h2 id="chronyc-命令详解"><a href="#chronyc-命令详解" class="headerlink" title="chronyc 命令详解"></a>chronyc 命令详解</h2><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>tracking</code></td><td>显示当前时间跟踪状态，包括时间源、时钟偏移、频率偏移等信息。</td></tr><tr><td><code>sources</code></td><td>列出当前配置的 NTP 时间源及其状态。</td></tr><tr><td><code>sourcestats</code></td><td>显示各个 NTP 时间源的统计信息，包括时间源的延迟、偏移、抖动等。</td></tr><tr><td><code>ntpdata</code></td><td>显示与各个时间源相关的低级 NTP 数据，如参考时钟 ID 和偏移量等。</td></tr><tr><td><code>makestep</code></td><td>立即将系统时间同步到时间源（即大幅度调整系统时间，而非逐步调整）。</td></tr><tr><td><code>burst</code></td><td>向所有时间源发送一组时间请求，以加快同步速度。</td></tr><tr><td><code>reload sources</code></td><td>重新加载配置文件中的时间源，而不需要重新启动 <code>chronyd</code>。</td></tr><tr><td><code>clients</code></td><td>列出通过 <code>chronyd</code> 进行时间同步的客户端。</td></tr><tr><td><code>settime</code></td><td>手动设置系统时间。</td></tr><tr><td><code>rtcdata</code></td><td>显示实时时钟（RTC）的状态信息。</td></tr><tr><td><code>manual</code></td><td>启动手动时间输入模式，用于手动设置时间（如通过键盘或手表）。</td></tr><tr><td><code>dump</code></td><td>输出 <code>chronyd</code> 内存中时间源的状态信息。</td></tr><tr><td><code>waitsync</code></td><td>等待系统时钟与时间源同步，通常用于确保系统启动时时间同步完成。</td></tr><tr><td><code>activity</code></td><td>显示当前活动的时间源数量和状态。</td></tr><tr><td><code>reselect</code></td><td>强制 <code>chronyd</code> 重新选择最佳的时间源。</td></tr><tr><td><code>serverstats</code></td><td>显示 <code>chronyd</code> 的服务器统计信息，如请求数量、响应延迟等。</td></tr><tr><td><code>manual list</code></td><td>列出手动设置的时间值。</td></tr><tr><td><code>trimrtc</code></td><td>通过调整实时时钟（RTC）的频率，使其更接近系统时钟的频率。</td></tr><tr><td><code>quit</code></td><td>退出 <code>chronyc</code> 交互模式。</td></tr></tbody></table><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><p>我们先看一下常用的一些命令:</p><h4 id="chronyc-sources"><a href="#chronyc-sources" class="headerlink" title="chronyc sources"></a>chronyc sources</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# chronyc sources</span><br><span class="line">210 Number of sources = 3</span><br><span class="line">MS Name/IP address         Stratum Poll Reach LastRx Last sample</span><br><span class="line">===============================================================================</span><br><span class="line">^+ node1                        3   6   377    46   +330us[ +400us] +/- 3523us</span><br><span class="line">^+ 8.8.8.8                      2   6   377    47   +570us[ +640us] +/- 2602us</span><br><span class="line">^* 8.8.8.9                      2   6   377    45   +366us[ +436us] +/- 3478us</span><br></pre></td></tr></table></figure><p>这里显示了当前这个机器同步的一些源信息，包含</p><ol><li>源节点: <code>node1</code>、<code>8.8.8.8</code>、<code>9.9.9.9</code>, 最前面的*表示最优先的时钟源，</li><li>Stratum: NTP 时间源的层级（stratum），表示时间源的准确性层次。Stratum 0 是参考时钟（如 GPS），Stratum 1 是直接从参考时钟获取时间的服务器，以此类推。较高的层级表示离参考时钟的距离越远，时钟的准确性也会降低。</li><li>Poll: 系统与时间源之间的轮询间隔（以秒为单位）。该值表示在上一次时间同步之后，系统等待多久再次向该时间源请求同步。Poll 值会根据网络状况自动调整，通常范围是 64 到 1024 秒。</li><li>Reach: 到达值（reach），是一个 8 位的八进制值，表示最近 8 次对该时间源的请求是否成功。该值通常为 377（所有 8 次请求都成功），较低的值表示有请求失败。</li><li>LastRx: 最近一次从该时间源接收 NTP 数据包的时间（以秒为单位），表示距离上次成功接收数据包的时间长度。值越大表示该时间源未及时响应，可能存在问题。</li><li>Last sample:最近一次时间样本的偏差值，表示系统时钟与时间源时钟之间的偏移量。正数表示系统时钟快于时间源，负数表示系统时钟慢于时间源。偏差通常以毫秒（ms）或微秒（µs）为单位显示。</li></ol><p>我们可以看下这个节点的配置文件:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server node1</span><br><span class="line">commandkey 1</span><br><span class="line">keyfile /etc/chrony.keys</span><br></pre></td></tr></table></figure><p>这里大家会好奇，我这里明明只配置了 node1 为源服务器，为啥会多出两个 ip? 正好 Redhat 官方给了解释:<br><a href="https://access.redhat.com/solutions/4072781">Why does “chronyc sources” output unexpected NTP servers</a></p><p>但是有点烦的是这个文档需要开通红帽订阅才能看，这里我直接粘贴一下原因:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Resolution:</span><br><span class="line"></span><br><span class="line">Add &quot;PEERNTP=no&quot; entry to /etc/sysconfig/network will prevent dhclient from receiving a list of NTP servers from the DHCP server.</span><br><span class="line">If you already set the network connection down but still gets the NTP server in chronyc sources, delete /var/lib/dhclient/chrony.servers.* file and restart chronyd service.</span><br><span class="line"></span><br><span class="line">Root Cause:</span><br><span class="line"></span><br><span class="line">If a network connection is set to use DHCP to get IP address, when NetworkManager starts or network connection is up, dhclient receives a list of NTP servers from the DHCP server and generates /var/lib/dhclient/chrony.servers.* file (since chrony 4.1-1, the file is /run/chrony-helper/nm-dhcp.*).</span><br><span class="line">Chronyd not only reads /etc/chrony.conf file, but also reads /var/lib/dhclient/chrony.servers.* file to get NTP server list.</span><br><span class="line"></span><br><span class="line">If an NTP server has already been configured in /etc/chrony.conf file, it won&#x27;t appear in /var/run/chrony-helper/added_servers.</span><br><span class="line">Thus, user can confirm the added servers in /var/run/chrony-helper/added_servers.</span><br><span class="line"></span><br><span class="line">Note:</span><br><span class="line">The environment variable, PEERNTP is used in /etc/dhcp/dhclient.d/chrony.sh(chrony rpm ) and /etc/dhcp/dhclient.d/ntp.sh(ntp rpm)</span><br></pre></td></tr></table></figure><p>简单来说就是 chronyd 不仅会从 chrony.conf中去获取源，也会去 dhcp client 生成的信息中去获取源服务器</p><h4 id="chronyc-tracking"><a href="#chronyc-tracking" class="headerlink" title="chronyc tracking"></a>chronyc tracking</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@\node2 ~]# chronyc tracking</span><br><span class="line">Reference ID    : xxx (8.8.8.8)</span><br><span class="line">Stratum         : 3</span><br><span class="line">Ref time (UTC)  : Mon Sep 09 07:58:14 2024</span><br><span class="line">System time     : 0.000109912 seconds fast of NTP time</span><br><span class="line">Last offset     : +0.000090043 seconds</span><br><span class="line">RMS offset      : 0.000686857 seconds</span><br><span class="line">Frequency       : 11.188 ppm slow</span><br><span class="line">Residual freq   : +0.026 ppm</span><br><span class="line">Skew            : 0.786 ppm</span><br><span class="line">Root delay      : 0.003966943 seconds</span><br><span class="line">Root dispersion : 0.000785699 seconds</span><br><span class="line">Update interval : 64.8 seconds</span><br><span class="line">Leap status     : Normal</span><br></pre></td></tr></table></figure><p>这里能看到更加细致的同步信息，比如时间的偏移量、更新间隔等</p><h4 id="chronyc-makestep"><a href="#chronyc-makestep" class="headerlink" title="chronyc makestep"></a>chronyc makestep</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# chronyc makestep</span><br><span class="line">200 OK</span><br></pre></td></tr></table></figure><p>这个命令主要用于时间跨度太大一次性直接进行同步的，由于时钟的调整是非常微妙要求精确的，时间跨度太大的话同步完成的周期可能比较久，所以可以通过这个命令直接同步。</p>]]></content>
    
    
    <summary type="html">时钟同步服务 chronyd 介绍</summary>
    
    
    
    <category term="运维工具" scheme="http://baixiaozhou.github.io/categories/%E8%BF%90%E7%BB%B4%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="Linux" scheme="http://baixiaozhou.github.io/tags/Linux/"/>
    
    <category term="Chronyd" scheme="http://baixiaozhou.github.io/tags/Chronyd/"/>
    
    <category term="时钟同步" scheme="http://baixiaozhou.github.io/tags/%E6%97%B6%E9%92%9F%E5%90%8C%E6%AD%A5/"/>
    
  </entry>
  
  <entry>
    <title>Pacemaker+Corosync使用简介</title>
    <link href="http://baixiaozhou.github.io/p/Pacemaker-Corosync%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BB%8B/"/>
    <id>http://baixiaozhou.github.io/p/Pacemaker-Corosync%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BB%8B/</id>
    <published>2024-08-30T09:59:26.000Z</published>
    <updated>2024-09-18T02:30:54.207Z</updated>
    
    <content type="html"><![CDATA[<div class="tag-plugin quot"><p class="content" type="text"><span class="empty"></span><span class="text">参考文档</span><span class="empty"></span></p></div><p><a href="https://docs.redhat.com/zh_hans/documentation/red_hat_enterprise_linux/7/html/high_availability_add-on_reference/index">红帽官方文档</a></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>pacemaker 和 corosync是两种开源软件组件，通常结合使用以构建高可用性（HA）集群。</p><h2 id="Pacemaker"><a href="#Pacemaker" class="headerlink" title="Pacemaker"></a>Pacemaker</h2><p>Pacemaker 是一个集群资源管理器，负责管理集群中所有资源的启动、停止、迁移等操作。它通过与 Corosync 协作，确保在节点故障或服务异常时，资源能够自动在其他健康节点上接管。从这里我们就可以发现，pacemaker 的核心在于管理</p><h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><p>pacemaker 主要包括以下组件:</p><ul><li>   CIB (Cluster Information Base)：存储集群的配置信息，包括资源、约束、节点等。</li><li>   CRM (Cluster Resource Manager)：决定如何在集群中分配和管理资源。</li><li>   PEngine (Policy Engine)：根据集群状态和配置策略做出决策。</li><li>   Fencing：通过 STONITH（Shoot The Other Node In The Head）机制来隔离失效的节点，防止脑裂。</li></ul><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>   管理集群中的各种资源（如虚拟 IP、数据库服务、文件系统等）。</li><li>   确保服务的高可用性，在故障发生时自动切换资源到其他节点。</li></ul><h2 id="Corosync"><a href="#Corosync" class="headerlink" title="Corosync"></a>Corosync</h2><p>Corosync 是一个集群通信引擎，负责在集群节点之间提供消息传递、组成员资格管理、心跳检测等功能。它确保集群中所有节点之间的信息同步，监控节点的健康状况，并在节点故障时通知 pacemaker。</p><h3 id="组件-1"><a href="#组件-1" class="headerlink" title="组件"></a>组件</h3><ul><li>   组通信：用于确保集群中所有节点保持一致的视图。</li><li>   故障检测：通过心跳机制监控节点状态，当节点失联时，通知 Pacemaker。</li><li>   配置管理：管理集群节点的配置和成员资格。</li></ul><h3 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>   集群中节点间的实时通信。</li><li>   监控节点的可用性，并在节点失效时做出响应。</li></ul><h1 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h1><h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><ol><li>在集群的所有节点上安装相关依赖:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y pcs pacemaker corosync # Centos</span><br></pre></td></tr></table></figure></li><li>启动相关服务并设置服务开机自启动:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start pcsd </span><br><span class="line">systemctl enable pcsd</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>设置<code>hacluster</code>用户的密码(此用户在包安装的过程中会自动创建)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo passwd hacluster</span><br></pre></td></tr></table></figure></li><li>在 <code>/etc/hosts</code> 中加入节点配置，例如:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.2 node2</span><br><span class="line">192.168.1.3 node3</span><br></pre></td></tr></table></figure></li></ol><h2 id="命令操作"><a href="#命令操作" class="headerlink" title="命令操作"></a>命令操作</h2><p>集群的命令行操作基本上都是通过 pcs 进行，pcs 提供了如下一些命令:</p><table><thead><tr><th>命令</th><th>说明</th><th>示例命令</th></tr></thead><tbody><tr><td><code>cluster</code></td><td>配置集群选项和节点</td><td><code>pcs cluster start</code> 启动集群</td></tr><tr><td><code>resource</code></td><td>管理集群资源</td><td><code>pcs resource create myresource ocf:heartbeat:IPaddr2 ip=192.168.1.1</code> 创建一个资源</td></tr><tr><td><code>stonith</code></td><td>管理 fence 设备</td><td><code>pcs stonith create myfence fence_ipmilan ipaddr=192.168.1.100 login=admin passwd=password lanplus=1</code> 创建 STONITH 设备</td></tr><tr><td><code>constraint</code></td><td>管理资源约束</td><td><code>pcs constraint location myresource prefers node1=100</code> 设置资源约束</td></tr><tr><td><code>property</code></td><td>管理 Pacemaker 属性</td><td><code>pcs property set stonith-enabled=false</code> 禁用 STONITH</td></tr><tr><td><code>acl</code></td><td>管理 Pacemaker 访问控制列表</td><td><code>pcs acl role create readonly</code> 创建只读角色</td></tr><tr><td><code>qdevice</code></td><td>管理本地主机上的仲裁设备提供程序</td><td><code>pcs qdevice add model net</code> 添加网络仲裁设备</td></tr><tr><td><code>quorum</code></td><td>管理集群仲裁设置</td><td><code>pcs quorum status</code> 查看仲裁状态</td></tr><tr><td><code>booth</code></td><td>管理 booth (集群票据管理器)</td><td><code>pcs booth status</code> 查看 booth 状态</td></tr><tr><td><code>status</code></td><td>查看集群状态</td><td><code>pcs status</code> 查看集群运行状态</td></tr><tr><td><code>config</code></td><td>查看和管理集群配置</td><td><code>pcs config show</code> 显示集群配置</td></tr><tr><td><code>pcsd</code></td><td>管理 pcs 守护进程</td><td><code>pcs pcsd status</code> 查看 pcsd 服务状态</td></tr><tr><td><code>node</code></td><td>管理集群节点</td><td><code>pcs node standby node1</code> 将节点设置为备用</td></tr><tr><td><code>alert</code></td><td>管理 Pacemaker 警报</td><td><code>pcs alert create node=node1 severity=critical</code> 创建警报</td></tr><tr><td><code>client</code></td><td>管理 pcsd 客户端配置</td><td><code>pcs client cert-key-gen --force</code> 生成新的客户端证书</td></tr></tbody></table><p>此外，packmaker 还提供了其他的命令，比如 crm 的一系列工具:</p><table><thead><tr><th>工具名</th><th>解释</th><th>示例</th></tr></thead><tbody><tr><td><code>crm_attribute</code></td><td>管理集群属性，包括设置、修改或删除节点属性。</td><td><code>crm_attribute --node node1 --name attr_name --update attr_value</code> 设置节点属性。</td></tr><tr><td><code>crm_diff</code></td><td>比较两个 CIB 配置文件的差异，便于配置版本管理。</td><td><code>crm_diff cib_old.xml cib_new.xml</code> 比较两个 CIB 文件的差异。</td></tr><tr><td><code>crm_error</code></td><td>显示集群运行过程中遇到的错误信息，帮助排查故障。</td><td><code>crm_error -s 12345</code> 显示特定错误代码的详细信息。</td></tr><tr><td><code>crm_failcount</code></td><td>查看或管理资源的失败计数，影响资源的自动重新调度。</td><td><code>crm_failcount --query --resource my_resource --node node1</code> 查看失败计数。</td></tr><tr><td><code>crm_master</code></td><td>管理主从资源（如 DRBD）状态的工具，用于启动或停止主从资源。</td><td><code>crm_master --promote my_resource</code> 提升资源为主状态。</td></tr><tr><td><code>crm_mon</code></td><td>实时监控集群状态，显示资源、节点、失败信息。</td><td><code>crm_mon --interval=5s --show-detail</code> 每5秒更新监控，显示详细信息。</td></tr><tr><td><code>crm_node</code></td><td>管理集群节点的工具，包括查看节点状态、删除节点等。</td><td><code>crm_node -l</code> 列出所有集群节点。</td></tr><tr><td><code>crm_report</code></td><td>生成集群故障报告的工具，汇总集群状态、日志和诊断信息。</td><td><code>crm_report -f report.tar.bz2</code> 生成详细的故障报告。</td></tr><tr><td><code>crm_resource</code></td><td>管理集群资源，包括启动、停止、迁移和清除资源。</td><td><code>crm_resource --move my_resource --node node2</code> 将资源迁移到另一个节点。</td></tr><tr><td><code>crm_shadow</code></td><td>允许对 CIB 进行“影子”配置，便于测试和调试。</td><td><code>crm_shadow --create shadow_test</code> 创建影子配置。</td></tr><tr><td><code>crm_simulate</code></td><td>模拟集群运行状态的工具，用于测试集群配置的行为。</td><td><code>crm_simulate --live --save-output output.xml</code> 运行模拟，并保存输出。</td></tr><tr><td><code>crm_standby</code></td><td>将节点设置为待机状态，临时不参与资源调度，或重新激活节点。</td><td><code>crm_standby --node node1 --off</code> 将节点设置为待机状态。</td></tr><tr><td><code>crm_ticket</code></td><td>管理集群的 ticket，用于决定哪些资源在哪些位置可以运行（多站点集群）。</td><td><code>crm_ticket --grant my_ticket --node node1</code> 授权 ticket 给指定节点。</td></tr><tr><td><code>crm_verify</code></td><td>验证当前集群配置的工具，检查配置文件的完整性和正确性。</td><td><code>crm_verify --live-check</code> 验证当前运行中的集群配置。</td></tr></tbody></table><p>pacemaker 和 crm 的命令对比:</p><ol><li>pcs（Pacemaker&#x2F;Corosync Shell）</li></ol><ul><li>简介: pcs 是 Pacemaker 和 Corosync 集群管理的命令行工具。它主要用于 Red Hat 系列操作系统（例如 RHEL、CentOS 等）。pcs 提供了一个简单的命令行界面，用于管理集群、资源、节点、约束等功能。</li><li>功能:<ul><li>管理 Pacemaker 集群、Corosync 配置、STONITH 设备、资源和约束等。</li><li>提供集群的创建、启动、停止、删除、资源添加、约束设置等命令。</li><li>提供简单易用的命令接口，能够将集群管理的命令封装成一步到位的操作。</li><li>支持通过 pcsd 提供 Web 界面的管理。</li></ul></li><li>适用场景: pcs 更加适用于初学者和需要快速操作的用户，因为它提供了很多高层次的命令，简化了集群管理。</li></ul><ol start="2"><li>crm（Cluster Resource Manager Shell）</li></ol><ul><li>简介: crm 是 Pacemaker 的原生命令行工具，提供更加底层的控制。crm 主要用于 Pacemaker 集群资源管理和调度，支持在更细粒度上配置和管理集群资源。</li><li>功能:<ul><li>提供更细致的资源管理和集群控制功能。</li><li>crm 的指令可以进行更复杂的操作，比如编辑 CIB (Cluster Information Base) 的 XML 配置文件。</li><li>允许更加精细的配置，适合对集群系统有深度了解的用户。</li></ul></li><li>适用场景: crm 更加适合高级用户，特别是那些需要精确配置、排查问题或操作底层 Pacemaker 资源的场景。</li></ul><h2 id="节点认证和集群创建"><a href="#节点认证和集群创建" class="headerlink" title="节点认证和集群创建"></a>节点认证和集群创建</h2><p>在集群中的任意一个节点上执行:</p><ol><li><p>认证:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcs cluster auth node2 node3 -u hacluster</span><br></pre></td></tr></table></figure></li><li><p>认证完整后创建集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcs cluster setup --name mycluster node2 node3 (同时添加所有节点)</span><br></pre></td></tr></table></figure><p>创建完成后，会生成 corosync 的配置文件，默认位置<code>/etc/corosync/corosync.conf</code>, 其中的内容如下:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">totem <span class="punctuation">&#123;</span></span><br><span class="line">    version<span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">    cluster_name<span class="punctuation">:</span> mycluster</span><br><span class="line">    secauth<span class="punctuation">:</span> off</span><br><span class="line">    transport<span class="punctuation">:</span> udpu</span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">nodelist <span class="punctuation">&#123;</span></span><br><span class="line">    node <span class="punctuation">&#123;</span></span><br><span class="line">        ring0_addr<span class="punctuation">:</span> node2</span><br><span class="line">        nodeid<span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">    node <span class="punctuation">&#123;</span></span><br><span class="line">        ring0_addr<span class="punctuation">:</span> node3</span><br><span class="line">        nodeid<span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">quorum <span class="punctuation">&#123;</span></span><br><span class="line">    provider<span class="punctuation">:</span> corosync_votequorum</span><br><span class="line">    two_node<span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">logging <span class="punctuation">&#123;</span></span><br><span class="line">    to_logfile<span class="punctuation">:</span> yes</span><br><span class="line">    logfile<span class="punctuation">:</span> /var/log/cluster/corosync.log</span><br><span class="line">    to_syslog<span class="punctuation">:</span> yes</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>启动集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pcs cluster start --all <span class="comment"># 这里启动失败的话，可以后面加上 --debug参数查看更详细的信息，可能会因为防火墙等问题导致启动失败</span></span><br><span class="line">pcs cluster <span class="built_in">enable</span> --all <span class="comment"># 设置自启动</span></span><br></pre></td></tr></table></figure></li><li><p>查看集群状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcs status</span><br></pre></td></tr></table></figure><p>我们看下输出情况:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Cluster name: mycluster</span><br><span class="line"></span><br><span class="line">WARNINGS:</span><br><span class="line">No stonith devices and stonith-enabled is not false</span><br><span class="line"></span><br><span class="line">Stack: corosync</span><br><span class="line">Current DC: node2 (version 1.1.23-1.el7_9.1-9acf116022) - partition with quorum</span><br><span class="line">Last updated: Mon Sep  2 18:43:57 2024</span><br><span class="line">Last change: Mon Sep  2 18:35:08 2024 by hacluster via crmd on node2</span><br><span class="line"></span><br><span class="line">2 nodes configured</span><br><span class="line">0 resource instances configured</span><br><span class="line"></span><br><span class="line">Online: [ node2 node3 ]</span><br><span class="line"></span><br><span class="line">No resources</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Daemon Status:</span><br><span class="line">  corosync: active/disabled</span><br><span class="line">  pacemaker: active/disabled</span><br><span class="line">  pcsd: active/enabled</span><br></pre></td></tr></table></figure><p>这里我们可以看到集群的总体情况，包括节点状态、服务状态（有两个服务还处于 disabled 状态， 通过<code>systemctl enable corosync pacemaker</code> 设置开机启动）、资源信息（还没有添加 resource）等</p></li></ol><h2 id="stonith-配置"><a href="#stonith-配置" class="headerlink" title="stonith 配置"></a>stonith 配置</h2><p>在上文集群的状态输出中还包括了一个告警信息: <code>No stonith devices and stonith-enabled is not false</code>, 这里的 stonith（Shoot The Other Node In The Head） 是一种防止“脑裂” (split-brain) 的机制。当集群中的一个节点失去与其他节点的连接时，stonith 设备可以强制重启或关闭这个失联的节点，避免两个或多个节点同时操作同一个资源，导致数据损坏。想要消除这个告警，有两种解决方案:</p><ol><li>禁用 stonith: 如果是自己的测试环境，那么可以禁用掉 stonith 来消除告警，操作方法为:  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcs property <span class="built_in">set</span> stonith-enabled=<span class="literal">false</span></span><br></pre></td></tr></table></figure></li><li>配置 stonith 设备: 在生产环境中，建议配置 stonith</li></ol><p>我们先根据官方文档的指示看一下stonith 有哪些可用代理:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 corosync]# pcs stonith list</span><br><span class="line">Error: No stonith agents available. Do you have fence agents installed?</span><br></pre></td></tr></table></figure><p>这里提示没有代理的 agent 可用，所以我们首先需要安装<code>fence agent</code>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y fence-agents</span><br></pre></td></tr></table></figure><p>我们再 list 一下，就可以看到支持的代理了</p><table><thead><tr><th>Fence Agent</th><th>描述</th></tr></thead><tbody><tr><td><code>fence_amt_ws</code></td><td>适用于 AMT (WS) 的 Fence 代理</td></tr><tr><td><code>fence_apc</code></td><td>通过 telnet&#x2F;ssh 控制 APC 的 Fence 代理</td></tr><tr><td><code>fence_apc_snmp</code></td><td>适用于 APC 和 Tripplite PDU 的 SNMP Fence 代理</td></tr><tr><td><code>fence_bladecenter</code></td><td>适用于 IBM BladeCenter 的 Fence 代理</td></tr><tr><td><code>fence_brocade</code></td><td>通过 telnet&#x2F;ssh 控制 HP Brocade 的 Fence 代理</td></tr><tr><td><code>fence_cisco_mds</code></td><td>适用于 Cisco MDS 的 Fence 代理</td></tr><tr><td><code>fence_cisco_ucs</code></td><td>适用于 Cisco UCS 的 Fence 代理</td></tr><tr><td><code>fence_compute</code></td><td>用于自动复活 OpenStack 计算实例的 Fence 代理</td></tr><tr><td><code>fence_drac5</code></td><td>适用于 Dell DRAC CMC&#x2F;5 的 Fence 代理</td></tr><tr><td><code>fence_eaton_snmp</code></td><td>适用于 Eaton 的 SNMP Fence 代理</td></tr><tr><td><code>fence_emerson</code></td><td>适用于 Emerson 的 SNMP Fence 代理</td></tr><tr><td><code>fence_eps</code></td><td>适用于 ePowerSwitch 的 Fence 代理</td></tr><tr><td><code>fence_evacuate</code></td><td>用于自动复活 OpenStack 计算实例的 Fence 代理</td></tr><tr><td><code>fence_heuristics_ping</code></td><td>基于 ping 进行启发式 Fencing 的代理</td></tr><tr><td><code>fence_hpblade</code></td><td>适用于 HP BladeSystem 的 Fence 代理</td></tr><tr><td><code>fence_ibmblade</code></td><td>通过 SNMP 控制 IBM BladeCenter 的 Fence 代理</td></tr><tr><td><code>fence_idrac</code></td><td>适用于 IPMI 的 Fence 代理</td></tr><tr><td><code>fence_ifmib</code></td><td>适用于 IF MIB 的 Fence 代理</td></tr><tr><td><code>fence_ilo</code></td><td>适用于 HP iLO 的 Fence 代理</td></tr><tr><td><code>fence_ilo2</code></td><td>适用于 HP iLO2 的 Fence 代理</td></tr><tr><td><code>fence_ilo3</code></td><td>适用于 IPMI 的 Fence 代理</td></tr><tr><td><code>fence_ilo3_ssh</code></td><td>通过 SSH 控制 HP iLO3 的 Fence 代理</td></tr><tr><td><code>fence_ilo4</code></td><td>适用于 IPMI 的 Fence 代理</td></tr><tr><td><code>fence_ilo4_ssh</code></td><td>通过 SSH 控制 HP iLO4 的 Fence 代理</td></tr><tr><td><code>fence_ilo5</code></td><td>适用于 IPMI 的 Fence 代理</td></tr><tr><td><code>fence_ilo5_ssh</code></td><td>通过 SSH 控制 HP iLO5 的 Fence 代理</td></tr><tr><td><code>fence_ilo_moonshot</code></td><td>适用于 HP Moonshot iLO 的 Fence 代理</td></tr><tr><td><code>fence_ilo_mp</code></td><td>适用于 HP iLO MP 的 Fence 代理</td></tr><tr><td><code>fence_ilo_ssh</code></td><td>通过 SSH 控制 HP iLO 的 Fence 代理</td></tr><tr><td><code>fence_imm</code></td><td>适用于 IPMI 的 Fence 代理</td></tr><tr><td><code>fence_intelmodular</code></td><td>适用于 Intel Modular 的 Fence 代理</td></tr><tr><td><code>fence_ipdu</code></td><td>通过 SNMP 控制 iPDU 的 Fence 代理</td></tr><tr><td><code>fence_ipmilan</code></td><td>适用于 IPMI 的 Fence 代理</td></tr><tr><td><code>fence_kdump</code></td><td>与 kdump 崩溃恢复服务一起使用的 Fence 代理</td></tr><tr><td><code>fence_mpath</code></td><td>用于多路径持久保留的 Fence 代理</td></tr><tr><td><code>fence_redfish</code></td><td>适用于 Redfish 的 I&#x2F;O Fencing 代理</td></tr><tr><td><code>fence_rhevm</code></td><td>适用于 RHEV-M REST API 的 Fence 代理</td></tr><tr><td><code>fence_rsa</code></td><td>适用于 IBM RSA 的 Fence 代理</td></tr><tr><td><code>fence_rsb</code></td><td>适用于 Fujitsu-Siemens RSB 的 I&#x2F;O Fencing 代理</td></tr><tr><td><code>fence_sbd</code></td><td>适用于 SBD 的 Fence 代理</td></tr><tr><td><code>fence_scsi</code></td><td>用于 SCSI 持久保留的 Fence 代理</td></tr><tr><td><code>fence_virt</code></td><td>适用于虚拟机的 Fence 代理</td></tr><tr><td><code>fence_vmware_rest</code></td><td>适用于 VMware REST API 的 Fence 代理</td></tr><tr><td><code>fence_vmware_soap</code></td><td>通过 SOAP API 控制 VMware 的 Fence 代理</td></tr><tr><td><code>fence_wti</code></td><td>适用于 WTI 的 Fence 代理</td></tr><tr><td><code>fence_xvm</code></td><td>适用于虚拟机的 Fence 代理</td></tr></tbody></table><p>想查看代理的具体用法，可以使用:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcs stonith describe stonith_agent</span><br></pre></td></tr></table></figure><p>使用 <code>fence_heuristics_ping</code> 作为代理，先通过<code>pcs stonith describe fence_heuristics_ping</code> 看下具体的用法和配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">fence_heuristics_ping - Fence agent for ping-heuristic based fencing</span><br><span class="line"></span><br><span class="line">fence_heuristics_ping uses ping-heuristics to control execution of another fence agent on the same fencing level.</span><br><span class="line"></span><br><span class="line">This is not a fence agent by itself! Its only purpose is to enable/disable another fence agent that lives on the same fencing level but after fence_heuristics_ping.</span><br><span class="line"></span><br><span class="line">Stonith options:</span><br><span class="line">  method: Method to fence</span><br><span class="line">  ping_count: The number of ping-probes that is being sent per target</span><br><span class="line">  ping_good_count: The number of positive ping-probes required to account a target as available</span><br><span class="line">  ping_interval: The interval in seconds between ping-probes</span><br><span class="line">  ping_maxfail: The number of failed ping-targets to still account as overall success</span><br><span class="line">  ping_targets (required): A comma separated list of ping-targets (optionally prepended by &#x27;inet:&#x27; or &#x27;inet6:&#x27;) to be probed</span><br><span class="line">  ping_timeout: The timeout in seconds till an individual ping-probe is accounted as lost</span><br><span class="line">  quiet: Disable logging to stderr. Does not affect --verbose or --debug-file or logging to syslog.</span><br><span class="line">  verbose: Verbose mode</span><br><span class="line">  debug: Write debug information to given file</span><br><span class="line">  delay: Wait X seconds before fencing is started</span><br><span class="line">  login_timeout: Wait X seconds for cmd prompt after login</span><br><span class="line">  power_timeout: Test X seconds for status change after ON/OFF</span><br><span class="line">  power_wait: Wait X seconds after issuing ON/OFF</span><br><span class="line">  shell_timeout: Wait X seconds for cmd prompt after issuing command</span><br><span class="line">  retry_on: Count of attempts to retry power on</span><br><span class="line">  pcmk_host_map: A mapping of host names to ports numbers for devices that do not support host names. Eg. node1:1;node2:2,3 would tell the cluster to use port 1 for node1 and ports 2 and 3</span><br><span class="line">                 for node2</span><br><span class="line">  pcmk_host_list: A list of machines controlled by this device (Optional unless pcmk_host_check=static-list).</span><br><span class="line">  pcmk_host_check: How to determine which machines are controlled by the device. Allowed values: dynamic-list (query the device via the &#x27;list&#x27; command), static-list (check the pcmk_host_list</span><br><span class="line">                   attribute), status (query the device via the &#x27;status&#x27; command), none (assume every device can fence every machine)</span><br><span class="line">  pcmk_delay_max: Enable a random delay for stonith actions and specify the maximum of random delay. This prevents double fencing when using slow devices such as sbd. Use this to enable a</span><br><span class="line">                  random delay for stonith actions. The overall delay is derived from this random delay value adding a static delay so that the sum is kept below the maximum delay.</span><br><span class="line">  pcmk_delay_base: Enable a base delay for stonith actions and specify base delay value. This prevents double fencing when different delays are configured on the nodes. Use this to enable a</span><br><span class="line">                   static delay for stonith actions. The overall delay is derived from a random delay value adding this static delay so that the sum is kept below the maximum delay.</span><br><span class="line">  pcmk_action_limit: The maximum number of actions can be performed in parallel on this device Pengine property concurrent-fencing=true needs to be configured first. Then use this to specify</span><br><span class="line">                     the maximum number of actions can be performed in parallel on this device. -1 is unlimited.</span><br><span class="line"></span><br><span class="line">Default operations:</span><br><span class="line">  monitor: interval=60s</span><br></pre></td></tr></table></figure><p>这里我们进行创建(其他参数都有默认值，按需修改即可):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pcs stonith create my_ping_fence_device fence_heuristics_ping \</span><br><span class="line">    ping_targets=<span class="string">&quot;node2,node3&quot;</span></span><br></pre></td></tr></table></figure><p>创建完成后<code>pcs status</code>查看状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Cluster name: mycluster</span><br><span class="line">Stack: corosync</span><br><span class="line">Current DC: node2 (version 1.1.23-1.el7_9.1-9acf116022) - partition with quorum</span><br><span class="line">Last updated: Tue Sep  3 14:40:56 2024</span><br><span class="line">Last change: Tue Sep  3 14:35:39 2024 by root via cibadmin on node2</span><br><span class="line"></span><br><span class="line">2 nodes configured</span><br><span class="line">1 resource instance configured</span><br><span class="line"></span><br><span class="line">Online: [ node2 node3 ]</span><br><span class="line"></span><br><span class="line">Full list of resources:</span><br><span class="line"></span><br><span class="line"> my_ping_fence_device(stonith:fence_heuristics_ping):Started node2</span><br><span class="line"></span><br><span class="line">Failed Fencing Actions:</span><br><span class="line">* reboot of my_apc_fence_device failed: delegate=, client=stonith_admin.40341, origin=node2,</span><br><span class="line">    last-failed=&#x27;Tue Sep  3 14:12:23 2024&#x27;</span><br><span class="line"></span><br><span class="line">Daemon Status:</span><br><span class="line">  corosync: active/enabled</span><br><span class="line">  pacemaker: active/enabled</span><br><span class="line">  pcsd: active/enabled</span><br></pre></td></tr></table></figure><p>验证 stonith 是否生效:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 cluster]# pcs stonith fence node3</span><br><span class="line">Node: node3 fenced</span><br></pre></td></tr></table></figure><p>执行完这个操作后，节点会离线，pcs 服务会停止，想要加回来的话，在停止的节点上重新启动集群即可:<code>pcs cluster start &amp;&amp; pcs cluster enable</code></p><h1 id="实战操作"><a href="#实战操作" class="headerlink" title="实战操作"></a>实战操作</h1><h2 id="添加节点"><a href="#添加节点" class="headerlink" title="添加节点"></a>添加节点</h2><p>上文中，我们构建了一个两节点的集群，我们可以尝试增加一个节点，构建一个三节点的集群</p><ol><li>首先在新节点上安装各种依赖，设置密码等。</li><li>在原集群上认证新 node</li><li>在原集群上添加 node：<code>pcs cluster node add node4</code></li><li>在 node4 上执行：<code>pcs cluster start &amp;&amp; pcs cluster enable</code></li></ol><p>再通过<code>pcs status</code>就可以看到新的节点已经加入</p><p>添加完之后还需要更新新节点的一些配置，比如上文提到的 stonith：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pcs stonith update my_ping_fence_device fence_heuristics_ping \</span><br><span class="line">    ping_targets=<span class="string">&quot;node2,node3,node4&quot;</span></span><br></pre></td></tr></table></figure><h2 id="配置-resource"><a href="#配置-resource" class="headerlink" title="配置 resource"></a>配置 resource</h2><h3 id="资源类型"><a href="#资源类型" class="headerlink" title="资源类型"></a>资源类型</h3><p>创建 resource 的基本格式为:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcs resource create resource-name ocf:heartbeat:apache [--options]</span><br></pre></td></tr></table></figure><p>这里的 ocf:heartbeat:apache 第一个部分ocf，指明了这个资源采用的标准(类型)，第二个部分标明这个资源脚本的在ocf中的名字空间，在这个例子中是heartbeat。最后一个部分指明了资源脚本的名称。</p><p>我们先看下有哪些标准类型</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node3 ~]# pcs resource standards</span><br><span class="line">lsb</span><br><span class="line">ocf</span><br><span class="line">service</span><br><span class="line">systemd</span><br></pre></td></tr></table></figure><p>查看可用的ocf资源提供者:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node3 ~]# pcs resource providers</span><br><span class="line">heartbeat</span><br><span class="line">openstack</span><br><span class="line">pacemaker</span><br></pre></td></tr></table></figure><p>查看特定标准下所支持的脚本，例：ofc:heartbeat 下的脚本(列举了部分)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@node3 ~]# pcs resource agents ocf:heartbeat</span><br><span class="line">aliyun-vpc-move-ip</span><br><span class="line">apache</span><br><span class="line">aws-vpc-move-ip</span><br><span class="line">aws-vpc-route53</span><br><span class="line">awseip</span><br><span class="line">awsvip</span><br><span class="line">azure-events</span><br><span class="line">azure-lb</span><br><span class="line">clvm</span><br><span class="line">conntrackd</span><br><span class="line">CTDB</span><br><span class="line">db2</span><br><span class="line">Delay</span><br><span class="line">dhcpd</span><br><span class="line">docker</span><br><span class="line">Dummy</span><br><span class="line">ethmonitor</span><br><span class="line">exportfs</span><br><span class="line">Filesystem</span><br><span class="line">galera</span><br><span class="line">garbd</span><br><span class="line">iface-vlan</span><br><span class="line">IPaddr</span><br><span class="line">IPaddr2</span><br></pre></td></tr></table></figure><h3 id="设置虚拟-ip"><a href="#设置虚拟-ip" class="headerlink" title="设置虚拟 ip"></a>设置虚拟 ip</h3><p>虚拟 IP（Virtual IP）是在高可用性集群中使用的一种技术，通过为服务提供一个不依赖于特定物理节点的 IP 地址来实现服务的高可用性。当集群中的某个节点出现故障时，虚拟 IP 可以迅速转移到另一个健康的节点上，从而保证服务的连续性。</p><p>虚拟 IP 的使用场景</p><ol><li>高可用性：虚拟 IP 最常见的使用场景是高可用性集群（如 Pacemaker 或 Keepalived），它允许一个服务在集群中的多个节点之间进行切换，而不会更改客户端访问的 IP 地址。</li><li>负载均衡：虚拟 IP 可以结合负载均衡器使用，将来自客户端的请求分配到多个后端服务器，以实现流量的均匀分布。</li><li>灾难恢复：在灾难恢复场景中，虚拟 IP 可以用于快速恢复服务，将业务流量从故障节点转移到备用节点上</li></ol><p>在 pcs 集群中，我们可以通过以下方式增加一个虚拟 ip:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcs resource create virtual_ip ocf:heartbeat:IPaddr2 ip=x.x.x.x cidr_netmask=32 nic=bond1 op monitor interval=30s</span><br></pre></td></tr></table></figure><p>执行完成后，通过<code>pcs status</code>就可以看到 ip 绑定在哪里:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtual_ip(ocf::heartbeat:IPaddr2):Started node3</span><br></pre></td></tr></table></figure><p>当我们关停 node3 的服务时，就会发现这个虚拟ip 绑定到了其他节点的 bond1 网卡上。</p><h3 id="增加服务"><a href="#增加服务" class="headerlink" title="增加服务"></a>增加服务</h3><p>我们以 httpd 服务为例，在集群中创建资源,首先安装对应服务:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum install httpd -y</span><br><span class="line"><span class="built_in">sudo</span> systemctl start httpd <span class="comment"># 这里可选择不启动，后续如果通过pcs 直接托管，需要先停掉，</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> httpd </span><br></pre></td></tr></table></figure><p>创建 resource:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcs resource create WebService ocf:heartbeat:apache configfile=/etc/httpd/conf/httpd.conf op monitor interval=30s</span><br></pre></td></tr></table></figure><h2 id="结合-LVS-ldirectord-进行使用"><a href="#结合-LVS-ldirectord-进行使用" class="headerlink" title="结合 LVS + ldirectord 进行使用"></a>结合 LVS + ldirectord 进行使用</h2><p>如果环境是一套多节点集群，在生产中我们肯定需要充分利用起这些节点，所以就要考虑流量分发。在这一层面上，我们可以使用 lvs 进行流量分发。这里首先对 lvs 对一个简单的介绍</p><p>LVS（Linux Virtual Server）是一个基于 IP 负载均衡技术的开源软件项目，主要用于构建高可用、高性能的负载均衡集群。LVS 是 Linux 内核的一部分，通过网络层的负载均衡技术，将来自客户端的请求分发到多个后端服务器，从而实现分布式处理、提高系统的处理能力和可靠性。</p><p>LVS 主要通过三种负载均衡模式（NAT 模式、DR 模式、TUN 模式）来实现流量的分发，支持大规模并发请求的处理，通常用于大型网站、电子商务平台和高访问量的 Web 应用中。</p><p>LVS 的特点</p><ol><li>高性能: LVS 工作在网络层（第4层），基于 IP 进行流量转发，性能极高。它能够处理大量的并发连接，适合高流量、大规模的网站和服务。</li><li>高可用性: LVS 通常与 Keepalived、Pacemaker 等高可用性工具配合使用，以实现负载均衡器的自动故障切换，确保服务的高可用性和稳定性。</li><li>多种负载均衡算法: LVS 提供了多种负载均衡算法，如轮询（Round Robin）、最小连接（Least Connection）、基于目标地址哈希（Destination Hashing）等，可以根据具体需求选择合适的算法进行流量分发。</li><li>多种工作模式, LVS 支持三种主要工作模式：<ul><li>   NAT 模式（网络地址转换模式）：LVS 充当请求和响应的中介，适用于小规模集群。</li><li>   DR 模式（直接路由模式）：请求由 LVS 转发，但响应直接返回给客户端，适用于大型集群，性能高。</li><li>   TUN 模式（IP 隧道模式）：类似于 DR 模式，但支持跨网络部署，非常适合广域网负载均衡。</li></ul></li><li>高扩展性: LVS 可以轻松地扩展和管理多台服务器，支持动态添加或移除后端服务器，适应业务需求的变化，且不影响服务的正常运行。</li><li>透明性: 对客户端和后端服务器来说，LVS 的存在是透明的。客户端并不感知负载均衡的存在，访问体验一致。后端服务器也不需要做特殊的配置，只需处理 LVS 转发的请求。</li><li>成熟且稳定: 作为一个成熟的负载均衡解决方案，LVS 被广泛应用于生产环境中，经过多年发展，功能完备，稳定性高。</li><li>安全性: LVS 可以与防火墙等安全工具结合使用，增强系统的安全性。此外，LVS 还支持 IP 地址过滤、端口过滤等功能，提供一定程度的安全保护。</li></ol><p>ldirectord 是一个守护进程，用于管理和监控由 LVS 提供的虚拟服务（Virtual Services）。其主要功能包括：</p><ol><li>   监控后端服务器：ldirectord 定期检查后端服务器的健康状况，确保只有健康的服务器参与流量分配。</li><li>   动态配置：基于后端服务器的健康状况，ldirectord 可以动态调整 LVS 的配置。例如，当一台服务器宕机时，ldirectord 会自动将其从 LVS 配置中移除。</li><li>   高可用性：结合 heartbeat 等高可用性工具，ldirectord 可以确保在主节点故障时，负载均衡服务能够自动切换到备用节点，继续提供服务。</li></ol><h3 id="安装部署-1"><a href="#安装部署-1" class="headerlink" title="安装部署"></a>安装部署</h3><p>安装lvs：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install lvm2 ipvsadm -y</span><br></pre></td></tr></table></figure><p>在这里找包有一些技巧，比如一开始 chatgpt 提供的说法是要安装<code>lvs</code> 和 <code>ipvsadm</code>，但是在我的环境上通过<code>yum install -y lvs</code> 的时候提示没有这个包，那我们可以通过 yum 提供的一些命令来简单锁定一下，比如 <code>yum provides lvs</code>,这样就会把包含了这个命令的包显示出来（适用于知道命令但是不知道是哪个包的场景），</p><p>安装 ldirector：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 这里我用 yum 下载是没有找到对应包的，找了一圈也没找到安装方法，所以直接找的 rpm 包</span><br><span class="line"># 下载地址: ftp://ftp.icm.edu.pl/vol/rzm3/linux-opensuse/update/leap/15.2/oss/x86_64/ldirectord-4.4.0+git57.70549516-lp152.2.9.1.x86_64.rpm</span><br><span class="line"># 上传到机器上后，进行安装</span><br><span class="line">rpm -Uvh --force ldirectord-4.4.0+git57.70549516-lp152.2.9.1.x86_64.rpm</span><br><span class="line"></span><br><span class="line"># 需要依赖，先安装依赖,再装包</span><br><span class="line">yum install -y perl-IO-Socket-INET6 perl-MailTools perl-Net-SSLeay perl-Socket6 perl-libwww-perl</span><br><span class="line"># 操作完成之后，启动服务</span><br><span class="line">systemctl start ldirectord.service</span><br></pre></td></tr></table></figure><p>服务启动失败:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/ldirectord.png" alt="ldirectord服务" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">ldirectord服务</span></div></div><p>这里有点坑，缺少了依赖的文件，但是装包的时候没有提示，需要再安装: <code>yum install -y perl-Sys-Syslog</code>, 安装完成后此问题消失，但是此时配置文件还没配置，所以服务还起不来。</p><h3 id="pcs-结合-lvs、ldirectord"><a href="#pcs-结合-lvs、ldirectord" class="headerlink" title="pcs 结合 lvs、ldirectord"></a>pcs 结合 lvs、ldirectord</h3><p>在上文中，我们创建了一个 httpd 服务和 vip 资源。 在实际生产中，要充分利用节点性能，我们可能要在多个节点上启动httpd 示例，我们在每个节点上都启动一个实例，然后将他们归到一个组中:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pcs resource delete WebService <span class="comment"># 移除之前创建的服务</span></span><br><span class="line">pcs resource create WebService1 ocf:heartbeat:apache configfile=/etc/httpd/conf/httpd.conf op monitor interval=30s</span><br><span class="line">pcs resource create WebService2 ocf:heartbeat:apache configfile=/etc/httpd/conf/httpd.conf op monitor interval=30s --force</span><br><span class="line">pcs resource create WebService3 ocf:heartbeat:apache configfile=/etc/httpd/conf/httpd.conf op monitor interval=30s --force <span class="comment"># 创建三个服务</span></span><br><span class="line"></span><br><span class="line">pcs constraint location WebService1 prefers node2</span><br><span class="line">pcs constraint location WebService2 prefers node3</span><br><span class="line">pcs constraint location WebService3 prefers node4  <span class="comment"># 限制对应 resource 服务只能在指定节点上运行</span></span><br></pre></td></tr></table></figure><p>配置 ldirectord:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">checktimeout=10</span><br><span class="line">checkinterval=2</span><br><span class="line">autoreload=yes</span><br><span class="line">logfile=&quot;/var/log/ldirectord.log&quot;</span><br><span class="line">quiescent=yes</span><br><span class="line"></span><br><span class="line">virtual=vip:80 # 之前绑定的 VIP</span><br><span class="line">    real=192.168.1.2:80 gate</span><br><span class="line">    real=192.168.1.3:80 gate</span><br><span class="line">    real=192.168.1.4:80 gate</span><br><span class="line">    fallback=127.0.0.1:80</span><br><span class="line">    service=http</span><br><span class="line">    request=&quot;index.html&quot;</span><br><span class="line">    receive=&quot;HTTP/1.1 200 OK&quot;</span><br><span class="line">    scheduler=rr</span><br><span class="line">    protocol=tcp</span><br><span class="line">    checktype=negotiate</span><br></pre></td></tr></table></figure><p>然后在通过 <code>ipvsadm -ln</code> 就可以查看到详细的信息:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  vip:80 rr</span><br><span class="line">  -&gt; 192.168.1.2:80               Route   0      0          0</span><br><span class="line">  -&gt; 192.168.1.3:80               Route   0      0          0</span><br><span class="line">  -&gt; 192.168.1.4:80               Route   0      0          0</span><br><span class="line">  -&gt; 127.0.0.1:80                 Route   1      0          0</span><br></pre></td></tr></table></figure><p>然后我们可以在 pcs 上创建一个资源 lvs 相关的资源:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pcs resource create my_lvs ocf:heartbeat:ldirectord \</span><br><span class="line">    configfile=/etc/ha.d/ldirectord.cf \</span><br><span class="line">    ldirectord=/usr/sbin/ldirectord  \</span><br><span class="line">    op monitor interval=15s <span class="built_in">timeout</span>=60s \</span><br><span class="line">    op stop <span class="built_in">timeout</span>=60s</span><br></pre></td></tr></table></figure><p>这里的ocf:heartbeat:ldirectord 在有的版本中会默认安装，有的版本不会，如果没有的话需要手动下载: <a href="https://github.com/ClusterLabs/resource-agents/blob/main/ldirectord/OCF/ldirectord.in">https://github.com/ClusterLabs/resource-agents/blob/main/ldirectord/OCF/ldirectord.in</a><br>存放到: <code>/usr/lib/ocf/resource.d/heartbeat/ldirectord</code> 并添加可执行权限: <code>chmod +x /usr/lib/ocf/resource.d/heartbeat/ldirectord</code></p><p>创建完成后，我们可以将 vip 和 lvs 绑定到一个组中，这样 lvs 就会跟着 vip 进行转移了:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcs resource group add balanceGroup virtual_ip my_lvs</span><br></pre></td></tr></table></figure><p>通过<code>pcs status</code>查看就可以看到:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Resource Group: balanceGroup</span><br><span class="line">     virtual_ip(ocf::heartbeat:IPaddr2):Started node2</span><br><span class="line">     my_lvs(ocf::heartbeat:ldirectord):Started node2</span><br></pre></td></tr></table></figure><p>不断对节点进行关闭测试，可以看到 lvs 和 vip 始终都在同一个节点上</p><h2 id="增加节点属性"><a href="#增加节点属性" class="headerlink" title="增加节点属性"></a>增加节点属性</h2><p>我们这里使用另外一个观察集群状态的命令:<code>crm_mon</code>, 比如<code>crm_mon -A1</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 rpm]# crm_mon -A1</span><br><span class="line">Stack: corosync</span><br><span class="line">Current DC: node3 (version 1.1.23-1.el7_9.1-9acf116022) - partition with quorum</span><br><span class="line">Last updated: Thu Sep  5 22:09:53 2024</span><br><span class="line">Last change: Wed Sep  4 18:17:25 2024 by root via cibadmin on node3</span><br><span class="line"></span><br><span class="line">3 nodes configured</span><br><span class="line">6 resource instances configured</span><br><span class="line"></span><br><span class="line">Online: [ node2 node3 node4 ]</span><br><span class="line"></span><br><span class="line">Active resources:</span><br><span class="line"></span><br><span class="line"> my_ping_fence_device(stonith:fence_heuristics_ping):Started node3</span><br><span class="line"> WebService1(ocf::heartbeat:apache):Started node4</span><br><span class="line"> WebService2(ocf::heartbeat:apache):Started node3</span><br><span class="line"> WebService3(ocf::heartbeat:apache):Started node4</span><br><span class="line"> Resource Group: balanceGroup</span><br><span class="line">     virtual_ip(ocf::heartbeat:IPaddr2):Started node2</span><br><span class="line">     my_lvs(ocf::heartbeat:ldirectord):Started node2</span><br><span class="line"></span><br><span class="line">Node Attributes:</span><br><span class="line">* Node node2:</span><br><span class="line">* Node node3:</span><br><span class="line">* Node node4:</span><br><span class="line">.....</span><br></pre></td></tr></table></figure><p>输出和<code>pcs status</code>查看到的效果基本上是差不多的。但是在下面有<code>Node Attributes</code>，这里我们看下节点属性怎么设置:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pcs node attribute node2 role=master</span><br><span class="line">pcs node attribute node3 role=standby</span><br><span class="line">pcs node attribute node4 role=standby</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crm_attribute --node node2 --name mysql --update master</span><br><span class="line">crm_attribute --node node3 --name mysql --update standby</span><br></pre></td></tr></table></figure><p>设置完成之后，我们就可以看到节点属性:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Node Attributes:</span><br><span class="line">* Node node2:</span><br><span class="line">    + mysql                           : master</span><br><span class="line">    + role                            : master</span><br><span class="line">* Node node3:</span><br><span class="line">    + mysql                           : standby</span><br><span class="line">    + role                            : standby</span><br><span class="line">* Node node4:</span><br><span class="line">    + role                            : standby</span><br></pre></td></tr></table></figure><p>那有人就会好奇这样设置有什么用呢？主要用途是在哪里呢。</p><p>这里的指标往往是动态的，可以根据自己喜好结合一些扩展进行变化，比如部署了一套 postgresql 集群，集群中有主有备，有同步节点也有异步节点，有的节点状态可能有问题，那我们怎么能够显示出这个集群的整体情况呢，这样就可以使用 Node Attributes进行设置，关于如果搭建 pcs + postgresql 的集群，大家可以参考这篇文章: <a href="https://www.cnblogs.com/Alicebat/p/14148933.html">基于Pacemaker的PostgreSQL高可用集群</a></p><p>最终我们看到的效果如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Node Attributes:</span><br><span class="line">* Node pg01:</span><br><span class="line">    + master-pgsql                    : 1000      </span><br><span class="line">    + pgsql-data-status               : LATEST    </span><br><span class="line">    + pgsql-master-baseline           : 0000000008000098</span><br><span class="line">    + pgsql-status                    : PRI       </span><br><span class="line">* Node pg02:</span><br><span class="line">    + master-pgsql                    : -INFINITY </span><br><span class="line">    + pgsql-data-status               : STREAMING|ASYNC</span><br><span class="line">    + pgsql-status                    : HS:async  </span><br><span class="line">* Node pg03:</span><br><span class="line">    + master-pgsql                    : 100       </span><br><span class="line">    + pgsql-data-status               : STREAMING|SYNC</span><br><span class="line">    + pgsql-status                    : HS:sync   </span><br></pre></td></tr></table></figure><p>当集群发生节点变动，状态异常时，我们就可以根据 attibutes 的一些信息查看定位。</p>]]></content>
    
    
    <summary type="html">Pacemaker+Corosync使用简介</summary>
    
    
    
    <category term="高可用" scheme="http://baixiaozhou.github.io/categories/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
    
    <category term="Linux" scheme="http://baixiaozhou.github.io/tags/Linux/"/>
    
    <category term="Pacemaker" scheme="http://baixiaozhou.github.io/tags/Pacemaker/"/>
    
    <category term="Corosync" scheme="http://baixiaozhou.github.io/tags/Corosync/"/>
    
    <category term="高可用方案" scheme="http://baixiaozhou.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88/"/>
    
    <category term="负载均衡" scheme="http://baixiaozhou.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
    <category term="LVS" scheme="http://baixiaozhou.github.io/tags/LVS/"/>
    
  </entry>
  
  <entry>
    <title>工作随记</title>
    <link href="http://baixiaozhou.github.io/p/%E5%B7%A5%E4%BD%9C%E9%9A%8F%E8%AE%B0/"/>
    <id>http://baixiaozhou.github.io/p/%E5%B7%A5%E4%BD%9C%E9%9A%8F%E8%AE%B0/</id>
    <published>2024-08-21T10:28:27.000Z</published>
    <updated>2024-10-10T09:27:35.903Z</updated>
    
    <content type="html"><![CDATA[<!-- Your content starts here --><h2 id="Centos-安装-EBPF"><a href="#Centos-安装-EBPF" class="headerlink" title="Centos 安装 EBPF"></a>Centos 安装 EBPF</h2><p>安装必要工具和依赖:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> yum install python3 python3-pip python3-devel gcc gcc-c++ make bcc bcc-tools bcc-devel</span><br></pre></td></tr></table></figure><p>安装 BCC Python 模块</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install bcc</span><br></pre></td></tr></table></figure><p>离线安装的方式如下：</p><ol><li>下载 bcc 和 Python 模块源包<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载 bcc 的源码包</span></span><br><span class="line">wget https://github.com/iovisor/bcc/archive/refs/tags/v0.22.0.tar.gz -O bcc.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 bcc 的 Python 模块源代码包</span></span><br><span class="line"><span class="comment"># 可以去这里 https://pypi.org/project/bcc/#files 进行查找</span></span><br><span class="line">wget https://files.pythonhosted.org/packages/38/dc/3ca34874926789f8df53f3c1d1c38e77ebf876f43760e8745316bb8bd1c0/bcc-0.1.10.tar.gz</span><br></pre></td></tr></table></figure></li><li>上传文件到离线环境上,解压并进行安装:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tar -xzf bcc.tar.gz</span><br><span class="line"><span class="built_in">cd</span> bcc-0.22.0  <span class="comment"># 目录名可能会有所不同</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装系统依赖（可能需要根权限）</span></span><br><span class="line"><span class="built_in">sudo</span> yum install -y gcc gcc-c++ make bpfcc-tools  <span class="comment"># CentOS/RHEL</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install -y gcc g++ make bpfcc-tools  <span class="comment"># Ubuntu/Debian</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译和安装 bcc</span></span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br><span class="line"><span class="built_in">sudo</span> make install</span><br></pre></td></tr></table></figure></li><li>安装 bcc Python 模块<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压下载的 Python 模块源代码包</span></span><br><span class="line">tar -xzf bcc-python.tar.gz</span><br><span class="line"><span class="built_in">cd</span> bcc-python  <span class="comment"># 目录名可能会有所不同</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 Python 模块</span></span><br><span class="line">pip3 install .</span><br></pre></td></tr></table></figure></li></ol><h2 id="iperf-测试带宽打不满"><a href="#iperf-测试带宽打不满" class="headerlink" title="iperf 测试带宽打不满"></a>iperf 测试带宽打不满</h2><p>iperf3 作为iperf 系列网络测试工具新一代工具，开发团队重写代码使之有全新的实现方式，更少的代码量，更加小巧，但这也导致了其与iperf工具前后不兼容，一些命令执行具有差异化</p><p>iperf3 是不支持多线程的，与iperf 通过-P 参数增加数据并行流开启多线程不同，iperf3 增加-P 参数也是单线程的，测试过程中所有并行流运行与同一个CPU核心，这将限制我们获得最大的带宽测试结果，为了解决这一问题，可以增加iperf3的进程。</p><p>Server端: </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf3 -s -p 5201 &amp; iperf3 -s -p 5202 &amp; iperf3 -s -p 5203&amp;</span><br></pre></td></tr></table></figure><p>Client端:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iperf3 -c <span class="variable">$ip</span>  -i 5 -t 100 -P 11 -p 5201 &amp; </span><br><span class="line">iperf3 -c <span class="variable">$ip</span>  -i 5 -t 100 -P 11 -p 5202 &amp; </span><br><span class="line">iperf3 -c <span class="variable">$ip</span>  -i 5 -t 100 -P 11 -p 5203 &amp; </span><br></pre></td></tr></table></figure><h2 id="mac-tar-打包文件后到-linux-解压后出现-开头的文件"><a href="#mac-tar-打包文件后到-linux-解压后出现-开头的文件" class="headerlink" title="mac tar 打包文件后到 linux 解压后出现 ._ 开头的文件"></a>mac tar 打包文件后到 linux 解压后出现 ._ 开头的文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar --disable-copyfile -czvf archive_name.tar.gz /path/to/file_or_directory</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">记录工作中的一些日常操作</summary>
    
    
    
    <category term="工作随记" scheme="http://baixiaozhou.github.io/categories/%E5%B7%A5%E4%BD%9C%E9%9A%8F%E8%AE%B0/"/>
    
    
    <category term="Linux" scheme="http://baixiaozhou.github.io/tags/Linux/"/>
    
    <category term="ebpf" scheme="http://baixiaozhou.github.io/tags/ebpf/"/>
    
  </entry>
  
  <entry>
    <title>ansible详细介绍</title>
    <link href="http://baixiaozhou.github.io/p/ansible%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    <id>http://baixiaozhou.github.io/p/ansible%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/</id>
    <published>2024-08-19T11:09:34.000Z</published>
    <updated>2024-09-18T02:30:17.163Z</updated>
    
    <content type="html"><![CDATA[<!-- Your content starts here --><div class="tag-plugin quot"><p class="content" type="text"><span class="empty"></span><span class="text">官方文档</span><span class="empty"></span></p></div><p><a href="https://docs.ansible.com/ansible/latest/index.html">英文文档</a><br><a href="http://www.ansible.com.cn/docs/intro_adhoc.html">中文文档</a></p><h1 id="ansible-介绍"><a href="#ansible-介绍" class="headerlink" title="ansible 介绍"></a>ansible 介绍</h1><p>我们先看一下 ansible 的相关介绍:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.</span><br></pre></td></tr></table></figure><p>这里有几点核心:</p><ol><li>ansible 是一个自动化平台</li><li>ansible 使用 ssh 协议（通过密码或者密钥等方式进行访问），部署简单，没有客户端，只需在主控端部署 Ansible 环境，无需在远程系统上安装代理程序</li><li>模块化：调用特定的模块，完成特定任务</li><li>支持自定义扩展</li></ol><p>每开发一个工具或者平台的时候，这些工具和平台提供了各种各样的功能，那么我们能用 ansible 来干什么呢？ 下面就是一些 ansible 核心的功能介绍：</p><table><thead><tr><th>功能</th><th>描述</th><th>常见场景示例</th></tr></thead><tbody><tr><td>配置管理</td><td>自动化管理服务器和设备的配置，确保它们处于期望的状态。</td><td>自动化安装和配置 Web 服务器，确保所有服务器配置一致。</td></tr><tr><td>应用部署</td><td>自动化应用程序的部署过程，从代码库拉取到在服务器上部署和配置应用。</td><td>自动部署多层 Web 应用程序，包括数据库设置、应用服务部署、负载均衡配置等。</td></tr><tr><td>持续交付与持续集成（CI&#x2F;CD）</td><td>与 CI&#x2F;CD 工具集成，实现自动化的构建、测试和部署流程。</td><td>代码提交后自动执行测试、构建容器镜像，并部署到 Kubernetes 集群中。</td></tr><tr><td>基础设施即代码（IaC）</td><td>编写和管理基础设施的配置文件，使其像管理代码一样。</td><td>使用 Ansible Playbooks 定义云环境资源配置，实现可重复的基础设施部署。</td></tr><tr><td>云管理</td><td>自动化云服务资源的管理，包括虚拟机、存储、网络等的创建和配置。</td><td>自动化创建和管理 AWS EC2 实例、配置 VPC 和安全组。</td></tr><tr><td>网络自动化</td><td>管理和配置网络设备，使得大规模的网络设备配置变得简单和一致。</td><td>自动化配置多台交换机的 VLAN 设置和路由协议。</td></tr><tr><td>安全与合规</td><td>自动化安全补丁的部署、系统安全配置的强化以及合规性检查。</td><td>自动化应用系统安全补丁，配置防火墙规则，执行安全扫描和合规性检查。</td></tr><tr><td>多平台环境管理</td><td>支持多种操作系统，在混合环境中统一管理平台上的配置和应用。</td><td>在混合的 Linux 和 Windows 服务器环境中，统一部署和配置监控软件。</td></tr><tr><td>灾难恢复</td><td>自动化灾难恢复流程，如备份、数据恢复和服务恢复。</td><td>自动化数据库备份并在需要时恢复和重建数据库服务。</td></tr><tr><td>任务调度与批量操作</td><td>通过 Playbooks 调度定期任务或对大量服务器执行批量操作。</td><td>定期清理服务器上的临时文件或批量更新多个服务器的操作系统。</td></tr></tbody></table><h2 id="ansible的工作机制"><a href="#ansible的工作机制" class="headerlink" title="ansible的工作机制"></a>ansible的工作机制</h2><p>Ansible 在管理节点将 Ansible 模块通过 SSH 协议推送到被管理端执行，执行完之后自动删除，可以使用 SVN 等来管理自定义模块及编排</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/ansible-diagram.png" alt="ansible结构" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">ansible结构</span></div></div><p>从这张图中我们可以看到，ansible 由以下模块组成</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Ansible： ansible的核心模块</span><br><span class="line">Host Inventory：主机清单，也就是被管理的主机列表</span><br><span class="line">Playbooks：ansible的剧本，可想象为将多个任务放置在一起，一块执行</span><br><span class="line">Core Modules：ansible的核心模块</span><br><span class="line">Custom Modules：自定义模块</span><br><span class="line">Connection Plugins：连接插件，用于与被管控主机之间基于SSH建立连接关系</span><br><span class="line">Plugins：其他插件，包括记录日志等</span><br></pre></td></tr></table></figure><h2 id="ansible-安装"><a href="#ansible-安装" class="headerlink" title="ansible 安装"></a>ansible 安装</h2><p>在 centos 环境下，我们可以通过：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ansible -y 进行安装</span><br></pre></td></tr></table></figure><p>安装完成后我们看下 ansible 提供了哪些命令:</p><table><thead><tr><th>命令</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td><code>ansible</code></td><td>用于在一个或多个主机上运行单个模块（通常用于临时命令）。</td><td><code>ansible all -m ping</code></td></tr><tr><td><code>ansible-playbook</code></td><td>用于运行 Ansible playbook 文件，是 Ansible 的核心命令之一。</td><td><code>ansible-playbook site.yml</code></td></tr><tr><td><code>ansible-galaxy</code></td><td>用于管理 Ansible 角色和集合。可以下载、创建和分享角色。</td><td><code>ansible-galaxy install geerlingguy.apache</code></td></tr><tr><td><code>ansible-vault</code></td><td>用于加密和解密敏感数据（如密码、密钥）。</td><td><code>ansible-vault encrypt secrets.yml</code></td></tr><tr><td><code>ansible-doc</code></td><td>显示 Ansible 模块的文档和示例用法。</td><td><code>ansible-doc -l</code></td></tr><tr><td><code>ansible-config</code></td><td>用于查看、验证和管理 Ansible 配置文件。</td><td><code>ansible-config list</code></td></tr><tr><td><code>ansible-inventory</code></td><td>管理和检索 Ansible inventory 信息。</td><td><code>ansible-inventory --list -i inventory.yml</code></td></tr><tr><td><code>ansible-pull</code></td><td>用于从远程版本控制系统（如 Git）拉取 playbook 并在本地执行，常用于自动化部署。</td><td><code>ansible-pull -U https://github.com/username/repo.git</code></td></tr><tr><td><code>ansible-console</code></td><td>提供一个交互式命令行接口，可用于动态执行 Ansible 任务和命令。</td><td><code>ansible-console</code></td></tr></tbody></table><p>对两个比较常用的命令:<code>ansible</code> 和 <code>ansible-plabook</code> 做一下具体的介绍:</p><h3 id="ansible-命令"><a href="#ansible-命令" class="headerlink" title="ansible 命令"></a>ansible 命令</h3><p>命令格式:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible 组名 -m 模块名 -a <span class="string">&#x27;参数&#x27;</span></span><br></pre></td></tr></table></figure><p>这里的组名是自定义的一系列组信息，组的定义在后面会讲到。</p><p>模块名是ansible提供的一些列支持模块，默认模块是 command，查看 ansible 支持的模块：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-doc -l <span class="comment">#大概有 3000 多个</span></span><br></pre></td></tr></table></figure><p>ansible涉及到的模块非常非常多，按照实际需要使用，初步先掌握一些比较常用的就可以</p><p>查看模块描述：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-doc -s 模块名称</span><br></pre></td></tr></table></figure><p>实例:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看webserver 组机器的时间信息</span></span><br><span class="line">ansible webserver -m shell -a <span class="string">&quot;date&quot;</span> <span class="comment"># 这里的组就是 webserver，shell 是模块名（比较常用的模块）date 是具体执行的命令</span></span><br><span class="line"><span class="comment"># 将本机的/tmp/test.sh 拷贝到其他机器上的 /etc目录下</span></span><br><span class="line">ansible webserver -m copy -a <span class="string">&quot;src=/tmp/test.sh dest=/etc/test.sh&quot;</span> <span class="comment"># 这里的 copy 是模块名，里面的 src 是源路径，dest 是目标路径</span></span><br></pre></td></tr></table></figure><h3 id="ansible-playbook命令"><a href="#ansible-playbook命令" class="headerlink" title="ansible-playbook命令"></a>ansible-playbook命令</h3><p>用于执行 Ansible Playbooks。Playbooks 是一系列任务的集合，用于自动化配置管理、应用部署、任务执行等操作。<br>基本语法:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook [options] playbook.yml</span><br></pre></td></tr></table></figure><p>命令帮助:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">positional arguments:</span><br><span class="line">  playbook              Playbook(s)</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  --ask-vault-pass      ask for vault password</span><br><span class="line">  --flush-cache         clear the fact cache for every host in inventory</span><br><span class="line">  --force-handlers      run handlers even if a task fails</span><br><span class="line">  --list-hosts          outputs a list of matching hosts; does not execute</span><br><span class="line">                        anything else</span><br><span class="line">  --list-tags           list all available tags</span><br><span class="line">  --list-tasks          list all tasks that would be executed</span><br><span class="line">  --skip-tags SKIP_TAGS</span><br><span class="line">                        only run plays and tasks whose tags do not match these</span><br><span class="line">                        values</span><br><span class="line">  --start-at-task START_AT_TASK</span><br><span class="line">                        start the playbook at the task matching this name</span><br><span class="line">  --step                one-step-at-a-time: confirm each task before running</span><br><span class="line">  --syntax-check        perform a syntax check on the playbook, but do not</span><br><span class="line">                        execute it</span><br><span class="line">  --vault-id VAULT_IDS  the vault identity to use</span><br><span class="line">  --vault-password-file VAULT_PASSWORD_FILES</span><br><span class="line">                        vault password file</span><br><span class="line">  --version             show program&#x27;s version number, config file location,</span><br><span class="line">                        configured module search path, module location,</span><br><span class="line">                        executable location and exit</span><br><span class="line">  -C, --check           don&#x27;t make any changes; instead, try to predict some</span><br><span class="line">                        of the changes that may occur</span><br><span class="line">  -D, --diff            when changing (small) files and templates, show the</span><br><span class="line">                        differences in those files; works great with --check</span><br><span class="line">  -M MODULE_PATH, --module-path MODULE_PATH</span><br><span class="line">                        prepend colon-separated path(s) to module library (def</span><br><span class="line">                        ault=~/.ansible/plugins/modules:/usr/share/ansible/plu</span><br><span class="line">                        gins/modules)</span><br><span class="line">  -e EXTRA_VARS, --extra-vars EXTRA_VARS</span><br><span class="line">                        set additional variables as key=value or YAML/JSON, if</span><br><span class="line">                        filename prepend with @</span><br><span class="line">  -f FORKS, --forks FORKS</span><br><span class="line">                        specify number of parallel processes to use</span><br><span class="line">                        (default=64)</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  -i INVENTORY, --inventory INVENTORY, --inventory-file INVENTORY</span><br><span class="line">                        specify inventory host path or comma separated host</span><br><span class="line">                        list. --inventory-file is deprecated</span><br><span class="line">  -l SUBSET, --limit SUBSET</span><br><span class="line">                        further limit selected hosts to an additional pattern</span><br><span class="line">  -t TAGS, --tags TAGS  only run plays and tasks tagged with these values</span><br><span class="line">  -v, --verbose         verbose mode (-vvv for more, -vvvv to enable</span><br><span class="line">                        connection debugging)</span><br><span class="line"></span><br><span class="line">Connection Options:</span><br><span class="line">  control as whom and how to connect to hosts</span><br><span class="line"></span><br><span class="line">  --private-key PRIVATE_KEY_FILE, --key-file PRIVATE_KEY_FILE</span><br><span class="line">                        use this file to authenticate the connection</span><br><span class="line">  --scp-extra-args SCP_EXTRA_ARGS</span><br><span class="line">                        specify extra arguments to pass to scp only (e.g. -l)</span><br><span class="line">  --sftp-extra-args SFTP_EXTRA_ARGS</span><br><span class="line">                        specify extra arguments to pass to sftp only (e.g. -f,</span><br><span class="line">                        -l)</span><br><span class="line">  --ssh-common-args SSH_COMMON_ARGS</span><br><span class="line">                        specify common arguments to pass to sftp/scp/ssh (e.g.</span><br><span class="line">                        ProxyCommand)</span><br><span class="line">  --ssh-extra-args SSH_EXTRA_ARGS</span><br><span class="line">                        specify extra arguments to pass to ssh only (e.g. -R)</span><br><span class="line">  -T TIMEOUT, --timeout TIMEOUT</span><br><span class="line">                        override the connection timeout in seconds</span><br><span class="line">                        (default=10)</span><br><span class="line">  -c CONNECTION, --connection CONNECTION</span><br><span class="line">                        connection type to use (default=smart)</span><br><span class="line">  -k, --ask-pass        ask for connection password</span><br><span class="line">  -u REMOTE_USER, --user REMOTE_USER</span><br><span class="line">                        connect as this user (default=None)</span><br><span class="line"></span><br><span class="line">Privilege Escalation Options:</span><br><span class="line">  control how and which user you become as on target hosts</span><br><span class="line"></span><br><span class="line">  --become-method BECOME_METHOD</span><br><span class="line">                        privilege escalation method to use (default=sudo), use</span><br><span class="line">                        `ansible-doc -t become -l` to list valid choices.</span><br><span class="line">  --become-user BECOME_USER</span><br><span class="line">                        run operations as this user (default=root)</span><br><span class="line">  -K, --ask-become-pass</span><br><span class="line">                        ask for privilege escalation password</span><br><span class="line">  -b, --become          run operations with become (does not imply password</span><br><span class="line">                        prompting)</span><br></pre></td></tr></table></figure><h1 id="ansible-基本使用"><a href="#ansible-基本使用" class="headerlink" title="ansible 基本使用"></a>ansible 基本使用</h1><p>我们先看一个最基本的 ansible 组成:</p><div class="tag-plugin image"><div class="image-bg"><img src="https://docs.ansible.com/ansible/latest/_images/ansible_inv_start.svg" alt="ansible基本组成" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">ansible基本组成</span></div></div><p>如上图所示，大部分的 ansible 环境都包含以下三个组件:</p><ol><li>控制节点:安装了Ansible的系统。可以在控制节点上运行Ansible命令，例如ansible或ansible-inventory。</li><li>Inventory: 按逻辑组织的托管节点的列表。可以在控制节点上创建一个清单，以向Ansible描述主机部署。</li><li>被管理节点: Ansible控制的远程系统或主机。</li></ol><h2 id="Inventory文件"><a href="#Inventory文件" class="headerlink" title="Inventory文件"></a>Inventory文件</h2><p>inventory 主要包括主机和组两个概念, 默认文件 <code>/etc/ansible/hosts</code></p><h3 id="主机"><a href="#主机" class="headerlink" title="主机"></a>主机</h3><p>主机是 Ansible 可以管理的单个设备或虚拟机。主机可以是物理服务器、虚拟机、容器，甚至是网络设备（如路由器和交换机）。每个主机都有一个唯一的标识（通常是主机名或 IP 地址），并且可以通过 Ansible 的 inventory 文件或其他动态方法来定义</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 定义单个主机</span><br><span class="line">web1.example.com</span><br><span class="line"></span><br><span class="line"># 定义多个主机</span><br><span class="line">web2.example.com</span><br><span class="line">192.168.1.10</span><br><span class="line"></span><br><span class="line"># 主机变量</span><br><span class="line">[atlanta]</span><br><span class="line">host1 http_port=80 maxRequestsPerChild=808</span><br><span class="line">host2 http_port=303 maxRequestsPerChild=909</span><br></pre></td></tr></table></figure><h3 id="组"><a href="#组" class="headerlink" title="组"></a>组</h3><p>组是主机的集合，可以对一组主机应用相同的配置或操作。组允许用户在多个主机上批量执行任务。一个主机可以属于多个组。组之间还可以嵌套，例如，你可以将所有 Web 服务器放在一个组中，然后将该组嵌套在一个更大的生产环境组中</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一下所有节点的信息</span></span><br><span class="line"><span class="section">[all_hosts]</span></span><br><span class="line">node1 <span class="attr">public_ip</span>=<span class="number">192.168</span>.<span class="number">1.101</span> ansible_host=<span class="number">192.168</span>.<span class="number">1.101</span> ansible_user=your_user ansible_ssh_pass=your_password ansible_port=<span class="number">22</span></span><br><span class="line">node2 <span class="attr">public_ip</span>=<span class="number">192.168</span>.<span class="number">1.102</span> ansible_host=<span class="number">192.168</span>.<span class="number">1.102</span> ansible_user=your_user ansible_ssh_pass=your_password ansible_port=<span class="number">22</span></span><br><span class="line">node3 <span class="attr">public_ip</span>=<span class="number">192.168</span>.<span class="number">1.103</span> ansible_host=<span class="number">192.168</span>.<span class="number">1.103</span> ansible_user=your_user ansible_ssh_pass=your_password ansible_port=<span class="number">22</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个 mysql 组，假如要在 node1 和 node2上部署 mysql</span></span><br><span class="line"><span class="section">[mysql]</span></span><br><span class="line">node1</span><br><span class="line">node2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个 nginx 组，假如要在 node1 和 node3上部署 nginx</span></span><br><span class="line"><span class="section">[nginx]</span></span><br><span class="line">node1</span><br><span class="line">node3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假如我们还想部署一个 redis 组，mysql 部署在那里，redis 就部署在那里，重新写一遍很麻烦，那么我们可以把 redis 当做 mysql 的子集</span></span><br><span class="line"><span class="comment"># 这里有一个疑问，我们既然用一个一模一样的组再了，为啥搞个 children，直接用原来的组不行吗，这里可以是可以，但是从模块划分来看，做一下区分易于后续的管理</span></span><br><span class="line"><span class="section">[redis:children]</span></span><br><span class="line">mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义组变量</span></span><br><span class="line"><span class="section">[atlanta:vars]</span></span><br><span class="line"><span class="attr">ntp_server</span>=ntp.atlanta.example.com</span><br><span class="line"><span class="attr">proxy</span>=proxy.atlanta.example.com</span><br></pre></td></tr></table></figure><h2 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h2><p>在我们了解完 inventory 之后，我们开始做一些简单的模拟:</p><ol><li>在 node1 上安装 ansible，作为控制节点，在&#x2F;etc&#x2F;ansbile&#x2F;hosts中加入三个节点的信息</li><li>如果是通过密码连接的话，需要在 ansible_ssh_pass中输入机器密码，如果是通过密钥链接，这里可不填；配置 ssh 免密登录，可以自行百度，这里只需要配置 node1 到所有节点的免密（包括 node1 到 node1 自己）</li><li>免密配置完成后，我们可以做一下简单的操作:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 mysql 组机器的时间信息</span></span><br><span class="line">ansilbe mysql -m shell -a <span class="string">&quot;date&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 nginx 组机器的启动时间</span></span><br><span class="line">ansible nginx -m shell -a <span class="string">&quot;uptime&quot;</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="playbooks"><a href="#playbooks" class="headerlink" title="playbooks"></a>playbooks</h1><p>playbook是由一个或多个play组成的列表，play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上来讲，所谓的task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让它们联合起来按事先编排的机制完成某一任务</p><h2 id="playbook语法"><a href="#playbook语法" class="headerlink" title="playbook语法:"></a>playbook语法:</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">playbook使用yaml语法格式，后缀可以是yaml,也可以是yml。</span><br><span class="line"></span><br><span class="line">在单个playbook文件中，可以连续三个连子号(---)区分多个play。还有选择性的连续三个点好(...)用来表示play的结尾，也可省略。</span><br><span class="line"></span><br><span class="line">次行开始正常写playbook的内容，一般都会写上描述该playbook的功能。</span><br><span class="line"></span><br><span class="line">使用#号注释代码。</span><br><span class="line"></span><br><span class="line">缩进必须统一，不能空格和tab混用。</span><br><span class="line"></span><br><span class="line">缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过缩进结合换行实现的。</span><br><span class="line"></span><br><span class="line">YAML文件内容和Linux系统大小写判断方式保持一致，是区分大小写的，k/v的值均需大小写敏感</span><br><span class="line"></span><br><span class="line">k/v的值可同行写也可以换行写。同行使用:分隔。</span><br><span class="line"></span><br><span class="line">v可以是个字符串，也可以是一个列表</span><br><span class="line"></span><br><span class="line">一个完整的代码块功能需要最少元素包括 name: task</span><br></pre></td></tr></table></figure><h2 id="playbook核心元素"><a href="#playbook核心元素" class="headerlink" title="playbook核心元素"></a>playbook核心元素</h2><h3 id="1-Play"><a href="#1-Play" class="headerlink" title="1. Play"></a>1. Play</h3><p>Play 是 Playbook 的基本单元，用于定义在一组主机上执行的一系列任务。一个 Playbook 可以包含多个 Play，每个 Play 在不同的主机或组上执行不同的任务。</p><p>关键字：</p><ul><li>hosts: 指定要在哪些主机或主机组上执行 Play。</li><li>tasks: 包含一系列任务，这些任务会按顺序执行。</li><li>vars: 定义在 Play 中使用的变量。</li><li>roles: 指定要应用的角色。</li><li>gather_facts: 控制是否收集主机的事实信息（默认 true）。</li><li>become: 是否使用 sudo 或其他特权提升执行任务。</li></ul><h3 id="2-Tasks"><a href="#2-Tasks" class="headerlink" title="2. Tasks"></a>2. Tasks</h3><p>Tasks 是 Play 中的核心部分，定义了要执行的具体操作。每个 Task 通常使用一个 Ansible 模块，并可包含条件、循环、错误处理等。</p><p>关键字：</p><ul><li>name: 任务的描述性名称（可选，但推荐使用）。</li><li>   action 或模块名称: 具体执行的操作，如 apt、yum、copy 等。</li><li>   when: 定义条件，满足时才会执行任务。</li><li>   with_items: 用于循环执行任务。</li><li>   register: 保存任务的结果到变量。</li><li>   ignore_errors: 忽略任务执行失败（设为 yes 时）。</li></ul><h3 id="3-Variables"><a href="#3-Variables" class="headerlink" title="3. Variables"></a>3. Variables</h3><p>Variables 是 Playbook 中的动态值，用于提高复用性和灵活性。可以在多个地方定义变量，如 vars、group_vars、host_vars、inventory 文件，或通过命令行传递。</p><p>关键字：<br>-vars: 在 Play 或 Task 中定义变量。<br>-vars_files: 引入外部变量文件。<br>-vars_prompt: 运行时提示用户输入变量值。</p><h3 id="4-Handlers"><a href="#4-Handlers" class="headerlink" title="4. Handlers"></a>4. Handlers</h3><p>Handlers 是一种特殊类型的 Task，只会在被触发时执行。通常用于在配置更改后执行动作，如重启服务。比如我要等服务重启完检查端口监听，就可以用handler</p><p>关键字：<br>-name: Handler 的名称。<br>-notify: 在普通 Task 中调用 notify 触发对应的 Handler。</p><h3 id="5-Roles"><a href="#5-Roles" class="headerlink" title="5. Roles"></a>5. Roles</h3><p>Roles 是 Playbook 中组织和复用任务、变量、文件、模板等的一种方式。Roles 使得 Playbook 更加模块化和可维护。举个例子，我现在要在服务器上部署各种各样的组件，webserver、mysql、redis、ng 等等，我们就可以用这个不同的 roles 来管理，我们可以在创建四个文件夹，分别对应起名 webserver、mysql、redis、ng，然后在这些文件夹里面添加服务部署或者更新需要的东西。</p><p>角色的目录结构：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">my_role/</span><br><span class="line">├── tasks/</span><br><span class="line">│   └── main.yml</span><br><span class="line">├── handlers/</span><br><span class="line">│   └── main.yml</span><br><span class="line">├── templates/</span><br><span class="line">├── files/</span><br><span class="line">├── vars/</span><br><span class="line">│   └── main.yml</span><br><span class="line">├── defaults/</span><br><span class="line">│   └── main.yml</span><br><span class="line">└── meta/</span><br><span class="line">    └── main.yml</span><br></pre></td></tr></table></figure><p>roles内各自目录含义：</p><ul><li>files用来存放copy模块或script模块调用的文件</li><li>templates用来存放jinjia2模板，template模块会自动在此目录中寻找jinjia2模板文件</li><li>tasks此目录应当包含一个main.yml文件，用于定义此角色的任务列表，此文件可以使用include包含其它的位于此目录的task文件</li><li>handlers此目录应当包含一个main.yml文件，用于定义此角色中触发条件时执行的动作</li><li>vars此目录应当包含一个main.yml文件，用于定义此角色用到的变量</li><li>defailts此目录应当包含一个main.yml文件，用于为当前角色设定默认变量</li><li>meta此目录应当包含一个main.yml文件，用于定义此角色的特殊设及其依赖关系</li></ul><h3 id="6-Includes-and-Imports"><a href="#6-Includes-and-Imports" class="headerlink" title="6. Includes and Imports"></a>6. Includes and Imports</h3><p>Includes 和 Imports 用于在 Playbook 中包含其他任务、变量、文件等。import_tasks 和 include_tasks 的区别在于，import_tasks 在解析 Playbook 时执行，而 include_tasks 在运行时执行。</p><h3 id="7-Templates"><a href="#7-Templates" class="headerlink" title="7. Templates"></a>7. Templates</h3><p>Templates 是使用 Jinja2 模板引擎的文件，用于动态生成配置文件或其他文件。模板通常存放在 templates&#x2F; 目录下，并通过 template 模块应用到目标主机</p><h3 id="8-Tags"><a href="#8-Tags" class="headerlink" title="8. Tags"></a>8. Tags</h3><p>标签是用于对 play 进行标注，当你写了一个很长的playbook，其中有很多的任务，这并没有什么问题，不过在实际使用这个剧本时，你可能只是想要执行其中的一部分任务而已，或者，你只想要执行其中一类任务而已，而并非想要执行整个剧本中的全部任务，这时，我们可以借助tags模块为任务进行打标签操作，任务存在标签后，我们可以在执行playbook时利用标签，指定执行哪些任务，或者不执行哪些任务</p><p>比如说在实际线上环境中，我们有更新二进制包的操作，那么我们可以在更新二进制的相关 task 中添加名为bin 的 tags，有更新配置文件的操作，那么可以在相关的 tasks 中添加 conf 的 tags</p><h3 id="完整示例"><a href="#完整示例" class="headerlink" title="完整示例"></a>完整示例</h3><p>我们通过一个安装 nginx 的操作来完整演示一下:</p><p>设置项目目录结构:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── ansible.cfg</span><br><span class="line">├── inventory</span><br><span class="line">├── playbook.yml</span><br><span class="line">└── roles</span><br><span class="line">    └── nginx</span><br><span class="line">        ├── tasks</span><br><span class="line">        │   ├── main.yml</span><br><span class="line">        │   └── install.yml</span><br><span class="line">        ├── handlers</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        ├── templates</span><br><span class="line">        │   └── nginx.conf.j2</span><br><span class="line">        ├── files</span><br><span class="line">        ├── vars</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        └── defaults</span><br><span class="line">            └── main.yml</span><br></pre></td></tr></table></figure><p>inventory配置文件</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[webservers]</span></span><br><span class="line">192.168.1.101 <span class="attr">ansible_ssh_user</span>=your_user ansible_ssh_pass=your_password ansible_host=<span class="number">203.0</span>.<span class="number">113.1</span></span><br></pre></td></tr></table></figure><p>playbook.yml:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Update</span> <span class="string">and</span> <span class="string">Install</span> <span class="string">Nginx</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">webservers</span>  <span class="comment">#引用组</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">yes</span>        <span class="comment">#开启 sudo</span></span><br><span class="line">  <span class="attr">roles:</span>             </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">nginx</span>    <span class="comment">#角色是nginx，对应到  roles/nginx 目录</span></span><br><span class="line">      <span class="attr">tags:</span>          <span class="comment">#两个 tags</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">bin</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">conf</span></span><br></pre></td></tr></table></figure><p>任务文件 roles&#x2F;nginx&#x2F;tasks&#x2F;main.yml:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># 包含其他任务文件, 这里直接用 install.yml里面的文件内容肯定也是没问题的，但是我们可以通过这样的方式更好的进行管理</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">include_tasks:</span> <span class="string">install.yml</span></span><br></pre></td></tr></table></figure><p>安装任务 roles&#x2F;nginx&#x2F;tasks&#x2F;install.yml:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># 更新安装 Nginx</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Update</span> <span class="string">apt</span> <span class="string">cache</span> <span class="string">and</span> <span class="string">install</span> <span class="string">Nginx</span></span><br><span class="line">  <span class="attr">apt:</span>                  <span class="comment">#安装nginx 相关包, 不同平台不太一样，比如 centos 可以使用 package</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">latest</span></span><br><span class="line">    <span class="attr">update_cache:</span> <span class="literal">yes</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">bin</span>               <span class="comment">#这里添加了 bin 的 tag</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署 Nginx 配置文件</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Deploy</span> <span class="string">Nginx</span> <span class="string">configuration</span> <span class="string">from</span> <span class="string">template</span></span><br><span class="line">  <span class="attr">template:</span>              <span class="comment">#这里是更新 nginx 配置文件</span></span><br><span class="line">    <span class="attr">src:</span> <span class="string">nginx.conf.j2</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">/etc/nginx/nginx.conf</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="string">&#x27;0644&#x27;</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="string">Restart</span> <span class="string">Nginx</span>   <span class="comment">#这里配合handler 使用，handlers 里面会有一个名称为 “Restart Nginx”的操作</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">conf</span>                <span class="comment">#这里添加了 conf 的 tag</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 Nginx 是否监听正确端口</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Check</span> <span class="string">Nginx</span> <span class="string">is</span> <span class="string">listening</span> <span class="string">on</span> <span class="string">port</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">ss</span> <span class="string">-tuln</span> <span class="string">|</span> <span class="string">grep</span> <span class="string">:80</span>    <span class="comment">#通过 command 模块，ss 命令监听 80 端口是否启动</span></span><br><span class="line">  <span class="attr">register:</span> <span class="string">result</span></span><br><span class="line">  <span class="attr">ignore_errors:</span> <span class="literal">yes</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">Nginx</span> <span class="string">listening</span> <span class="string">port</span> <span class="string">check</span> <span class="string">result</span></span><br><span class="line">  <span class="attr">debug:</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; result.stdout &#125;&#125;</span>&quot;</span></span><br><span class="line">  <span class="attr">when:</span> <span class="string">result.rc</span> <span class="string">==</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><p>处理程序 roles&#x2F;nginx&#x2F;handlers&#x2F;main.yml：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># 当配置文件变更时，重启 Nginx, 和上面的 notify 是对应的</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Restart</span> <span class="string">Nginx</span></span><br><span class="line">  <span class="attr">service:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">restarted</span></span><br></pre></td></tr></table></figure><p>模板文件 roles&#x2F;nginx&#x2F;templates&#x2F;nginx.conf.j2:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen &#123;&#123; nginx_port &#125;&#125;;</span><br><span class="line">    server_name localhost;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page 404 /404.html;</span><br><span class="line">        location = /40x.html &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page 500 502 503 504 /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>默认变量 roles&#x2F;nginx&#x2F;defaults&#x2F;main.yml:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">nginx_port:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>当我们更新安装时,可以通过(在正式执行前，可以在后面加-C -D 做测试使用):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbook.yml </span><br></pre></td></tr></table></figure><p>后续有二进制更新时，可以通过:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbook.yml -t bin</span><br></pre></td></tr></table></figure><p>后续有配置文件更新时，可以通过:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbook.yml -t conf</span><br></pre></td></tr></table></figure><h2 id="逻辑控制语句"><a href="#逻辑控制语句" class="headerlink" title="逻辑控制语句"></a>逻辑控制语句</h2><h3 id="条件语句when"><a href="#条件语句when" class="headerlink" title="条件语句when"></a>条件语句when</h3><p>when条件支持多种判断类型，主要用于根据某些条件决定是否执行某个任务。这些判断类型通常基于Python的语法，因为Ansible的任务是用Python编写的</p><p>主要支持的判断类型:</p><ul><li>比较运算符：&#x3D;&#x3D;, !&#x3D;, &gt;, &lt;, &gt;&#x3D;, &lt;&#x3D; 用于比较两个值。</li><li>字符串方法：.startswith(), .endswith(), .find(), .contains() 等字符串方法可以用来检查字符串的特性。</li><li>逻辑运算符：and, or, not 用于组合多个条件。</li><li>Jinja2模板表达式：由于Ansible使用Jinja2作为模板引擎，因此你也可以在when条件中使用Jinja2的表达式和过滤器。</li><li>Ansible事实（facts）和变量：你可以使用Ansible收集的主机事实（facts）和定义的变量来进行条件判断。</li><li>函数和内置方法：Python的内置函数和方法也可以在when条件中使用，比如isinstance(), len(), 等等。</li><li>正则表达式：使用Python的正则表达式模块（如re）进行更复杂的字符串匹配。</li></ul><p>其中facts涉及到的判断条件非常多，可以通过如下形式获取</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">show</span> <span class="string">ansible</span> <span class="string">facts</span></span><br><span class="line">      <span class="attr">debug:</span></span><br><span class="line">        <span class="attr">var:</span> <span class="string">ansible_facts</span></span><br></pre></td></tr></table></figure><p>执行以上yml文件之后，会输出一个json串，我们就可以获取到所有的fact信息了.</p><p>示例：假如我们想在ip为 192.168.0.102 的机器上创建文件</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">when测试练习</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">webservers</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">文件测试创建</span></span><br><span class="line">      <span class="attr">file:</span> </span><br><span class="line">        <span class="attr">path:</span> <span class="string">/tmp/when.txt</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">touch</span></span><br><span class="line">      <span class="attr">when:</span> <span class="string">&quot;&#x27;192.168.0.102&#x27; in ansible_all_ipv4_addresses&quot;</span></span><br></pre></td></tr></table></figure><h3 id="循环语句loop"><a href="#循环语句loop" class="headerlink" title="循环语句loop"></a>循环语句loop</h3><p>用于在任务中循环执行操作</p><p>示例:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">multiple</span> <span class="string">packages</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">webservers</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">yes</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">packages</span></span><br><span class="line">      <span class="attr">apt:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; item &#125;&#125;</span>&quot;</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">      <span class="attr">loop:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">nginx</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">git</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">curl</span></span><br></pre></td></tr></table></figure><p>上面的示例就是循环装包</p><h3 id="块语句block"><a href="#块语句block" class="headerlink" title="块语句block"></a>块语句block</h3><p>在 Ansible 中，block 关键字允许你将多个任务组合成一个逻辑块，并对这个块应用一些条件或错误处理逻辑。这是 Ansible 2.5 版本及以后引入的一个功能，它提供了更高级的任务组织方式。简单来说，block任务块就是一组逻辑的tasks。使用block可以将多个任务合并为一个组。</p><p>playbook会定义三种块，三种块的作用分别如下:</p><ul><li>block: block里的tasks,如果运行正确,则不会运行rescue；</li><li>rescue：block里的tasks,如果运行失败,才会运行rescue里的tasks</li><li>always：block和rescue里的tasks无论是否运行成功，都会运行always里的tasks</li></ul>]]></content>
    
    
    <summary type="html">本文将对 ansible 工具的具体使用做一个详细的介绍</summary>
    
    
    
    <category term="运维工具" scheme="http://baixiaozhou.github.io/categories/%E8%BF%90%E7%BB%B4%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="ansible" scheme="http://baixiaozhou.github.io/tags/ansible/"/>
    
    <category term="运维工具" scheme="http://baixiaozhou.github.io/tags/%E8%BF%90%E7%BB%B4%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>线上故障排查方法和工具介绍</title>
    <link href="http://baixiaozhou.github.io/p/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/"/>
    <id>http://baixiaozhou.github.io/p/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/</id>
    <published>2024-08-15T03:12:21.000Z</published>
    <updated>2025-04-25T02:33:09.937Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><div class="tag-plugin quot"><p class="content" type="text"><span class="empty"></span><span class="text">参考文档</span><span class="empty"></span></p></div><p><a href="https://www.linuxjournal.com/article/9001">Examining Load Average</a><br><a href="https://community.tenable.com/s/article/What-is-CPU-Load-Average">What-is-CPU-Load-Average</a><br><a href="www.brendangregg.com">Brendan Gregg个人网站</a></p><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>在很多文章中，每当提到去解决线上问题的时候，大部分的处理方式就是登录环境，哐哐各种敲命令。操作本身没什么问题，但是对于很多人而言，我觉得这种做法其实是本末倒置的，过于在乎去快速抓住重点问题，而忽略了从全局去看问题。那么如果最开始不去操作各种命令，那应该干什么呢？</p><p><em><strong>看监控！！！！</strong></em></p><p>首先不要觉得这个是废话，对于很多场景来说，业务规模是不断变化的，有的时候并发超过了极限的性能，那么这种情况下都没有必要去后台进行各种查询。举个简单的例子，假如说某套业务系统，本身只能支持 500 并发，现在实际上的量到了 2000，导致线上各种内存、CPU、负载的告警，这种情况下还有必要去后台敲<code>top</code>、<code>free</code>吗？答案当然是否定的，这种情况下，就需要考虑对业务系统进行快速的扩容等。</p><p>看监控的意义在于尽可能的找到更多的性能瓶颈或者异常的点，从全局出发，对系统当前存在的问题和异常点有全面的了解。</p><p>监控系统多种多样，从较早的 zabbix 到现在比较流行的prometheus+grafana（举两个常用的例子），对于系统业务都有比较完善的监控，可以帮助我们更加具体的了解到系统运行全貌。如果你对这些都不喜欢，那么你自己写一个监控系统也没什么问题。</p><p>当我们看完监控之后（假设你真的看了），接下来进入实际操作环节，我会从这些指标的详细含义出发，然后尽可能地将各种处理方式分享给大家。</p><h2 id="Linux性能谱图"><a href="#Linux性能谱图" class="headerlink" title="Linux性能谱图"></a>Linux性能谱图</h2><p>在分析问题前，我们首先需要明确 Linux 有哪些性能分析工具，我们先上一下LINUX 性能专家 Brendan Gregg 总结的图（大家如果对性能分析等感兴趣的话，可以认真看下这位大佬的个人网站）:</p><div class="tag-plugin image"><div class="image-bg"><img src="https://www.brendangregg.com/Perf/linux_observability_tools.png" alt="Linux Performance Observability Tool" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">Linux Performance Observability Tool</span></div></div><p>上面这张图是引用大佬文章的图，原文链接在这里: <a href="https://www.brendangregg.com/linuxperf.html">https://www.brendangregg.com/linuxperf.html</a></p><h2 id="CPU使用率飙升"><a href="#CPU使用率飙升" class="headerlink" title="CPU使用率飙升"></a>CPU使用率飙升</h2><h3 id="如何让CPU使用率飙升"><a href="#如何让CPU使用率飙升" class="headerlink" title="如何让CPU使用率飙升"></a>如何让CPU使用率飙升</h3><p>这个问题其实很简单，只要有计算任务一直存在，让 CPU 一直处于繁忙之中，那么 CPU 必然飙升。我们可以通过一系列的工具去模拟这个情况。</p><p><a href="https://github.com/baixiaozhou/SysStress">github SysStress</a> 这是我自己用 golang 写的压测工具(还在开发中，可以点个 star 让我更有动力😂)</p><p>使用方法:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sysstress cpu --cpu-number 10 --duration 10m</span><br></pre></td></tr></table></figure><p>这个就是模拟占用 10 核心的 CPU 并持续 10min，当然大家也可以用其他的压测工具，比如<code>stress-ng</code></p><h3 id="如何判断和发现CPU使用率飙升"><a href="#如何判断和发现CPU使用率飙升" class="headerlink" title="如何判断和发现CPU使用率飙升"></a>如何判断和发现CPU使用率飙升</h3><p>首先我们先看一下，跟 CPU 使用率相关的有哪些指标。我们通过 <code>top</code> 命令就可以看到具体的信息</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/top.png" alt="top" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">top</span></div></div><!-- ![top](../images/top.png) --><p>这些输出中有一行是 <code>%Cpu(s)</code>, 这行展示了 CPU 的整体使用情况，是一个百分比的形式，我们详细阐述下这几个字段的含义</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">us, user    : time running un-niced user processes   未降低优先级的用户进程所占用的时间</span><br><span class="line">sy, system  : time running kernel processes          内核进程所占用的时间</span><br><span class="line">ni, nice    : time running niced user processes      降低优先级的用户进程所占用的时间</span><br><span class="line">id, idle    : time spent in the kernel idle handler  空闲的时间</span><br><span class="line">wa, IO-wait : time waiting for I/O completion        等待 I/O 操作完成所花费的时间</span><br><span class="line">hi : time spent servicing hardware interrupts        处理硬件中断所花费的时间</span><br><span class="line">si : time spent servicing software interrupts        处理软件中断所花费的时间</span><br><span class="line">st : time stolen from this vm by the hypervisor      被虚拟机管理程序从此虚拟机中窃取的时间</span><br></pre></td></tr></table></figure><p>在这些指标中，一般关注的比较多的就是 us、sy、id、wa（其他几个指标很高的情况我个人目前基本上没有遇到过）</p><p>上述指标反映了系统整体的 CPU 情况。而程序在操作系统中实际上是以一个个的进程存在的，那我们如何确定到占用 CPU 高的进程呢？让我们的目光从 top 的头部信息往下移动，下面就展示了详细的进程信息</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/top-process.png" data-fancybox="true"/></div></div><!-- !cess](../imagescess.png) --><p>这些程序默认是按照 CPU 的使用率从高到底进行排序的，当然你也可以通过在<code>top</code>的时候输入<code>P</code>进行排序，这样我们就可以看到系统中消耗 CPU 资源的详细进程信息</p><p>上面是我通过 <code>./sysstress cpu --cpu-number 10 --duration 10m</code> 压测程序跑出来的，可以看到这里的 sysstress 程序占用了 1002 的 %CPU，也就是说基本上是 10 个核心，那我们跑一个更高的，将<code>--cpu-number</code>加到 60 看看发生了什么</p><!-- ![stress-cpu](../images/stress-cpu.png) --><div class="tag-plugin image"><div class="image-bg"><img src="/images/stress-cpu.png" alt="stress-cpu" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">stress-cpu</span></div></div><p>我们可以看到这次%CPU打到了 6000，那很多人就好奇我日常的程序跑到多高算高呢？</p><p>这里我们需要明确一点，现在的服务器绝大部分都是多核心 CPU（1C2G这种自己用来玩的忽略），CPU 的核心数决定了我们程序在同一时间能够执行多少个线程，也就是说，这个高不高是相对于机器配置而言的。如果你的机器只有 16C，那么单个进程占用的 %CPU 到 1000，那么其实已经算是比较高了。如果是 256C 的CPU（土豪级配置），那么单个进程占用的 %CPU 到 6000，对于系统的稳定性影响就没有那么大了。</p><p>上述我们说的情况是进程占用 CPU 对整个系统的影响，那么进程占用的 CPU 对系统的影响不大就代表这个程序一定没有问题吗？答案显然是未必的。</p><p>我们还是要回归到业务本身，如果进程的 CPU 占用在业务变动不大的情况下，发生了异常波动，或者正常情况下业务不会消耗这么高的 CPU，那么我们就需要继续排查了。</p><h3 id="如何确定CPU飙升的根源"><a href="#如何确定CPU飙升的根源" class="headerlink" title="如何确定CPU飙升的根源"></a>如何确定CPU飙升的根源</h3><p>这个问题的 核心是 CPU 上在运行什么东西。 多核心CPU 下，每个核心都可以执行不同的程序，我们如何确定一个进程中那些方法在消耗 CPU 呢？从而引申下面详细的问题:</p><ol><li>程序的调用栈是什么样的？</li><li>调用栈信息中哪些是需要关注的，那些是可以忽略的？</li><li>热点函数是什么？</li></ol><p>老话说得好，”工欲善其事，必先利其器”, 我们需要这些东西，就必须了解到什么样的工具可以拿到上面我提到的一些信息。接下来我将通过常用的后端语言：<code>golang</code> 和 <code>java</code> 为例构造一些高 CPU 的程序来进行展示。</p><h4 id="perf命令"><a href="#perf命令" class="headerlink" title="perf命令"></a>perf命令</h4><p><strong>perf是一款Linux性能分析工具。Linux性能计数器是一个新的基于内核的子系统，它提供一个性能分析框架，比如硬件（CPU、PMU(Performance Monitoring Unit)）功能和软件(软件计数器、tracepoint)功能。</strong></p><p>安装:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install perf   #Centos</span><br></pre></td></tr></table></figure><p>安装完成后，我们可以首先看下 <code>perf</code>的用法，这里不展开具体用法，只列出我平常使用的几个命令:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">top        System profiling tool.               #对系统性能进行实时分析。</span><br><span class="line">record     Run a command and record its profile into perf.data     #收集采样信息</span><br><span class="line">report     Read perf.data (created by perf record) and display the profile  #分析采样信息，和record配合使用</span><br></pre></td></tr></table></figure><p>record 和 report 的使用更多在于 dump 当前环境的信息用于后续分析，如果在自己环境上测试，可以用 top 进行一些简单的实时分析（类似于 top 命令）。</p><p>还是用之前的压测工具，我们模拟一个 10 核心的 10min 的压测场景</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ./sysstress cpu --cpu-number 10 --duration 10m &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>执行这个语句，让压测程序在后台执行，然后我们通过<code>perf top</code>查看具体的情况（可以通过-p 指定 pid）</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/perftop.png" alt="perf top," data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">perf top,</span></div></div><!-- ![perf top](../images/perftop.png) --><p>从截图的信息中我们可以看到占用资源最多的一些方法，包括 sysstress 进程的各种方法(从图片中基本上就可以确定高消耗的方法在哪里)以及底层的 <code>__vdso_clock_gettime</code>, 那再结合压测工具的代码分析下:</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">burnCpu</span><span class="params">(wg *sync.WaitGroup, start time.Time, durSec <span class="type">int64</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">defer</span> wg.Done()</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">_ = <span class="number">1</span> * <span class="number">1</span></span><br><span class="line">now := time.Now()</span><br><span class="line"><span class="keyword">if</span> now.Sub(start) &gt; time.Duration(durSec)*time.Second &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是方法的核心，其实就是做无意义的计算，外加时间的判断，超过 duration 就结束。这样和上面的 perf top 信息就能对应起来。</p><p>然后我们用 java 写一个同样的程序，再看看 <code>perf top</code>的情况:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/javaperftop.png" alt="perf top," data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">perf top,</span></div></div><!-- ![perf top](../images/javaperftop.png) --><p>从这一大段显示来看，是不是看的一脸懵逼，很难发现到底是什么程序在占用CPU 资源。大家可以看一下源程序:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.time.LocalDateTime;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">                        Math.sin(Math.random());</span><br><span class="line">                        <span class="type">LocalDateTime</span> <span class="variable">currentTime</span> <span class="operator">=</span> LocalDateTime.now();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的程序也是非常简单，启动 10 个线程，做一个无意义的数学运算，然后获取当前时间。从这段代码中是不是很难和上面<code>perf top</code>的显示关联起来？ 原因也非常简单， 像Java 这种通过 JVM 来运行的应用程序，运行堆栈用的都是 JVM 内置的函数和堆栈管理。所以，从系统层面只能看到 JVM 的函数堆栈，而不能直接得到 Java 应用程序的堆栈。那我们好能通过 perf 去看到 java 相关的堆栈吗？答案是可以的。</p><p>可以借助 <a href="https://github.com/jvm-profiling-tools/perf-map-agent">perf-map-agent</a> 这样的开源工具，去生成和<code>perf</code> 工具一起使用的方法映射，但是需要做额外的一些配置。这里的方法大家可以自己探究，为什么不详细的讲这个呢，原因也简单，排查问题的工具多种多样，没必要在一棵树上吊死。</p><h4 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h4><p>既然 perf top 去查看 JAVA 的调用栈不太方便，我们就直接上 java 提供的 jstack 工具去分析。</p><ul><li>jstack -l pid &gt; xxx.txt 需要注意的是，linux系统中往往会用不同的用户去执行不同的程序，此时可能需要通过sudu -u xxx jstack的形式</li><li>kill -3， jstack 用不了的情况下可以使用 kill -3 pid 的形式，堆栈默认会输出在系统日志中（根据不同的配置，信息也可能输出在其他地方，比如这个程序的日志中）。</li></ul><p>具体的操作步骤:</p><ol><li><code>top -Hp $pid</code> 找到占用 CPU 的具体线程</li><li><code>jstack -l $pid &gt; /tmp/$pid.jstack</code> 或者 <code>kill -3 $pid</code>将 java 进程的堆栈情况输出的日志中，然后根据 <code>top -Hp</code> 看到的线程信息在输出的堆栈日志中进行查找（<code>top -Hp</code> 输出的是 10 进制的 id，<code>jstack</code> 输出的是 16 进制的，在查找时注意进制转换）</li></ol><p>我们看下上面 java 程序的堆栈的信息:</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2024</span><span class="number">-08</span><span class="number">-16</span> <span class="number">15</span>:<span class="number">15</span>:<span class="number">40</span></span><br><span class="line">Full thread <span class="built_in">dump</span> Java HotSpot(TM) <span class="number">64</span>-Bit Server VM (<span class="number">25.221</span>-b11 mixed mode):</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Attach Listener&quot;</span> #<span class="number">35</span> daemon prio=<span class="number">9</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f52b4001000</span> nid=<span class="number">0x71f4</span> waiting on condition [<span class="number">0x0000000000000000</span>]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;DestroyJavaVM&quot;</span> #<span class="number">34</span> prio=<span class="number">5</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e0009800</span> nid=<span class="number">0x1693</span> waiting on condition [<span class="number">0x0000000000000000</span>]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Thread-1&quot;</span> #<span class="number">25</span> prio=<span class="number">5</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e015a800</span> nid=<span class="number">0x16d9</span> runnable [<span class="number">0x00007f52f64e3000</span>]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line">at sun.misc.Unsafe.getObjectVolatile(Native Method)</span><br><span class="line">at java.util.concurrent.ConcurrentHashMap.tabAt(ConcurrentHashMap.java:<span class="number">755</span>)</span><br><span class="line">at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:<span class="number">938</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.zone.ZoneRulesProvider.getProvider(ZoneRulesProvider.java:<span class="number">267</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.zone.ZoneRulesProvider.getRules(ZoneRulesProvider.java:<span class="number">227</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneRegion.ofId(ZoneRegion.java:<span class="number">120</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneId.of(ZoneId.java:<span class="number">411</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneId.of(ZoneId.java:<span class="number">359</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneId.of(ZoneId.java:<span class="number">315</span>)</span><br><span class="line">at java.util.TimeZone.toZoneId(TimeZone.java:<span class="number">556</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneId.systemDefault(ZoneId.java:<span class="number">274</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.Clock.systemDefaultZone(Clock.java:<span class="number">178</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.LocalDateTime.now(LocalDateTime.java:<span class="number">180</span>)</span><br><span class="line">at Main$<span class="number">1.</span>run(Main.java:<span class="number">12</span>)</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Thread-0&quot;</span> #<span class="number">24</span> prio=<span class="number">5</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e0159000</span> nid=<span class="number">0x16d8</span> runnable [<span class="number">0x00007f52f65e4000</span>]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line">at sun.misc.Unsafe.getObjectVolatile(Native Method)</span><br><span class="line">at java.util.concurrent.ConcurrentHashMap.tabAt(ConcurrentHashMap.java:<span class="number">755</span>)</span><br><span class="line">at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:<span class="number">938</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.zone.ZoneRulesProvider.getProvider(ZoneRulesProvider.java:<span class="number">267</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.zone.ZoneRulesProvider.getRules(ZoneRulesProvider.java:<span class="number">227</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneRegion.ofId(ZoneRegion.java:<span class="number">120</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneId.of(ZoneId.java:<span class="number">411</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneId.of(ZoneId.java:<span class="number">359</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneId.of(ZoneId.java:<span class="number">315</span>)</span><br><span class="line">at java.util.TimeZone.toZoneId(TimeZone.java:<span class="number">556</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.ZoneId.systemDefault(ZoneId.java:<span class="number">274</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.Clock.systemDefaultZone(Clock.java:<span class="number">178</span>)</span><br><span class="line">at java.<span class="built_in">time</span>.LocalDateTime.now(LocalDateTime.java:<span class="number">180</span>)</span><br><span class="line">at Main$<span class="number">1.</span>run(Main.java:<span class="number">12</span>)</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"> <span class="comment">--- 10 个 thread</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Service Thread&quot;</span> #<span class="number">23</span> daemon prio=<span class="number">9</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e0143800</span> nid=<span class="number">0x16d6</span> runnable [<span class="number">0x0000000000000000</span>]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;C2 CompilerThread1&quot;</span> #<span class="number">6</span> daemon prio=<span class="number">9</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e010e000</span> nid=<span class="number">0x16c5</span> waiting on condition [<span class="number">0x0000000000000000</span>]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"> <span class="comment">--- 一大堆 C2 CompilerThread</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;C2 CompilerThread0&quot;</span> #<span class="number">5</span> daemon prio=<span class="number">9</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e010b000</span> nid=<span class="number">0x16c4</span> waiting on condition [<span class="number">0x0000000000000000</span>]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Signal Dispatcher&quot;</span> #<span class="number">4</span> daemon prio=<span class="number">9</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e0109800</span> nid=<span class="number">0x16c3</span> runnable [<span class="number">0x0000000000000000</span>]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Finalizer&quot;</span> #<span class="number">3</span> daemon prio=<span class="number">8</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e00d8800</span> nid=<span class="number">0x16c2</span> <span class="keyword">in</span> Object.wait() [<span class="number">0x00007f52f7bfa000</span>]</span><br><span class="line">   java.lang.Thread.State: WAITING (on object monitor)</span><br><span class="line">at java.lang.Object.wait(Native Method)</span><br><span class="line">- waiting on &lt;<span class="number">0x000000008021a5e8</span>&gt; (a java.lang.ref.ReferenceQueue$Lock)</span><br><span class="line">at java.lang.ref.ReferenceQueue.<span class="built_in">remove</span>(ReferenceQueue.java:<span class="number">144</span>)</span><br><span class="line">- locked &lt;<span class="number">0x000000008021a5e8</span>&gt; (a java.lang.ref.ReferenceQueue$Lock)</span><br><span class="line">at java.lang.ref.ReferenceQueue.<span class="built_in">remove</span>(ReferenceQueue.java:<span class="number">165</span>)</span><br><span class="line">at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:<span class="number">216</span>)</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Reference Handler&quot;</span> #<span class="number">2</span> daemon prio=<span class="number">10</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e00d3800</span> nid=<span class="number">0x16c1</span> <span class="keyword">in</span> Object.wait() [<span class="number">0x00007f52f7cfb000</span>]</span><br><span class="line">   java.lang.Thread.State: WAITING (on object monitor)</span><br><span class="line">at java.lang.Object.wait(Native Method)</span><br><span class="line">- waiting on &lt;<span class="number">0x0000000080218d38</span>&gt; (a java.lang.ref.Reference$Lock)</span><br><span class="line">at java.lang.Object.wait(Object.java:<span class="number">502</span>)</span><br><span class="line">at java.lang.ref.Reference.tryHandlePending(Reference.java:<span class="number">191</span>)</span><br><span class="line">- locked &lt;<span class="number">0x0000000080218d38</span>&gt; (a java.lang.ref.Reference$Lock)</span><br><span class="line">at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:<span class="number">153</span>)</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">- None</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;VM Thread&quot;</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e00ca000</span> nid=<span class="number">0x16c0</span> runnable</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;GC task thread#0 (ParallelGC)&quot;</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e001f000</span> nid=<span class="number">0x1694</span> runnable</span><br><span class="line"></span><br><span class="line"><span class="comment">--- 一大堆 GC task thread</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;VM Periodic Task Thread&quot;</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f53e0146000</span> nid=<span class="number">0x16d7</span> waiting on condition</span><br><span class="line"></span><br><span class="line">JNI global references: <span class="number">202</span></span><br></pre></td></tr></table></figure><p>我们通过 top -Hp 的信息就可以快速定位到 Thread-[0-9] 这几个线程，而每个线程的调用栈都是 <code>java.time.LocalDateTime.now</code>, 也说明了这个方法在不停消耗 CPU。（但是 jstack 只能捕获短时间或者瞬时的堆栈信息，没法处理长时间的，所以我们在获取时可以多打印几次或者使用其他方法）</p><p>至于 jstack 的详细用法，请参考我的另一篇博客：<a href="https://baixiaozhou.github.io/2024/08/13/JAVA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/">java问题定位</a></p><p>除此之外，还有非常多的分析工具，pstack\gstack\strace\gdb等等，大家可以自行探索使用</p><h4 id="火焰图"><a href="#火焰图" class="headerlink" title="火焰图"></a>火焰图</h4><p>上面我们介绍了很多操作的命令和方法，那么有没有一种比较直观的方式能够直接看到各种方法执行的耗时比重等情况呢？火焰图就是为了解决这种情况而生的。</p><p>火焰图的分类有很多，常用的包括:</p><ol><li>CPU 火焰图 (CPU Flame Graph)<ul><li>   描述：展示 CPU 在不同方法上的消耗情况，显示每个方法调用所占用的 CPU 时间。</li><li>   用途：用于分析 CPU 性能瓶颈，识别哪些方法消耗了最多的 CPU 资源。</li><li>   应用：Java、C++ 等多种编程语言的性能分析。</li></ul></li><li>内存火焰图 (Memory Flame Graph)<ul><li>描述：展示内存分配情况，显示每个方法调用分配的内存量。</li><li>用途：用于检测内存泄漏、过度内存分配问题，帮助优化内存使用。</li><li>应用：常用于分析内存密集型应用，如 Java 应用的堆内存分析。</li></ul></li><li>I&#x2F;O 火焰图 (I&#x2F;O Flame Graph)<ul><li>   描述：展示 I&#x2F;O 操作的耗时情况，显示不同方法的 I&#x2F;O 操作占用的时间。</li><li>   用途：用于分析应用程序的 I&#x2F;O 性能，识别慢速或频繁的 I&#x2F;O 操作。</li><li>   应用：数据库查询、文件系统操作、网络通信等场景的性能调优。</li></ul></li></ol><p>我们这里通过 <a href="https://github.com/async-profiler/async-profiler">async-profiler</a> 对文章上面的java压测程序进行抓取(这个工具只能抓 java 的, 对于 golang 程序，可以利用 golang 提供的 pprof)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -xzf async-profiler-3.0-linux-x64.tar.gz</span><br><span class="line">cd async-profiler-3.0-linux-x64/bin</span><br><span class="line">./asprof -d 60 pid -f /tmp/javastress.html</span><br></pre></td></tr></table></figure><p>我们用浏览器打开生成的 html 文件，可以看到如下的火焰图信息（可以在网页进行点击，查看更细节的方法）</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/javafire.png" alt="java 程序的火焰图," data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">java 程序的火焰图,</span></div></div><!-- ![java 程序的火焰图](../images/javafire.png) --><p>这样看起来就比 jstack这些信息更加直观一点。</p><h2 id="负载飙升"><a href="#负载飙升" class="headerlink" title="负载飙升"></a>负载飙升</h2><h3 id="负载的定义以及如何查看负载"><a href="#负载的定义以及如何查看负载" class="headerlink" title="负载的定义以及如何查看负载"></a>负载的定义以及如何查看负载</h3><p>我们先看下系统负载的官方描述:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System load averages is the average number of processes that are either in a runnable or uninterruptable state. A process in arunnable state is either using the CPU or waiting to use the CPU.  A process in uninterruptable state is waiting for some I/O access,eg waiting for disk.  The averages are taken over the three time intervals.  Load averages are not normalized for the number of CPUs ina  system,  so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time.</span><br></pre></td></tr></table></figure><p>系统负载平均值表示处于可运行或不可中断状态的进程的平均数量。处于可运行状态的进程要么正在使用 CPU，要么正在等待使用 CPU。处于不可中断状态的进程正在等待某些 I&#x2F;O 访问，例如等待磁盘。这里的核心概念就是 loadavg 这个数值体现了某些特定状态进程的数量。</p><p>那引申出两个问题:</p><ol><li>进程的状态有哪些？ 如何在 Linux 上查看进程状态</li><li>可运行和不可中断状态的进程具体含义是什么</li></ol><p>查看的方式，我们可以通过 ps 命令进行查看，比如通过<code>ps -auxf</code>, 我么可以看到有一列为 <code>STAT</code>,这列就代表该进程的状态:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/psauxf.png" alt="进程状态" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">进程状态</span></div></div><p>进程的状态和具体含义:</p><ul><li>D    uninterruptible sleep (usually IO)</li><li>R    running or runnable (on run queue)</li><li>S    interruptible sleep (waiting for an event to complete)</li><li>T    stopped by job control signal</li><li>t    stopped by debugger during the tracing</li><li>W    paging (not valid since the 2.6.xx kernel)</li><li>X    dead (should never be seen) </li><li>Z    defunct (“zombie”) process, terminated but not reaped by its parent</li></ul><p>这里我们看到处于不可中断的状态的进程和正在运行的进程分别为 <code>D</code> 和 <code>R</code>,换个说法，也就是说造成负载升高的原因也就是这两个状态的进程引起的。</p><p>（插个题外话，按照官方的说法，X 状态的进程应该是不应该被看到的， 但是之前在腾讯云做ES的时候，偶然间碰到了一次，当时还截了个图用做留念😂，但是没有捕获到具体的信息）</p><p>负载的指标可以通过 <code>top</code> 以及 <code>uptime</code> 指令获取</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">23:35:00 up 1 day, 46 min,  1 user,  load average: 49.16, 18.35, 7.87</span><br></pre></td></tr></table></figure><p>这里展示了 loadavg 的三个数值: 分别代表的含义是 1min、5min、15min 的系统平均负载</p><p>那我们如何判断系统的负载是高是低呢？</p><p>这里一般有个经验值，我们一般和 CPU 和核心数进行对比，一般负载在 CPU 核心的 70% 左右以及以下，对系统一般没什么影响，超过 70%，系统可能收到影响。但是这里还需要注意的一点就是，负载的比例在 70% 以下时不一定代表系统就没问题，举个简单的例子，如果一个系统上基本上没有业务在运行，那么负载基本上就在零点几左右，那么这种情况下，负载有升高不一定是合理的（后面举一个简单的例子）</p><h3 id="如何让系统负载飙高"><a href="#如何让系统负载飙高" class="headerlink" title="如何让系统负载飙高"></a>如何让系统负载飙高</h3><h4 id="纯计算任务对负载的影响"><a href="#纯计算任务对负载的影响" class="headerlink" title="纯计算任务对负载的影响"></a>纯计算任务对负载的影响</h4><p>既然说正在运行的进程会引起负载的变化，那么跑一些程序，让程序不停运行，那么自然而然就能构造出持续运行的进程了。<br>我这里找了三台机器(64C)，用我的压测工具先跑一些纯 CPU 的运算，然后观察下效果：</p><p>测试分为三组，测试前关闭不必要的服务和进程:</p><ol><li>10 并发 30min<ul><li><code>nohup ./sysstress cpu --cpu-number 10 --duration 30m &gt; /dev/null 2&gt;&amp;1</code></li></ul></li><li>30 并发 30min<ul><li><code>nohup ./sysstress cpu --cpu-number 30 --duration 30m &gt; /dev/null 2&gt;&amp;1</code></li></ul></li><li>60 并发 30min<ul><li><code>nohup ./sysstress cpu --cpu-number 60 --duration 30m &gt; /dev/null 2&gt;&amp;1</code></li></ul></li></ol><p>效果如下:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/load10.png" alt="10并发负载," data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">10并发负载,</span></div></div><div class="tag-plugin image"><div class="image-bg"><img src="/images/load30.png" alt="30并发负载," data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">30并发负载,</span></div></div><div class="tag-plugin image"><div class="image-bg"><img src="/images/load60.png" alt="60并发负载," data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">60并发负载,</span></div></div><!-- ![10并发负载](../images/load10.png)![30并发负载](../images/load30.png)![60并发负载](../images/load60.png) --><p>从上述测试过程中，我们可以发现，在纯运算这种场景下，并发的量基本上和负载是对应的。也就是说随着 CPU的使用量 上涨，负载也会不断变高。</p><h4 id="磁盘-IO-对负载的影响"><a href="#磁盘-IO-对负载的影响" class="headerlink" title="磁盘 IO 对负载的影响"></a>磁盘 IO 对负载的影响</h4><p>在刚才的例子中，我们看到了纯运算对负载的影响（R 进程的代表），然后在关于 D 进程的说明中，我们可以看到有一个比较明显的说明 <code>(usually IO)</code> ,即通常是 IO 引起的，那么接下来我们通过磁盘 IO 来测试一下</p><p>测试分为三组，测试前关闭不必要的服务和进程:</p><ol><li>10 并发 15min<ul><li><code>nohup ./sysstress io --operation read --filepath test.access.log -p 10 -d 15m &gt; /dev/null 2&gt;&amp;1 &amp;</code></li></ul></li><li>30 并发 15min<ul><li><code>nohup ./sysstress io --operation read --filepath test.access.log -p 30 -d 15m &gt; /dev/null 2&gt;&amp;1 &amp;</code></li></ul></li><li>60 并发 15min<ul><li><code>nohup ./sysstress io --operation read --filepath test.access.log -p 60 -d 15m &gt; /dev/null 2&gt;&amp;1 &amp;</code></li></ul></li></ol><p>效果如下:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/ioload10.png" alt="10并发负载" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">10并发负载</span></div></div><div class="tag-plugin image"><div class="image-bg"><img src="/images/ioload30.png" alt="30并发负载" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">30并发负载</span></div></div><div class="tag-plugin image"><div class="image-bg"><img src="/images/ioload60.png" alt="60并发负载" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">60并发负载</span></div></div><p>我们也顺便看一下，60 并发下 CPU 的情况:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/io60c.png" alt="60并发系统整体情况" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">60并发系统整体情况</span></div></div><p>这里我们可以观察到，系统的 CPU 基本上已经跑满了。us 和 sy 都占的比较多，但是这种读取非常有可能走到缓存中，我们想测绕过缓存，可以通过 DIRECT 的方式。</p><p>但是上面的例子其实也证明了一件事，IO 的操作也是会导致负载产生飙升。</p><p>那么问题来了，磁盘IO 和 CPU 操作都会导致系统负载飙升，那么负载飙升一定会是这两个原因吗？答案也是未必的，因为上述我们曾经提到过 D 状态的进程，到目前为止我们好像还没介绍过，那么我们来继续模拟，既然 D 状态的进程是 IO 操作引起的，普通的磁盘读写 IO 很难模拟，那我们就换个 IO 场景继续模拟 – 网络 IO。</p><h4 id="通过网络-IO-模拟-D-状态进程观察负载影响"><a href="#通过网络-IO-模拟-D-状态进程观察负载影响" class="headerlink" title="通过网络 IO 模拟 D 状态进程观察负载影响"></a>通过网络 IO 模拟 D 状态进程观察负载影响</h4><p>这里直接上一个模拟方法:</p><ul><li>A 机器开启 NFS Server</li><li>B 机器作为客户端进行挂载</li><li>断开网络</li><li>疯狂 df -h</li></ul><p>详细的操作步骤:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 安装 Centos</span><br><span class="line">sudo yum install nfs-utils</span><br><span class="line"></span><br><span class="line"># 服务端配置</span><br><span class="line">sudo mkdir -p /mnt/nfs_share</span><br><span class="line">sudo chown nobody:nogroup /mnt/nfs_share</span><br><span class="line">sudo chmod 755 /mnt/nfs_share</span><br><span class="line">## 打开 /etc/exports 配置，添加一行来定义共享目录及其权限。例如，将 /mnt/nfs_share 共享给网络 192.168.1.0/24，并提供读写权限：</span><br><span class="line">/mnt/nfs_share 192.168.1.0/24(rw,sync,no_subtree_check)</span><br><span class="line"></span><br><span class="line">## 启动 NFS</span><br><span class="line">sudo exportfs -a</span><br><span class="line">sudo systemctl restart nfs-kernel-server</span><br><span class="line">sudo systemctl enable nfs-kernel-server</span><br><span class="line"></span><br><span class="line"># 客户端配置</span><br><span class="line">sudo mkdir -p /mnt/nfs_client</span><br><span class="line">sudo mount -t nfs 192.168.1.100(server ip):/mnt/nfs_share /mnt/nfs_client</span><br><span class="line">## 验证</span><br><span class="line">df -h /mnt/nfs_client</span><br><span class="line"></span><br><span class="line"># 断网模拟(客户端)</span><br><span class="line">iptables -I INPUT -s serverip -j DROP</span><br><span class="line"></span><br><span class="line"># 持续(疯狂)执行：</span><br><span class="line">du -sh /mnt/nfs_client</span><br></pre></td></tr></table></figure><p>因为网络已经断掉，所以<code>du -sh /mnt/nfs_client</code>,而且这个程序没有自动退出或者报错，这样就导致程序无法顺利执行下去，继而阻塞住就变成了 D 状态的进程。</p><p>基于这种模拟方法大家可以自行测试下，笔者之前做过一个场景，将一个两核心的 CPU负载干到了 200 多，但是因为<strong>这种情况下更多是阻塞在网络中，所以此时的负载虽高，并不一定影响系统运行</strong>。</p><p>当然这只是其中一个例子，笔者曾经也因为见过 ping 操作阻塞导致的负载飙升，所以这种场景是多种多样的😂，大家有更多的例子也可以在下方留言，共同学习进步。</p><h3 id="负载飙升如何排查"><a href="#负载飙升如何排查" class="headerlink" title="负载飙升如何排查"></a>负载飙升如何排查</h3><p>基于上面的例子和场景模拟，我们其实应该已经有一套基本的排查方法了，下面这张图是我个人的一些总结(图还会不断完善)</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/loadhigh.png" alt="负载高排查导图" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">负载高排查导图</span></div></div><h2 id="内存占用过高"><a href="#内存占用过高" class="headerlink" title="内存占用过高"></a>内存占用过高</h2><p>我们先来了解一下有哪些常用的内存性能工具:</p><table><thead><tr><th>工具</th><th>功能</th><th>用法</th><th>常用选项</th></tr></thead><tbody><tr><td><code>free</code></td><td>显示系统的内存使用情况</td><td><code>free -h</code></td><td><code>-h</code>：以人类可读的格式显示</td></tr><tr><td><code>top</code></td><td>实时显示系统的进程和内存使用情况</td><td><code>top</code></td><td>无</td></tr><tr><td><code>htop</code></td><td>提供更友好的用户界面的进程监控工具</td><td><code>htop</code></td><td>无</td></tr><tr><td><code>vmstat</code></td><td>报告虚拟内存、进程、CPU 活动等统计信息</td><td><code>vmstat 1</code></td><td><code>1</code>：每秒更新一次数据</td></tr><tr><td><code>ps</code></td><td>查看系统中进程的内存使用情况</td><td><code>ps aux --sort=-%mem</code></td><td><code>aux</code>：显示所有用户的进程， <code>--sort=-%mem</code>：按内存使用量降序排列</td></tr><tr><td><code>pmap</code></td><td>显示进程的内存映射</td><td><code>pmap -x &lt;pid&gt;</code></td><td><code>-x</code>：显示详细信息</td></tr><tr><td><code>smem</code></td><td>提供详细的内存使用报告</td><td><code>smem -r</code></td><td>无</td></tr><tr><td><code>/proc</code></td><td>提供系统和进程的详细内存信息</td><td><code>cat /proc/meminfo</code><br><code>cat /proc/&lt;pid&gt;/status</code></td><td>无</td></tr></tbody></table><h3 id="如何判断内存占用过高"><a href="#如何判断内存占用过高" class="headerlink" title="如何判断内存占用过高"></a>如何判断内存占用过高</h3><p>系统内存的使用情况可以通过 <code>top</code> 以及 <code>free</code> 命令进行查看，以 <code>free -m</code>为例:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/free.png" alt="free查看内存信息" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">free查看内存信息</span></div></div><p>字段说明：</p><ul><li>total:  系统总内存（RAM）或交换空间（Swap）的总量。</li><li>used:   已用内存或交换空间的量。这包括正在使用的内存以及系统缓存（对于内存）或已经使用的交换空间。</li><li>free:   空闲的内存或交换空间的量。表示当前未被任何进程使用的内存或交换空间。</li><li>shared: 被多个进程共享的内存量（对于内存）。通常是共享库和进程间通信的内存。</li><li>buff&#x2F;cache: 用作文件系统缓存和缓冲区的内存量。这包括缓存的文件数据（cache）和缓冲区（buff）。这些内存可以被系统用作其他用途。</li><li>available: 可以分配给新启动的应用程序的内存量，而不需要交换到磁盘。这个数字更能反映系统的实际可用内存</li></ul><p>这里我们需要关注下，一般可用内存我们就是以 available 为准。当 available 的指标越来越小时，我们就需要关注系统内存的整体使用情况。</p><p>这里还有一个需要关注的点：Swap，我们先看一下详细介绍:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Swap space in Linux is used when the amount of physical memory (RAM) is full. If the system </span><br><span class="line">needs more memory resources and the RAM is full, inactive pages in memory are moved to the </span><br><span class="line">swap space. While swap space can help machines with a small amount of RAM, it should not be </span><br><span class="line">considered a replacement for more RAM. Swap space is located on hard drives, which have a </span><br><span class="line">slower access time than physical memory.Swap space can be a dedicated swap partition (recommended),</span><br><span class="line"> a swap file, or a combination of swap partitions and swap files.</span><br></pre></td></tr></table></figure><p>SWAP意思是交换，顾名思义，当某进程向OS请求内存发现不足时，OS会把内存中暂时不用的数据交换出去，放在SWAP分区中，这个过程称为SWAP OUT。当某进程又需要这些数据且OS发现还有空闲物理内存时，又会把SWAP分区中的数据交换回物理内存中，这个过程称为SWAP IN。<br>简单来说，就是物理内存不足时，把磁盘空间当作 swap 分区，解决容量不足的问题。</p><p>这里我们其实会发现一个问题，物理内存的读写性能肯定要比磁盘强不少，使用了磁盘空间作为内存存储，本身读写的性能就不高，还涉及到频繁的交换，反而增加了系统的负载，所以在线上环境中我们一般建议关闭 swap，具体的关闭方法请自行百度。</p><p>我们也可以通过<code>cat /proc/meminfo</code> 来查看全局的内存占用情况. 这里面详细列出了各个内存的使用情况:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">MemTotal:       263676228 kB</span><br><span class="line">MemFree:        38840328 kB</span><br><span class="line">MemAvailable:   203804064 kB</span><br><span class="line">Buffers:          792100 kB</span><br><span class="line">Cached:         156780260 kB</span><br><span class="line">SwapCached:            0 kB</span><br><span class="line">Active:         107213216 kB</span><br><span class="line">Inactive:       102285984 kB</span><br><span class="line">Active(anon):   53984660 kB</span><br><span class="line">Inactive(anon):  1940744 kB</span><br><span class="line">Active(file):   53228556 kB</span><br><span class="line">Inactive(file): 100345240 kB</span><br><span class="line">Unevictable:           0 kB</span><br><span class="line">Mlocked:               0 kB</span><br><span class="line">SwapTotal:             0 kB</span><br><span class="line">SwapFree:              0 kB</span><br><span class="line">Dirty:               312 kB</span><br><span class="line">Writeback:             0 kB</span><br><span class="line">AnonPages:      51927324 kB</span><br><span class="line">Mapped:           323924 kB</span><br><span class="line">Shmem:           3998388 kB</span><br><span class="line">Slab:           12727244 kB</span><br><span class="line">SReclaimable:   12274136 kB</span><br><span class="line">SUnreclaim:       453108 kB</span><br><span class="line">KernelStack:       35680 kB</span><br><span class="line">PageTables:       146316 kB</span><br><span class="line">NFS_Unstable:          0 kB</span><br><span class="line">Bounce:                0 kB</span><br><span class="line">WritebackTmp:          0 kB</span><br><span class="line">CommitLimit:    131817632 kB</span><br><span class="line">Committed_AS:   91789580 kB</span><br><span class="line">VmallocTotal:   34359738367 kB</span><br><span class="line">VmallocUsed:      731428 kB</span><br><span class="line">VmallocChunk:   34224600712 kB</span><br><span class="line">HardwareCorrupted:     0 kB</span><br><span class="line">AnonHugePages:      8192 kB</span><br><span class="line">CmaTotal:              0 kB</span><br><span class="line">CmaFree:               0 kB</span><br><span class="line">HugePages_Total:      20</span><br><span class="line">HugePages_Free:       20</span><br><span class="line">HugePages_Rsvd:        0</span><br><span class="line">HugePages_Surp:        0</span><br><span class="line">Hugepagesize:       2048 kB</span><br><span class="line">DirectMap4k:     1242112 kB</span><br><span class="line">DirectMap2M:    85313536 kB</span><br><span class="line">DirectMap1G:    183500800 kB</span><br></pre></td></tr></table></figure><h3 id="如何定位内存占用高"><a href="#如何定位内存占用高" class="headerlink" title="如何定位内存占用高"></a>如何定位内存占用高</h3><p>针对内存的占用，常规情况下(当然也有非常规情况)，我们需要找到占用内存高的具体进程，详细的操作方式是:<br><code>top</code>的时候输入<code>M</code>进行排序，这样我们就可以看到系统中进程消耗内存的详细占比了:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/top-process.png" data-fancybox="true"/></div></div><p>这里我们重点关注两列: <code>%MEM</code> 和 <code>RES</code>, 前者是这个进程占用系统内存的百分比，后者是占用实际内存的大小。</p><p>我们还是以 JAVA 和 GOLANG 程序为例来分析内存高该如何排查</p><h4 id="JAVA-占用内存过高"><a href="#JAVA-占用内存过高" class="headerlink" title="JAVA 占用内存过高"></a>JAVA 占用内存过高</h4><p>Java 应用的内存管理依赖于 JVM (Java Virtual Machine)，通常会涉及到堆内存（Heap）、非堆内存（Non-Heap）以及本地内存（Native Memory）。</p><h5 id="堆内内存分析"><a href="#堆内内存分析" class="headerlink" title="堆内内存分析"></a>堆内内存分析</h5><ol><li>查看 JVM 启动参数，尤其是 -Xms 和 -Xmx 选项，这两个参数分别设置了初始堆内存大小和最大堆内存大小。可以通过 ps 命令查看这些参数：<code>ps -auxf | grep 程序名称</code></li><li>使用 jstat 查看 gc 情况, 实例：<code>jstat -gc pid 1000</code><div class="tag-plugin image"><div class="image-bg"><img src="/images/gc.png" alt="gc 信息" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">gc 信息</span></div></div>如果 GC 频繁，那么我们需要进一步进行分析</li><li>通过 jmap 生成进程的堆内存快照 (在 JVM启动时，建议添加 OOM 时自动生成 heap dump: <code>-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path/to/dumpfile</code>)：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -dump:live,format=b,file=heapdump.hprof &lt;pid&gt;</span><br></pre></td></tr></table></figure></li><li>拿到快照文件后，我们可以通过 MAT 或者 Jprofiler 这样的工具去具体分析<br>以 MAT 为例：</li></ol><div class="tag-plugin image"><div class="image-bg"><img src="/images/mat.jpeg" alt="MAT 分析 JAVA内存" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">MAT 分析 JAVA内存</span></div></div><h5 id="本地内存分析"><a href="#本地内存分析" class="headerlink" title="本地内存分析"></a>本地内存分析</h5><p>NMT（Native Memory Tracking）是 HotSpot JVM 引入的跟踪 JVM 内部使用的本地内存的一个特性，可以通过 jcmd 工具访问 NMT 数据。NMT 目前不支持跟踪第三方本地代码的内存分配和 JDK 类库。<br>NMT 不跟踪非 JVM 代码的内存分配，本地代码里的内存泄露需要使用操作系统支持的工具来定位。</p><p>启用 NMT 会带来 5-10% 的性能损失。NMT 的内存使用率情况需要添加两个机器字 word 到 malloc 内存的 malloc 头里。NMT 内存使用率也被 NMT 跟踪。<br>启动命令： <code>-XX:NativeMemoryTracking=[off | summary | detail]</code>。</p><ul><li>off：NMT 默认是关闭的；</li><li>summary：只收集子系统的内存使用的总计数据；</li><li>detail：收集每个调用点的内存使用数据。</li></ul><p>开启后，我们可以通过如下命令访问 NMT 内存：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jcmd &lt;pid&gt; VM.native_memory [summary | detail | baseline | summary.diff | detail.diff | shutdown] [scale= KB | MB | GB]</span><br></pre></td></tr></table></figure><h5 id="其他非堆内存"><a href="#其他非堆内存" class="headerlink" title="其他非堆内存"></a>其他非堆内存</h5><p>主要包括：</p><ul><li>JVM 自身运行占用的空间；</li><li>线程栈分配占用的系统内存；</li><li>DirectByteBuffer 占用的内存；</li><li>JNI 里分配的内存；</li><li>Java 8 开始的元数据空间；</li><li>NIO 缓存</li><li>Unsafe 调用分配的内存；</li><li>codecache</li></ul><p>对于这些问题，遇到内存升高的情况较少，所以也没有进行过详细的排查，如果有读者朋友有做过类似的排查，可以在下面留言讨论。</p><h4 id="golang程序占用内存高"><a href="#golang程序占用内存高" class="headerlink" title="golang程序占用内存高"></a>golang程序占用内存高</h4><p>golang 内置了 pprof 性能分析工具，支持 CPU、内存（Heap）、栈、协程等的分析。可以通过 HTTP 服务暴露 pprof 接口，并使用浏览器或 go tool pprof 进行分析：<br>在代码中引入 net&#x2F;http&#x2F;pprof 包：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> _ <span class="string">&quot;net/http/pprof&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        log.Println(http.ListenAndServe(<span class="string">&quot;localhost:6060&quot;</span>, <span class="literal">nil</span>))</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="comment">// 你的应用代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动应用后，通过浏览器访问 <code>http://localhost:6060/debug/pprof/heap</code> 下载堆内存快照，并使用以下命令分析：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof -http=:8080 heap.prof</span><br></pre></td></tr></table></figure><p>这将启动一个 Web 界面，供你分析内存占用的热点。<br>具体的使用方式大家可以自行研究。</p><h4 id="操作系统内存占用"><a href="#操作系统内存占用" class="headerlink" title="操作系统内存占用"></a>操作系统内存占用</h4><h5 id="基于内存的文件系统占用"><a href="#基于内存的文件系统占用" class="headerlink" title="基于内存的文件系统占用"></a>基于内存的文件系统占用</h5><p>在上文中，我们说了常规情况下的排查，那来个非常规的，先上张图：</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/tmp-mem.png" alt="内存占用模拟" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">内存占用模拟</span></div></div><p>这里大家看看到，内存总量大概有 250 个 G，可用内存只有 126G，但是我们通过 top 看内存占比跟实际的数值相差甚远。</p><p>这种场景是不是非常奇怪呢？没有进程占用内存，但是内存被消耗了，这种情况下，很有可能跟基于内存的文件系统有关。</p><p>这里我说一下模拟方法:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># systemd 的包中会默认自带一个 tmp.mount服务，这个服务默认是关闭的（默认是总内存的一半）</span><br><span class="line"># 这个服务本质上是一个基于内存的文件系统（把内存当磁盘使，在上面可以创建文件）</span><br><span class="line">systemctl start tmp.mount</span><br><span class="line"></span><br><span class="line"># 然后我们通过 df -h /tmp 可以看到</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">tmpfs           126G  111G   16G  88% /tmp</span><br><span class="line"></span><br><span class="line">这里挂载了/tmp 目录，文件系统是 tmpfs</span><br><span class="line"></span><br><span class="line"># 然后我们进入 /tmp目录</span><br><span class="line"># 模拟文件创建</span><br><span class="line">dd if=/dev/zero of=test.txt bs=G count=100</span><br><span class="line"></span><br><span class="line"># 然后我们就可以看到文件创建成功，然后 free -g 就可以看到内存成功消耗了100G😂</span><br></pre></td></tr></table></figure><p>这种场景也是我之前在排查问题的时候遇到的，大家有其他类似场景也可以进行补充</p><h5 id="slab-内存占用"><a href="#slab-内存占用" class="headerlink" title="slab 内存占用"></a>slab 内存占用</h5><p>slab内存是内核用于高效分配小块内存的一种缓存机制。当内核需要分配内存时，它会首先检查slab内存池是否有可用的内存块。如果有，内核会直接从slab内存池中分配内存，而不是每次都向操作系统请求内存。这样可以减少内存分配和释放的开销，提高内存分配的效率。</p><p>我们在 meminfo 文件中其实可以看到 slab 相关的使用情况。 包括可回收和不可回收的 slab 内存。如果可回收内存过高，那么针对性进行释放; 如果不可回收内存过高，可以针对性的进行排查。</p><h2 id="磁盘问题"><a href="#磁盘问题" class="headerlink" title="磁盘问题"></a>磁盘问题</h2><p>线上的磁盘问题，除了磁盘故障(坏块、文件系统损坏、RAID 等)之外，常见的比较多的问题可以分为两大类：磁盘空间不足和 IO 性能问题</p><h3 id="磁盘空间不足"><a href="#磁盘空间不足" class="headerlink" title="磁盘空间不足"></a>磁盘空间不足</h3><p>对于这类问题，一般情况下，本身可能就是数据文件、日志信息等过多导致的<strong>真实占用</strong>，还有一类是文件句柄泄露导致磁盘没有释放从而占据了多余的磁盘空间</p><p>对于这类问题我们一般通过以下手段进行排查，假如说我们现在接到告警 说根目录的磁盘空间不足了</p><ol><li>通过<code>df -h</code>命令查看磁盘分区的使用情况。</li><li>进入 <code>&quot;/&quot;</code> 目录下，可以对常用的目录进行 <code>du -sh</code>操作，然后进行简单的相加<ul><li>如果加起来的磁盘空间，和分区使用的磁盘空间相差不多，那就基本上说明磁盘空间是被真实占用的，找到占用高的目录继续通过<code>du -sh</code> 目录，不断递归。或者想快速找到磁盘中超过 1G 的文件，可以通过<code>find 目录 -type f -size +1G</code> 这样的方式。<br>如果想快速统计到所有子目录的磁盘信息，那么可以通过这样的方式进行操作<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">du -ah / 2&gt;/dev/null | grep -E &#x27;^([0-9]+([KMGT]?)|([0-9]+(\.[0-9]+)?[KMGT]))&#x27; | sort -rh | head -10</span><br></pre></td></tr></table></figure></li><li>如果加起来的磁盘空间，和分区使用的磁盘空间相差的比较大，那么可能存在句柄泄露，比如日志文件本身被删掉，但是句柄没有释放，可以通过一下方式: <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#列出进打开文件最多的 10 个进程；</span><br><span class="line">lsof +L1 | awk &#x27;&#123;print $2&#125;&#x27; | sort | uniq -c | sort -rn | head -n 10</span><br><span class="line">   </span><br><span class="line"># 查看某个进程的占用</span><br><span class="line">lsof -p $pid (查看是否存在已经删除的文件句柄没有释放，可以通过 grep deleted 过滤)</span><br><span class="line">   </span><br><span class="line"># 或者 ls /proc/$pid/fd 进行查看</span><br></pre></td></tr></table></figure></li></ul></li></ol><h3 id="磁盘IO性能问题"><a href="#磁盘IO性能问题" class="headerlink" title="磁盘IO性能问题"></a>磁盘IO性能问题</h3><p>我们可以通过 iostat 看下磁盘整体的读写情况:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/iostat.png" alt="iostat" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">iostat</span></div></div><p>关于 iostat 的采集，建议多采集几次观察，比如 <code>iostat -x 2</code>,每 2s 检查一次， 一直输出，当不需要的时候 ctrl c 掉</p><p>输出的指标每一项详细的介绍如下（也可以参考 man iostat）：</p><ol><li>CPU 使用情况</li></ol><table><thead><tr><th>Metric</th><th>Description</th></tr></thead><tbody><tr><td>%user</td><td>用户模式下消耗的 CPU 时间百分比</td></tr><tr><td>%nice</td><td>调整优先级的用户模式下的 CPU 时间百分比</td></tr><tr><td>%system</td><td>内核模式下消耗的 CPU 时间百分比</td></tr><tr><td>%iowait</td><td>CPU 等待 I&#x2F;O 操作完成的时间百分比</td></tr><tr><td>%steal</td><td>等待虚拟 CPU 被实际 CPU 服务的时间百分比</td></tr><tr><td>%idle</td><td>CPU 空闲时间百分比</td></tr></tbody></table><ol start="2"><li>设备 I&#x2F;O 使用情况</li></ol><table><thead><tr><th>Metric</th><th>Description</th></tr></thead><tbody><tr><td>Device</td><td>设备名称</td></tr><tr><td>tps</td><td>每秒传输数（I&#x2F;O 请求数）</td></tr><tr><td>kB_read&#x2F;s</td><td>每秒读取的 kB 数</td></tr><tr><td>kB_wrtn&#x2F;s</td><td>每秒写入的 kB 数</td></tr><tr><td>kB_read</td><td>读取的 kB 总数</td></tr><tr><td>kB_wrtn</td><td>写入的 kB 总数</td></tr><tr><td>rrqm&#x2F;s</td><td>每秒进行的合并读请求数</td></tr><tr><td>wrqm&#x2F;s</td><td>每秒进行的合并写请求数</td></tr><tr><td>r&#x2F;s</td><td>每秒完成的读请求数</td></tr><tr><td>w&#x2F;s</td><td>每秒完成的写请求数</td></tr><tr><td>rMB&#x2F;s</td><td>每秒读取的 MB 数</td></tr><tr><td>wMB&#x2F;s</td><td>每秒写入的 MB 数</td></tr><tr><td>avgrq-sz</td><td>平均每次 I&#x2F;O 请求的数据大小</td></tr><tr><td>avgqu-sz</td><td>平均 I&#x2F;O 队列长度</td></tr><tr><td>await</td><td>平均每次 I&#x2F;O 操作的等待时间</td></tr><tr><td>svctm</td><td>平均每次 I&#x2F;O 操作的服务时间</td></tr><tr><td>%util</td><td>设备 I&#x2F;O 活动时间百分比（表示设备忙碌度）</td></tr></tbody></table><p>通过这个我们就可以获取到磁盘的整体情况。需要注意的是 %util 到 100% 之后，不一定代表磁盘出现了瓶颈，还需要结合其他指标共同进行判断，比如有一张 nvme 的盘，持续的读写，这种情况下有不断地 io 操作， util 的指标会显示为 100%，但是如果磁盘的读写还没有达到预期的范围并且 avgqu-sz 指标始终为 0（没有 io 阻塞），那就说明磁盘完全承载当前的用量，所以无需关心。</p><p>当我们想查看进程占用的 io 情况时，可以通过 <code>iotop</code>命令进行查看，如下:</p><div class="tag-plugin image"><div class="image-bg"><img src="/images/iotop.png" alt="iotop" data-fancybox="true"/></div><div class="image-meta"><span class="image-caption center">iotop</span></div></div><p>结合上文讲的一些堆栈分析工具，推测到进程具体在做那些操作然后针对性进行处理。</p>]]></content>
    
    
    <summary type="html">线上故障问题的排查方法和工具介绍，包括 CPU、内存、负载、磁盘、IO、网络等</summary>
    
    
    
    <category term="问题排查" scheme="http://baixiaozhou.github.io/categories/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
    
    <category term="Linux" scheme="http://baixiaozhou.github.io/tags/Linux/"/>
    
    <category term="Java" scheme="http://baixiaozhou.github.io/tags/Java/"/>
    
    <category term="Golang" scheme="http://baixiaozhou.github.io/tags/Golang/"/>
    
    <category term="commands" scheme="http://baixiaozhou.github.io/tags/commands/"/>
    
  </entry>
  
  <entry>
    <title>JAVA问题定位</title>
    <link href="http://baixiaozhou.github.io/p/JAVA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"/>
    <id>http://baixiaozhou.github.io/p/JAVA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/</id>
    <published>2024-07-30T07:32:13.000Z</published>
    <updated>2024-08-17T15:11:14.404Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="一、JAVA-相关命令"><a href="#一、JAVA-相关命令" class="headerlink" title="一、JAVA 相关命令"></a>一、JAVA 相关命令</h1><h2 id="1-jps"><a href="#1-jps" class="headerlink" title="1.jps"></a>1.jps</h2><p>jps - Lists the instrumented Java Virtual Machines (JVMs) on the target system. This command is experimental and unsupported.</p><p>相关参数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">OPTIONS</span><br><span class="line">       The jps command supports a number of options that modify the output of the command. These options are subject to change or removal in the future.</span><br><span class="line">       -q</span><br><span class="line">              Suppresses the output of the class name, JAR file name, and arguments passed to the main method, producing only a list of local JVM identifiers.</span><br><span class="line">       -m</span><br><span class="line">              Displays the arguments passed to the main method. The output may be null for embedded JVMs.</span><br><span class="line">       -l</span><br><span class="line">              Displays the full package name for the application&#x27;s main class or the full path name to the application&#x27;s JAR file.</span><br><span class="line">       -v</span><br><span class="line">              Displays the arguments passed to the JVM.</span><br><span class="line">       -V</span><br><span class="line">              Suppresses the output of the class name, JAR file name, and arguments passed to the main method, producing only a list of local JVM identifiers.</span><br><span class="line">       -Joption</span><br><span class="line">              Passes option to the JVM, where option is one of the options described on the reference page for the Java application launcher. For example, -J-Xms48m sets the</span><br><span class="line">              startup memory to 48 MB. See java(1).</span><br></pre></td></tr></table></figure><h2 id="2-jinfo"><a href="#2-jinfo" class="headerlink" title="2.jinfo"></a>2.jinfo</h2><p>jinfo（Java Virtual Machine Configuration Information）是JDK提供的一个可以实时查看Java虚拟机各种配置参数和系统属性的命令行工具。使用jps命令的-v参数可以查看Java虚拟机启动时显式指定的配置参数，如果想查看没有显式指定的配置参数就可以使用jinfo命令进行查看。另外，jinfo命令还可以查询Java虚拟机进程的System.getProperties()的内容。</p><p>以tomcat进程为例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">Attaching to process ID 2045, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 25.242-b08</span><br><span class="line">Java System Properties:</span><br><span class="line"></span><br><span class="line">java.vendor = Huawei Technologies Co., Ltd</span><br><span class="line">sun.java.launcher = SUN_STANDARD</span><br><span class="line">catalina.base = /usr/share/tomcat</span><br><span class="line">sun.management.compiler = HotSpot 64-Bit Tiered Compilers</span><br><span class="line">sun.nio.ch.bugLevel = </span><br><span class="line">catalina.useNaming = true</span><br><span class="line">jnidispatch.path = /var/cache/tomcat/temp/jna--903012287/jna4240128671455089550.tmp</span><br><span class="line">os.name = Linux</span><br><span class="line">sun.boot.class.path = /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/resources.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/rt.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/jce.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/classes</span><br><span class="line">java.vm.specification.vendor = Oracle Corporation</span><br><span class="line">java.runtime.version = 1.8.0_242-b08</span><br><span class="line">jna.loaded = true</span><br><span class="line">user.name = xxx</span><br><span class="line">tomcat.util.scan.StandardJarScanFilter.jarsToScan = taglibs-standard-impl*.jar</span><br><span class="line">shared.loader = </span><br><span class="line">tomcat.util.buf.StringCache.byte.enabled = true</span><br><span class="line">user.language = en</span><br><span class="line">java.naming.factory.initial = org.apache.naming.java.javaURLContextFactory</span><br><span class="line">sun.boot.library.path = /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/amd64</span><br><span class="line">java.version = 1.8.0_242</span><br><span class="line">java.util.logging.manager = org.apache.juli.ClassLoaderLogManager</span><br><span class="line">user.timezone = Asia/Shanghai</span><br><span class="line">sun.arch.data.model = 64</span><br><span class="line">java.util.concurrent.ForkJoinPool.common.threadFactory = org.apache.catalina.startup.SafeForkJoinWorkerThreadFactory</span><br><span class="line">java.endorsed.dirs = </span><br><span class="line">sun.cpu.isalist = </span><br><span class="line">sun.jnu.encoding = UTF-8</span><br><span class="line">file.encoding.pkg = sun.io</span><br><span class="line">package.access = sun.,org.apache.catalina.,org.apache.coyote.,org.apache.jasper.,org.apache.tomcat.</span><br><span class="line">file.separator = /</span><br><span class="line">java.specification.name = Java Platform API Specification</span><br><span class="line">java.class.version = 52.0</span><br><span class="line">user.country = US</span><br><span class="line">java.home = /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre</span><br><span class="line">java.vm.info = mixed mode</span><br><span class="line">os.version = 4.19.90-24.4.v2101.ky10.x86_64</span><br><span class="line">sun.font.fontmanager = sun.awt.X11FontManager</span><br><span class="line">path.separator = :</span><br><span class="line">java.vm.version = 25.242-b08</span><br><span class="line">jboss.i18n.generate-proxies = true</span><br><span class="line">java.awt.printerjob = sun.print.PSPrinterJob</span><br><span class="line">sun.io.unicode.encoding = UnicodeLittle</span><br><span class="line">awt.toolkit = sun.awt.X11.XToolkit</span><br><span class="line">package.definition = sun.,java.,org.apache.catalina.,org.apache.coyote.,org.apache.jasper.,org.apache.naming.,org.apache.tomcat.</span><br><span class="line">java.naming.factory.url.pkgs = org.apache.naming</span><br><span class="line">mail.mime.splitlongparameters = false</span><br><span class="line">java.security.egd = file:/dev/./urandom</span><br><span class="line">user.home = /home/shterm</span><br><span class="line">java.specification.vendor = Oracle Corporation</span><br><span class="line">tomcat.util.scan.StandardJarScanFilter.jarsToSkip = activ*.jar,amqp-client.jar,annotations-api.jar,ant-junit*.jar,ant-launcher.jar,ant.jar,antlr.jar,aopalliance.jar,asm-*.jar,aspectj*.jar,bcp*.jar,bootstrap.jar,catalina-ant.jar,catalina-ha.jar,catalina-jmx-remote.jar,catalina-storeconfig.jar,catalina-tribes.jar,catalina-ws.jar,catalina.jar,cglib-*.jar,classmate.jar,cobertura-*.jar,commons-*.jar,compress-lzf.jar,curator-*.jar,db2-jdbc.jar,dom4j-*.jar,easymock-*.jar,ecj-*.jar,el-api.jar,elasticsearch.jar,geronimo-spec-jaxrpc*.jar,groovy-all.jar,guava.jar,h2*.jar,hamcrest-*.jar,hibernate*.jar,hppc.jar,http*.jar,icu4j-*.jar,itext*.jar,jackson-*.jar,jandex.jar,jasper-el.jar,jasper.jar,jasperreports*.jar,jaspic-api.jar,javamail.jar,javassist.jar,jaxb-*.jar,jaxen*.jar,jboss*.jar,jc*.jar,jdom-*.jar,jedis.jar,jetty-*.jar,jfreechart.jar,jgit.jar,jline.jar,jmx-tools.jar,jmx.jar,jna.jar,joda-time.jar,jr-*.jar,jsch.jar,json*.jar,jsoup.jar,jsp-api.jar,jsr166e.jar,jstl.jar,jta*.jar,junit-*.jar,junit.jar,liquibase-*.jar,log4j*.jar,lucene*.jar,mail*.jar,mariadb-jdbc.jar,mssql-jdbc.jar,mybatis.jar,netty.jar,nmap4j.jar,objenesis*.jar,olap4j.jar,opc*.jar,oracle-jdbc.jar,oraclepki.jar,oro-*.jar,poi*.jar,postgresql-jdbc.jar,quartz.jar,servlet-api-*.jar,servlet-api.jar,slf4j*.jar,snakeyaml.jar,snmp4j.jar,spring*.jar,sshd-core.jar,taglibs-standard-spec-*.jar,tagsoup-*.jar,t-digest.jar,tomcat-api.jar,tomcat-coyote.jar,tomcat-dbcp.jar,tomcat-i18n-*.jar,tomcat-jdbc.jar,tomcat-jni.jar,tomcat-juli-adapters.jar,tomcat-juli.jar,tomcat-util-scan.jar,tomcat-util.jar,tomcat-websocket.jar,tools.jar,validation-api.jar,velocypack.jar,websocket-api.jar,wl*.jar,wsdl4j*.jar,xercesImpl.jar,xml-apis.jar,xmlbeans.jar,xmlParserAPIs-*.jar,xmlParserAPIs.jar,xom-*.jar,xz.jar,zip4j.jar,zookeeper.jar</span><br><span class="line">java.library.path = /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib</span><br><span class="line">java.vendor.url = http://jdk.rnd.huawei.com/</span><br><span class="line">java.vm.vendor = Huawei Technologies Co., Ltd</span><br><span class="line">common.loader = &quot;$&#123;catalina.base&#125;/lib&quot;,&quot;$&#123;catalina.base&#125;/lib/*.jar&quot;,&quot;$&#123;catalina.home&#125;/lib&quot;,&quot;$&#123;catalina.home&#125;/lib/*.jar&quot;</span><br><span class="line">java.runtime.name = OpenJDK Runtime Environment</span><br><span class="line">sun.java.command = org.apache.catalina.startup.Bootstrap start</span><br><span class="line">java.class.path = /usr/share/tomcat/bin/bootstrap.jar:/usr/share/tomcat/bin/tomcat-juli.jar:/usr/lib/java/commons-daemon.jar</span><br><span class="line">java.vm.specification.name = Java Virtual Machine Specification</span><br><span class="line">java.vm.specification.version = 1.8</span><br><span class="line">catalina.home = /usr/share/tomcat</span><br><span class="line">sun.cpu.endian = little</span><br><span class="line">sun.os.patch.level = unknown</span><br><span class="line">java.awt.headless = true</span><br><span class="line">java.io.tmpdir = /var/cache/tomcat/temp</span><br><span class="line">java.vendor.url.bug = http://jdk.rnd.huawei.com/</span><br><span class="line">server.loader = </span><br><span class="line">java.rmi.server.hostname = 127.0.0.1</span><br><span class="line">jna.platform.library.path = /usr/lib64:/lib64:/usr/lib:/lib:/usr/lib64/tracker-miners-2.0:/usr/lib64/tracker-2.0:/usr/lib64/dyninst:/usr/libexec/sudo:/usr/lib64/sssd:/usr/pgsql-9.6/lib:/usr/lib64/perl5/CORE:/usr/lib64/opencryptoki:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/amd64/jli:/usr/lib64/bind9-export</span><br><span class="line">os.arch = amd64</span><br><span class="line">java.awt.graphicsenv = sun.awt.X11GraphicsEnvironment</span><br><span class="line">java.ext.dirs = /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-1.h5.ky10.x86_64/jre/lib/ext:/usr/java/packages/lib/ext</span><br><span class="line">user.dir = /usr/share/tomcat</span><br><span class="line">line.separator = </span><br><span class="line"></span><br><span class="line">java.vm.name = OpenJDK 64-Bit Server VM</span><br><span class="line">log4j.configurationFile = /etc/tomcat/log4j2.xml</span><br><span class="line">file.encoding = UTF-8</span><br><span class="line">com.sun.jndi.ldap.object.disableEndpointIdentification = </span><br><span class="line">java.specification.version = 1.8</span><br><span class="line"></span><br><span class="line">VM Flags:</span><br><span class="line">Non-default VM flags: -XX:CICompilerCount=4 -XX:GCLogFileSize=20971520 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=null -XX:InitialHeapSize=243269632 -XX:MaxHeapSize=1610612736 -XX:MaxNewSize=536870912 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=80740352 -XX:NumberOfGCLogFiles=15 -XX:OldSize=162529280 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseGCLogFileRotation -XX:+UseParallelGC </span><br><span class="line">Command line:  -Xmx1536m -Djava.security.egd=file:/dev/./urandom -Djava.awt.headless=true -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/var/log/tomcat -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=15 -XX:GCLogFileSize=20m -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:/var/log/tomcat/tomcat-gc-%t.log -Dcom.sun.jndi.ldap.object.disableEndpointIdentification -Dcatalina.base=/usr/share/tomcat -Dcatalina.home=/usr/share/tomcat -Djava.endorsed.dirs= -Djava.io.tmpdir=/var/cache/tomcat/temp -Dlog4j.configurationFile=/etc/tomcat/log4j2.xml -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager</span><br></pre></td></tr></table></figure><h2 id="3-jstat"><a href="#3-jstat" class="headerlink" title="3.jstat"></a>3.jstat</h2><p>命令参数说明：</p><ul><li>generalOptions：通用选项，如果指定一个通用选项，就不能指定任何其他选项或参数。它包括如下两个选项：</li><li>-help：显示帮助信息。</li><li>-options：显示outputOptions参数的列表。</li><li>outputOptions：输出选项，指定显示某一种Java虚拟机信息。</li><li>-t：把时间戳列显示为输出的第一列。这个时间戳是从Java虚拟机的开始运行到现在的秒数。</li><li>-h n：每显示n行显示一次表头，其中n为正整数。默认值为 0，即仅在第一行数据显示一次表头。</li><li>vmid：虚拟机唯一ID（LVMID，Local Virtual Machine Identifier），如果查看本机就是Java进程的进程ID。</li><li>interval：显示信息的时间间隔，单位默认毫秒。也可以指定秒为单位，比如：1s。如果指定了该参数，jstat命令将每隔这段时间显示一次统计信息。</li><li>count：显示数据的次数，默认值是无穷大，这将导致jstat命令一直显示统计信息，直到目标JVM终止或jstat命令终止。<br>输出选项<br>如果不指定通用选项（generalOptions），则可以指定输出选项（outputOptions）。输出选项决定jstat命令显示的内容和格式，具体如下：</li><li>-class：显示类加载、卸载数量、总空间和装载耗时的统计信息。</li><li>-compiler：显示即时编译的方法、耗时等信息。</li><li>-gc：显示堆各个区域内存使用和垃圾回收的统计信息。</li><li>-gccapacity：显示堆各个区域的容量及其对应的空间的统计信息。</li><li>-gcutil：显示有关垃圾收集统计信息的摘要。</li><li>-gccause：显示关于垃圾收集统计信息的摘要(与-gcutil相同)，以及最近和当前垃圾回收的原因。</li><li>-gcnew：显示新生代的垃圾回收统计信息。</li><li>-gcnewcapacity：显示新生代的大小及其对应的空间的统计信息。</li><li>-gcold: 显示老年代和元空间的垃圾回收统计信息。</li><li>-gcoldcapacity：显示老年代的大小统计信息。</li><li>-gcmetacapacity：显示元空间的大小的统计信息。</li><li>-printcompilation：显示即时编译方法的统计信息。</li></ul><h1 id="二、线程堆栈"><a href="#二、线程堆栈" class="headerlink" title="二、线程堆栈"></a>二、线程堆栈</h1><h2 id="1-输出"><a href="#1-输出" class="headerlink" title="1.输出"></a>1.输出</h2><p>Java虚拟机提供了线程转储(Thread dump)的后门，通过这个后门，可以将线程堆栈打印出来。这个后门就是通过向Java进程发送一个QUIT信号，Java虚拟机收到该信号之后，将系统当前的JAVA线程调用堆栈打印出来。</p><p>打印方法：</p><ul><li>jstack -l pid &gt; xxx.txt 需要注意的是，linux系统中往往会用不同的用户去执行不同的程序，此时可能需要通过sudu -u xxx jstack的形式</li><li>kill -3<br><em><strong>同时请确保Java命令行中没有DISABLE_JAVADUMP运行选项</strong></em></li></ul><h2 id="2-线程分析"><a href="#2-线程分析" class="headerlink" title="2.线程分析"></a>2.线程分析</h2><p>通过输出堆栈进行分析 <code>jstack -l $(jps | grep xxx | awk &#39;&#123;print $1&#125;&#39;)</code> &gt; &#x2F;tmp&#x2F;xxx.jstack</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;SYS_STATUS_CHECKER&quot;</span> #<span class="number">14</span> daemon prio=<span class="number">5</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f5e047bf000</span> nid=<span class="number">0xe15</span> waiting on condition [<span class="number">0x00007f5dd43d1000</span>]</span><br><span class="line">    java.lang.Thread.State: TIMED_WAITING (sleeping)</span><br><span class="line">        at java.lang.Thread.sleep(Native Method)</span><br><span class="line">ru        at com.xxx.xxx.SystemStatusChecker.run(SystemStatusChecker.java:xx)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:<span class="number">748</span>)        </span><br><span class="line">    Locked ownable synchronizers:</span><br><span class="line">        - None</span><br><span class="line">                </span><br><span class="line"><span class="string">&quot;RMI Reaper&quot;</span> #<span class="number">39</span> prio=<span class="number">5</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f5e04e4c800</span> nid=<span class="number">0xf0b</span> <span class="keyword">in</span> Object.wait() [<span class="number">0x00007f5dae2c4000</span>]</span><br><span class="line">    java.lang.Thread.State: WAITING (on object monitor)</span><br><span class="line">        at java.lang.Object.wait(Native Method)</span><br><span class="line">        - waiting on &lt;<span class="number">0x00000000c0c88d20</span>&gt; (a java.lang.ref.ReferenceQueue$Lock)</span><br><span class="line">        at java.lang.ref.ReferenceQueue.<span class="built_in">remove</span>(ReferenceQueue.java:<span class="number">144</span>)</span><br><span class="line">        - locked &lt;<span class="number">0x00000000c0c88d20</span>&gt; (a java.lang.ref.ReferenceQueue$Lock)</span><br><span class="line">        at java.lang.ref.ReferenceQueue.<span class="built_in">remove</span>(ReferenceQueue.java:<span class="number">165</span>)</span><br><span class="line">        at sun.rmi.transport.ObjectTable$Reaper.run(ObjectTable.java:<span class="number">351</span>)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br><span class="line">    Locked ownable synchronizers:</span><br><span class="line">        - None</span><br><span class="line">        </span><br><span class="line"><span class="string">&quot;main&quot;</span> #<span class="number">1</span> prio=<span class="number">5</span> os_prio=<span class="number">0</span> tid=<span class="number">0x00007f5e0400a000</span> nid=<span class="number">0xdcb</span> runnable [<span class="number">0x00007f5e0b393000</span>]</span><br><span class="line">    java.lang.Thread.State: RUNNABLE</span><br><span class="line">        at java.net.PlainSocketImpl.socketAccept(Native Method)</span><br><span class="line">        at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:<span class="number">409</span>)</span><br><span class="line">        at java.net.ServerSocket.implAccept(ServerSocket.java:<span class="number">545</span>)</span><br><span class="line">        at java.net.ServerSocket.accept(ServerSocket.java:<span class="number">513</span>)</span><br><span class="line">        at com.xxx.common.xxx.await(CommonMain.java:<span class="number">244</span>)</span><br><span class="line">        at com.xxx.common.xxx.startup(CommonMain.java:<span class="number">207</span>)</span><br><span class="line">        at com.xxx.common.xxx.main(CommonMain.java:<span class="number">147</span>)</span><br><span class="line">    Locked ownable synchronizers:</span><br><span class="line">        - None</span><br></pre></td></tr></table></figure><p>在RMI线程中可以看到 “ - locked &lt;0x00000000c0c88d20&gt; (a java.lang.ref.ReferenceQueue$Lock)” 表示该线程已经使用了ID为”0x00000000c0c88d2”的锁，锁的ID由系统自动产生</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;main&quot;  prio=5     os_prio=0          tid=0x00007f5e0400a000 nid=0xdcb      runnable [0x00007f5e0b393000]</span><br><span class="line">|       |          |                  |                      |              |         |</span><br><span class="line">线程名称 线程优先级   操作系统级别的优先级   线程id                 对应的本地线程ID  状态      线程占用内存地址</span><br></pre></td></tr></table></figure><p>其中”线程对应的本地线程id号”所指的”本地线程”是指该Java线程所对应的虚拟机中的本地线程。我们知道Java是解析型语言，执行的实体是Java虚拟机，因此Java语言中的线程是 依附于Java虚拟机中的本地线程来运行的，实际上是本地线程在执行Java线程代码。</p><p>Java代码 中创建一个thread，虚拟机在运行期就会创建一个对应的本地线程，而这个本地线程才是真正的线程实体。为了更加深入得理解本地线程和Java线程的关系，在Unix&#x2F;Linux下，我们可以通 如下方式把Java虚拟机的本地线程打印出来：</p><ul><li>使用ps -ef | grep java 获得Java进程ID。</li><li>使用pstack <java pid>获得Java虚拟机的本地线程的堆栈<br>其中本地线程各项含义如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Thread 56 (Thread 0x7f5e0b394700 (LWP 3531))</span><br><span class="line">|                 |                 |</span><br><span class="line">|                 |                 +----本地线程id(另一种表示,LWP-light weight process)</span><br><span class="line">|                 +-------------------本地线程id</span><br><span class="line">+------------------------------线程名称</span><br></pre></td></tr></table></figure>而通过jstack输出的main本地线程ID为0xdcb，其10进制正好为3531。</li></ul><p>“runnable”表示当前线程处于运行状态。这个runnable状态是从虚拟机的角度来看的, 表示这个线程正在运行</p><p><strong>⚠️ NOTE:</strong> 但是处于Runnable状态的线程不一定真的消耗CPU. 处于Runnable的线程只能说明该线程没有阻塞在java的wait或者sleep方法上，同时也没等待在锁上面。但是如果该线程调用了本地方法，而本地方法处于等待状态，这个时候虚拟机是不知道本地代码中发生 了什么（但操作系统是知道的，pstack就是操作提供的一个命令，它知道当前线程正在执行的本地代码上下文），此时尽管当前线程实际上也是阻塞的状态，但实际上显示出来的还是runnable状态， 这种情况下是不消耗CPU的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 处于waittig和blocked状态的线程都不会消耗CPU </span><br><span class="line">2. 线程频繁地挂起和唤醒需要消耗CPU, 而且代价颇大</span><br></pre></td></tr></table></figure><ul><li>TIMED_WAITING(on object monitor) 表示当前线程被挂起一段时间,说明该线程正在 执行obj.wait(int time)方法.</li><li>TIMED_WAITING(sleeping) 表示当前线程被挂起一段时间,即正在执行Thread.sleep(int time)方法. </li><li>TIMED_WAITING(parking) 当前线程被挂起一段时间,即正在执行Thread.sleep(int time)方法.</li><li>WAINTING(on object monitor) 当前线程被挂起，即正在执行obj.wait()方法(无参数的wait()方法).<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">处于TIMED_WAITING、WAINTING状态的线程一定不消耗CPU. 处于RUNNABLE的线程，要结合当前线程代码的性质判断，是否消耗CPU.</span><br><span class="line">• 如果是纯Java运算代码，则消耗CPU.</span><br><span class="line">• 如果是网络IO,很少消耗CPU.</span><br><span class="line">• 如果是本地代码，结合本地代码的性质判断(可以通过pstack/gstack获取本地线程堆栈)， 如果是纯运算代码，则消耗CPU, 如果被挂起，则不消耗CPU,如果是IO,则不怎么消 耗CPU。</span><br></pre></td></tr></table></figure></li></ul><h1 id="三、相关的排查方法"><a href="#三、相关的排查方法" class="headerlink" title="三、相关的排查方法"></a>三、相关的排查方法</h1><h2 id="1-CPU"><a href="#1-CPU" class="headerlink" title="1.CPU"></a>1.CPU</h2><p>生产环境中往往会出现CPU飙高的情况，对于JAVA应用而言，此类问题相对较好确定问题方向。</p><h3 id="1-1-使用jstack确定CPU占用高的线程"><a href="#1-1-使用jstack确定CPU占用高的线程" class="headerlink" title="1.1 使用jstack确定CPU占用高的线程\"></a>1.1 使用jstack确定CPU占用高的线程\</h3><p>通过<code>top</code>指令，可以看到进程占用的一些基础资源信息，然后“P”键可以按照CPU使用率进行排序，“M”键可以按照内存占用情况进行排序</p><p>找到CPU占用高的进程pid，然后将jstack信息定向到一个文件中去，通过<code>top -Hp pid</code>查看具体的情况。</p><p>通过 <code>printf &#39;%x\n&#39; pid</code>将pid转换为16进制，然后在jstack文件中根据对应的数字进行查找，然后针对性的进行分析</p><h3 id="1-2-频繁GC"><a href="#1-2-频繁GC" class="headerlink" title="1.2 频繁GC"></a>1.2 频繁GC</h3><p>有时候我们可以先确定下gc是不是太频繁，使用<code>jstat -gc pid 1000</code>命令来对gc分代变化情况进行观察，1000表示采样间隔(ms)，<code>S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU</code>分别代表两个Survivor区、Eden区、老年代、元数据区的容量和使用量。<code>YGC/YGT、FGC/FGCT、GCT</code>则代表YoungGc、FullGc的耗时和次数以及总耗时。如果看到gc比较频繁，再针对gc方面做进一步分析。<br><img src="/../images/gc.png" alt="alt text"></p><h3 id="1-3-频繁上下文切换"><a href="#1-3-频繁上下文切换" class="headerlink" title="1.3 频繁上下文切换"></a>1.3 频繁上下文切换</h3><p>针对频繁上下文问题，我们可以使用vmstat命令来进行查看<br><img src="/../images/vmstat.png" alt="alt text"><br>cs(context switch)一列则代表了上下文切换的次数。</p><p>如果我们希望对特定的pid进行监控那么可以使用 <code>pidstat -w pid</code>命令，cswch和nvcswch表示自愿及非自愿切换。</p><h2 id="2-内存"><a href="#2-内存" class="headerlink" title="2.内存"></a>2.内存</h2><p>对于JAVA应用，涉及到的内存问题主要包括OOM、GC问题和堆外内存。</p><h3 id="2-1-OOM"><a href="#2-1-OOM" class="headerlink" title="2.1 OOM"></a>2.1 OOM</h3><p>JVM中的内存不足，OOM大致可以分为以下几种情况</p><ul><li><code>Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: unable to create new native thread</code> 这个意思是没有足够的内存空间给线程分配java栈，基本上还是线程池代码写的有问题，比如说忘记shutdown，所以说应该首先从代码层面来寻找问题，使用jstack或者jmap。如果一切都正常，JVM方面可以通过指定Xss来减少单个thread stack的大小。另外也可以在系统层面，可以通过修改<code>/etc/security/limits.confnofile</code>和<code>nproc</code>来增大os对线程的限制</li><li><code>Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space </code> 这个意思是堆的内存占用已经达到-Xmx设置的最大值，应该是最常见的OOM错误了。解决思路仍然是先应该在代码中找，怀疑存在内存泄漏，通过jstack和jmap去定位问题。如果说一切都正常，才需要通过调整Xmx的值来扩大内存。</li><li><code>Caused by: java.lang.OutOfMemoryError: Meta space</code> 这个意思是元数据区的内存占用已经达到<code>XX:MaxMetaspaceSize</code>设置的最大值，排查思路和上面的一致，参数方面可以通过<code>XX:MaxPermSize</code>来进行调整</li><li><code>Exception in thread &quot;main&quot; java.lang.StackOverflowError</code> 表示线程栈需要的内存大于Xss值，同样也是先进行排查，参数方面通过Xss来调整，但调整的太大可能又会引起OOM。</li></ul><h3 id="2-2-GC问题"><a href="#2-2-GC问题" class="headerlink" title="2.2 GC问题"></a>2.2 GC问题</h3><p>gc问题除了影响cpu也会影响内存，排查思路也是一致的。一般先使用jstat来查看分代变化情况，比如youngGC或者fullGC次数是不是太多呀；EU、OU等指标增长是不是异常等。</p><p>线程的话太多而且不被及时gc也会引发oom，大部分就是之前说的<code>unable to create new native thread</code>。除了jstack细细分析dump文件外，我们一般先会看下总体线程，通过<code>pstreee -p pid |wc -l</code></p><h3 id="2-3-堆外内存"><a href="#2-3-堆外内存" class="headerlink" title="2.3 堆外内存"></a>2.3 堆外内存</h3><p>JVM 的堆外内存主要包括：</p><ul><li>JVM 自身运行占用的空间；</li><li>线程栈分配占用的系统内存；</li><li>DirectByteBuffer 占用的内存；</li><li>JNI 里分配的内存；</li><li>Java 8 开始的元数据空间；</li><li>NIO 缓存</li><li>Unsafe 调用分配的内存；</li><li>codecache</li></ul><p>冰山对象：冰山对象是指在 JVM 堆里占用的内存很小，但其实引用了一块很大的本地内存。DirectByteBuffer 和 线程都属于这类对象。</p><h4 id="2-3-1NMT分析堆外内存"><a href="#2-3-1NMT分析堆外内存" class="headerlink" title="2.3.1NMT分析堆外内存"></a>2.3.1NMT分析堆外内存</h4><p>NMT（Native Memory Tracking）是 HotSpot JVM 引入的跟踪 JVM 内部使用的本地内存的一个特性，可以通过 jcmd 工具访问 NMT 数据。NMT 目前不支持跟踪第三方本地代码的内存分配和 JDK 类库。</p><p>NMT 不跟踪非 JVM 代码的内存分配，本地代码里的内存泄露需要使用操作系统支持的工具来定位。</p><h4 id="2-3-2-开启-NMT"><a href="#2-3-2-开启-NMT" class="headerlink" title="2.3.2 开启 NMT"></a>2.3.2 开启 NMT</h4><p>启用 NMT 会带来 5-10% 的性能损失。NMT 的内存使用率情况需要添加两个机器字 word 到 malloc 内存的 malloc 头里。NMT 内存使用率也被 NMT 跟踪。<br>启动命令： <code>-XX:NativeMemoryTracking=[off | summary | detail]</code>。</p><ul><li>off：NMT 默认是关闭的；</li><li>summary：只收集子系统的内存使用的总计数据；</li><li>detail：收集每个调用点的内存使用数据。</li></ul><h4 id="2-3-3-jcmd-访问-NMT-数据"><a href="#2-3-3-jcmd-访问-NMT-数据" class="headerlink" title="2.3.3 jcmd 访问 NMT 数据"></a>2.3.3 jcmd 访问 NMT 数据</h4><p>命令：<br><code>jcmd &lt;pid&gt; VM.native_memory [summary | detail | baseline | summary.diff | detail.diff | shutdown] [scale= KB | MB | GB]</code></p>]]></content>
    
    
    <summary type="html">java常见问题和排查的基本方法和工具介绍</summary>
    
    
    
    <category term="问题排查" scheme="http://baixiaozhou.github.io/categories/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
    
    <category term="JAVA" scheme="http://baixiaozhou.github.io/tags/JAVA/"/>
    
    <category term="Linux" scheme="http://baixiaozhou.github.io/tags/Linux/"/>
    
  </entry>
  
</feed>
